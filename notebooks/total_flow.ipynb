{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luca-arts/seeingtheimperceptible/blob/main/notebooks/total_flow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auv1_Ky6GZlc"
      },
      "source": [
        "# Seeing the imperceptible: total flow\n",
        "\n",
        "this is a notebook which is used to have a set of images move through the processing steps which can individually be found in the topic related folders.\n",
        "\n",
        "A **batch** of images will be processed and all intermediate steps will be saved. This is not an optimized flow, yet a flow allowing the user to intervene where necessary and have updated images continue throughout the flow.\n",
        "\n",
        "This flow is created to test with some experts and capture their feedback, it is not intended for day-to-day usage. One testing day will be organized in which this notebook will be used with some unique images.\n",
        "\n",
        "## steps\n",
        "\n",
        "1. Sensor dust removal\n",
        "2. Image Editing (LaMa)\n",
        "3. Background Removal\n",
        "4. Background Recoloring: not yet\n",
        "5. Clothes recoloring: not yet\n",
        "6. Skin retouching\n",
        "<!-- 7. Face Detection -->\n",
        "7. optional: Color Corrections: not yet\n",
        "8. Color Grading: \n",
        "9. Image upscaling\n",
        "\n",
        "TODO: is it necessary to create a config file and have separate notebooks for each step? (with 1 common config generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrpFLD9BGU3q",
        "outputId": "89d7866a-27ef-4fb5-eb32-92267ac94b43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what's the username for nextcloud? colab\n",
            "what's the password for user colab? ··········\n",
            "0\n",
            "Please enter the username to authenticate with server\n",
            "https://cloud.bxlab.net/remote.php/dav/files/colab/colabfiles/ or hit enter for none.\n",
            "  Username: Please enter the password to authenticate user colab with server\n",
            "https://cloud.bxlab.net/remote.php/dav/files/colab/colabfiles/ or hit enter for none.\n",
            "  Password:  \n"
          ]
        }
      ],
      "source": [
        "# first we'll link a database connection:\n",
        "!curl https://raw.githubusercontent.com/luca-arts/seeingtheimperceptible/main/notebooks/database_mod.py -o /content/database_mod.py --silent\n",
        "from database_mod import *\n",
        "\n",
        "link_nextcloud()\n",
        "\n",
        "nextcloud = '/content/database/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv-3JoWpICRe"
      },
      "source": [
        "## SETUP\n",
        "\n",
        "we'll link this instance of the machine learning flow to your name:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PpvzPCmICRe",
        "outputId": "d153568c-6cef-4cfd-b405-e073d0b23e5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Are you sure you don't want to change the name?\n"
          ]
        }
      ],
      "source": [
        "tname = 'total' #@param {type:\"string\"}\n",
        "if(tname=='total'):\n",
        "    print(\"Are you sure you don't want to change the name?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB5-jsXmItCP"
      },
      "source": [
        "## Step 1: Sensor dust removal\n",
        "\n",
        "we'll link the main input folder and write the output images in the output folder of step 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gvKTWPdHkHN",
        "outputId": "267e7086-6304-40a2-87e9-55976a4193f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1255  100  1255    0     0   7212      0 --:--:-- --:--:-- --:--:--  7212\n"
          ]
        }
      ],
      "source": [
        "#@title imports of libraries & setting up\n",
        "input_step1, output_step1 = create_io(database=nextcloud,topic=tname,library='step1_sensor_dust', input_redirect='/content/database/total/input')\n",
        "\n",
        "#import libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import os, sys\n",
        "!curl https://raw.githubusercontent.com/Tschucker/Python-Automatic-Sensor-Dust-Removal/main/shapedetector.py -o /content/shapedetector.py\n",
        "module_path = os.path.abspath(os.path.join('.'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "from shapedetector import ShapeDetector\n",
        "import imutils\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UWZFZUVI36H",
        "outputId": "18cc732b-a5c2-49db-aa58-606b5673b245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing  1.jpg\n",
            "processing  2.jpg\n"
          ]
        }
      ],
      "source": [
        "#@title Set inpainting options and run the model\n",
        "radius = 11 #@param {type:\"slider\",min:1, max:50}\n",
        "flags = cv2.INPAINT_TELEA #@param [\"cv2.INPAINT_TELEA\",\"cv2.INPAINT_NS\"]\n",
        "\n",
        "def inpaint_img(img_path, img_name, output_path, radius=10, flags=cv2.INPAINT_TELEA):\n",
        "  #color version\n",
        "  cimg = cv2.imread(img_path)\n",
        "  #grey scale image\n",
        "  img = cv2.imread(img_path,0)\n",
        "\n",
        "  #Apply Global Threshold\n",
        "  m = np.mean(img, dtype=int)\n",
        "  global_thresh = cv2.threshold(img,int(m/1.2),255,cv2.THRESH_BINARY_INV)[1]\n",
        "\n",
        "  #Perform Adaptive Threshold\n",
        "  adaptive_thresh_img = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY_INV,19,10)\n",
        "\n",
        "  #Image Magnification Filter Kernel\n",
        "  KERNEL = np.ones((10,10), dtype=int)*10\n",
        "\n",
        "  #Filter the thresholded images*\n",
        "  img_filt = cv2.filter2D(adaptive_thresh_img,-1,KERNEL)\n",
        "  #global_thresh = cv2.filter2D(global_thresh,-1,KERNEL)\n",
        "\n",
        "  #Apply multiple times\n",
        "  for i in range(2):\n",
        "      KERNEL_i = np.ones((int(10),int(10)), dtype=int)*10\n",
        "      img_filt = cv2.filter2D(img_filt,-1,KERNEL_i)\n",
        "\n",
        "  #Combine Thresholds\n",
        "  comb = img_filt + global_thresh\n",
        "\n",
        "  #Find and Classify Contours of Image\n",
        "  cnts = cv2.findContours(comb.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cnts = imutils.grab_contours(cnts)\n",
        "  sd = ShapeDetector()\n",
        "  cimg_copy = cimg.copy()\n",
        "  for c in cnts:\n",
        "      # compute the center of the contour, then detect the name of the\n",
        "      # shape using only the contour\n",
        "      M = cv2.moments(c)\n",
        "      if M[\"m00\"] != 0:\n",
        "          cX = int((M[\"m10\"] / M[\"m00\"]) * 1)\n",
        "          cY = int((M[\"m01\"] / M[\"m00\"]) * 1)\n",
        "          shape = sd.detect(c)\n",
        "          # multiply the contour (x, y)-coordinates by the resize ratio,\n",
        "          # then draw the contours and the name of the shape on the image\n",
        "          if len(c) < 50:\n",
        "              c = c.astype(\"float\")\n",
        "              c *= 1\n",
        "              c = c.astype(\"int\")\n",
        "              cv2.drawContours(cimg_copy, [c], -1, (0, 255, 0), 2)\n",
        "              cv2.putText(cimg_copy, shape, (cX, cY), cv2.FONT_HERSHEY_SIMPLEX,0.5, (255, 255, 255), 2)\n",
        "  \n",
        "  #Create Dust Mask\n",
        "  img_mask = np.zeros((img.shape[0], img.shape[1]), dtype='uint8')\n",
        "  for c in cnts:\n",
        "      # compute the center of the contour, then detect the name of the\n",
        "      # shape using only the contour\n",
        "      M = cv2.moments(c)\n",
        "      if M[\"m00\"] != 0:\n",
        "          cX = int((M[\"m10\"] / M[\"m00\"]) * 1)\n",
        "          cY = int((M[\"m01\"] / M[\"m00\"]) * 1)\n",
        "          shape = sd.detect(c)\n",
        "          # multiply the contour (x, y)-coordinates by the resize ratio,\n",
        "          # then draw the contours and the name of the shape on the image\n",
        "          if len(c) < 50:\n",
        "              c = c.astype(\"float\")\n",
        "              c *= 1\n",
        "              c = c.astype(\"int\")\n",
        "              cv2.fillPoly(img_mask, pts=[c], color=(255,255,255))\n",
        "\n",
        "    \n",
        "  #Inpaint the image\n",
        "  cimg_inpaint = cv2.inpaint(cimg, img_mask, radius, flags=flags)\n",
        "\n",
        "  #Show and Save Final Image\n",
        "  save_img_pth = os.path.join(output_path,img_name)\n",
        "  cv2.imwrite(save_img_pth, cimg_inpaint)\n",
        "\n",
        "  # plt_out = cv2.cvtColor(cimg_inpaint, cv2.COLOR_BGR2RGB)\n",
        "  # return plt_out\n",
        "\n",
        "for img_name in os.listdir(input_step1):\n",
        "  print(\"processing \",img_name)\n",
        "  img_path = os.path.join(input_step1,img_name)\n",
        "  inpaint_img(img_path, img_name, output_step1, radius=radius, flags=flags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfTsfHmAI6R4"
      },
      "source": [
        "### verification\n",
        "\n",
        "Now it's time to go to the database and verify the results. If needed we adapt the images locally. \n",
        "\n",
        "TODO: how easily can we **sync** the images to allow the experts to intervene? Is it possible with nextcloud?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0UVWDfIJmUS"
      },
      "source": [
        "## step 2: Minor retouching: image editing LaMa \n",
        "Once verified we want to continue with the next step, being image editing (LaMa model)\n",
        "\n",
        "therefore we link the output folder of previous step to the inputfolder of this step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRUbNHttJb3l",
        "outputId": "033a4d14-4c08-4649-d813-2a0702bb7021",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/lama'...\n",
            "remote: Enumerating objects: 309, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 309 (delta 47), reused 40 (delta 39), pack-reused 240\u001b[K\n",
            "Receiving objects: 100% (309/309), 6.51 MiB | 20.13 MiB/s, done.\n",
            "Resolving deltas: 100% (89/89), done.\n",
            "\n",
            "> Install dependencies\n",
            "\u001b[K     |████████████████████████████████| 12.5 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 72 kB 533 kB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 50.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 841 kB 35.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 51.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 948 kB 42.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 48 kB/s \n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 39.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 32.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 136 kB 35.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 50.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 176 kB 34.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 7.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 35.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 33.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 46.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.2 MB/s \n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\u001b[0m\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\n",
            "> Download the model\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100  363M    0  363M    0     0  9979k      0 --:--:--  0:00:37 --:--:-- 10.2M\n",
            "Archive:  /content/lama/big-lama.zip\n",
            "  inflating: /content/lama/big-lama/config.yaml  \n",
            "  inflating: /content/lama/big-lama/models/best.ckpt  \n",
            ">fixing opencv\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 54.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#@title imports of libraries & setting up\n",
        "\n",
        "input_step2, output_step2 = create_io(database=nextcloud,topic=tname,library='step2_lama', input_redirect=output_step1)\n",
        "root_path2 = '/content/lama'\n",
        "\n",
        "# clone the repository\n",
        "if not os.path.exists(root_path2):\n",
        "  !git clone https://github.com/saic-mdal/lama {root_path2}\n",
        "# Set up the environment\n",
        "print('\\n> Install dependencies')\n",
        "!pip install -qr lama/requirements.txt \n",
        "# do we need the wget?\n",
        "!pip install -q wget \n",
        "\n",
        "# download the model\n",
        "print('\\n> Download the model')\n",
        "!curl -L $(yadisk-direct https://disk.yandex.ru/d/ouP6l8VJ0HpMZg) -o {root_path2}/big-lama.zip\n",
        "# todo check where the model is unzipped\n",
        "!unzip {root_path2}/big-lama.zip -d {root_path2}\n",
        "# fixing openCV\n",
        "print('>fixing opencv')\n",
        "!pip uninstall -q opencv-python-headless -y \n",
        "!pip install -q opencv-python-headless==4.1.2.30 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iG3cZFNfL-NZ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title imports & helper functions\n",
        "\n",
        "import base64, os\n",
        "from IPython.display import HTML, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import wget\n",
        "from shutil import copyfile\n",
        "import shutil\n",
        "\n",
        "canvas_html = \"\"\"\n",
        "<style>\n",
        ".button {\n",
        "  background-color: #4CAF50;\n",
        "  border: none;\n",
        "  color: white;\n",
        "  padding: 15px 32px;\n",
        "  text-align: center;\n",
        "  text-decoration: none;\n",
        "  display: inline-block;\n",
        "  font-size: 16px;\n",
        "  margin: 4px 2px;\n",
        "  cursor: pointer;\n",
        "}\n",
        "</style>\n",
        "<canvas1 width=%d height=%d>\n",
        "</canvas1>\n",
        "<canvas width=%d height=%d>\n",
        "</canvas>\n",
        "\n",
        "<button class=\"button\">Finish</button>\n",
        "<script>\n",
        "var canvas = document.querySelector('canvas')\n",
        "var ctx = canvas.getContext('2d')\n",
        "\n",
        "var canvas1 = document.querySelector('canvas1')\n",
        "var ctx1 = canvas.getContext('2d')\n",
        "\n",
        "\n",
        "ctx.strokeStyle = 'red';\n",
        "\n",
        "var img = new Image();\n",
        "img.src = \"data:image/%s;charset=utf-8;base64,%s\";\n",
        "console.log(img)\n",
        "img.onload = function() {\n",
        "  ctx1.drawImage(img, 0, 0);\n",
        "};\n",
        "img.crossOrigin = 'Anonymous';\n",
        "\n",
        "ctx.clearRect(0, 0, canvas.width, canvas.height);\n",
        "\n",
        "ctx.lineWidth = %d\n",
        "var button = document.querySelector('button')\n",
        "var mouse = {x: 0, y: 0}\n",
        "\n",
        "canvas.addEventListener('mousemove', function(e) {\n",
        "  mouse.x = e.pageX - this.offsetLeft\n",
        "  mouse.y = e.pageY - this.offsetTop\n",
        "})\n",
        "canvas.onmousedown = ()=>{\n",
        "  ctx.beginPath()\n",
        "  ctx.moveTo(mouse.x, mouse.y)\n",
        "  canvas.addEventListener('mousemove', onPaint)\n",
        "}\n",
        "canvas.onmouseup = ()=>{\n",
        "  canvas.removeEventListener('mousemove', onPaint)\n",
        "}\n",
        "var onPaint = ()=>{\n",
        "  ctx.lineTo(mouse.x, mouse.y)\n",
        "  ctx.stroke()\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "  button.onclick = ()=>{\n",
        "    resolve(canvas.toDataURL('image/png'))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def draw(imgm, filename='drawing.png', w=400, h=200, line_width=1):\n",
        "  display(HTML(canvas_html % (w, h, w,h, filename.split('.')[-1], imgm, line_width)))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZdwoEd9bqytl",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title some error happens in LaMa, so we're skipping this step for now\n",
        "import shutil\n",
        "for file in os.listdir(input_step2):\n",
        "  shutil.copy2(os.path.join(input_step2, file), output_step2)\n",
        "\n",
        "# for i in os.listdir(input_step2):\n",
        "#   fname = os.path.join(input_step2,i)\n",
        "\n",
        "#   image64 = base64.b64encode(open(fname, 'rb').read())\n",
        "#   image64 = image64.decode('utf-8')\n",
        "\n",
        "#   print(f'Will use {fname} for inpainting')\n",
        "#   img = np.array(plt.imread(f'{fname}')[:,:,:3])\n",
        "\n",
        "#   draw(image64, filename=f\"./{fname.split('.')[1]}_mask.png\", w=img.shape[1], h=img.shape[0], line_width=0.04*img.shape[1])\n",
        "#   #@title Show a masked image and save a mask\n",
        "\n",
        "#   # plt.rcParams[\"figure.figsize\"] = (15,5)\n",
        "#   # plt.rcParams['figure.dpi'] = 200\n",
        "#   # plt.subplot(131)\n",
        "#   # with_mask = np.array(plt.imread(f\"./{fname.split('.')[1]}_mask.png\")[:,:,:3])\n",
        "#   # mask = (with_mask[:,:,0]==1)*(with_mask[:,:,1]==0)*(with_mask[:,:,2]==0)\n",
        "#   # plt.imshow(mask, cmap='gray')\n",
        "#   # plt.axis('off')\n",
        "#   # plt.title('mask')\n",
        "#   # plt.imsave(f\"./{fname.split('.')[1]}_mask.png\",mask, cmap='gray')\n",
        "\n",
        "#   # plt.subplot(132)\n",
        "#   # img = np.array(plt.imread(f'{fname}')[:,:,:3])\n",
        "#   # plt.imshow(img)\n",
        "#   # plt.axis('off')\n",
        "#   # plt.title('img')\n",
        "\n",
        "#   # plt.subplot(133)\n",
        "#   # img = np.array((1-mask.reshape(mask.shape[0], mask.shape[1], -1))*plt.imread(fname)[:,:,:3])\n",
        "#   # _=plt.imshow(img)\n",
        "#   # _=plt.axis('off')\n",
        "#   # _=plt.title('img * mask')\n",
        "#   # plt.show()\n",
        "\n",
        "#   # os.makedirs('/content/output')\n",
        "\n",
        "#   print('Run inpainting')\n",
        "#   !echo $(pwd)\n",
        "#   if '.jpeg' in fname:\n",
        "#     !PYTHONPATH={root_path2} TORCH_HOME={root_path2} python3 {root_path2}/bin/predict.py model.path={root_path2}/big-lama indir={input_step2} outdir={output_step2} dataset.img_suffix=.jpeg > /dev/null\n",
        "#   elif '.jpg' in fname:\n",
        "#     !PYTHONPATH={root_path2} TORCH_HOME=$(pwd) python3 {root_path2}/bin/predict.py model.path={root_path2}/big-lama indir={input_step2}  outdir={output_step2}  dataset.img_suffix=.jpg   > /dev/null\n",
        "#   elif '.png' in fname:\n",
        "#     !PYTHONPATH={root_path2} TORCH_HOME={root_path2} python3 {root_path2}/bin/predict.py model.path={root_path2}/big-lama indir={input_step2}  outdir={output_step2}  dataset.img_suffix=.png > /dev/null\n",
        "#   else:\n",
        "#     print(f'Error: unknown suffix .{fname.split(\".\")[-1]} use [.png, .jpeg, .jpg]')\n",
        "\n",
        "#   plt.rcParams['figure.dpi'] = 200\n",
        "\n",
        "#   print(os.listdir(output_step2))\n",
        "\n",
        "# # plt.imshow(plt.imread(f\"/content/output/{fname.split('.')[1].split('/')[2]}_mask.png\"))\n",
        "# # _=plt.axis('off')\n",
        "# # _=plt.title('inpainting result')\n",
        "# # plt.show()\n",
        "\n",
        "# # fname = None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVknZ2QiAzSE"
      },
      "source": [
        "## Step 3: background removal\n",
        "\n",
        "Again, verify the outcome of step 2. \n",
        "\n",
        "Now we'll subtract the background using the PaddleSeg model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tAAAIFzIBD_Z",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "input_step3, output_step3 = create_io(database=nextcloud,topic=tname,library='step3_bg_removal', input_redirect=output_step2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "H2dRnK6VBMlj",
        "cellView": "form",
        "collapsed": true,
        "outputId": "520ea748-e1f4-4c3e-e715-5338c2955c36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PaddleSeg\n",
            "Obtaining file:///content/PaddleSeg\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (6.0)\n",
            "Requirement already satisfied: visualdl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (2.2.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (4.5.4.60)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (3.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (1.4.1)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (3.2.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (1.3.5)\n",
            "Requirement already satisfied: bce-python-sdk in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (0.8.64)\n",
            "Requirement already satisfied: pre-commit in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (2.18.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (1.21.6)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: shellcheck-py in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (0.8.0.4)\n",
            "Requirement already satisfied: flake8>=3.7.9 in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (4.0.1)\n",
            "Requirement already satisfied: Pillow>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (7.1.2)\n",
            "Requirement already satisfied: Flask-Babel>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (2.0.0)\n",
            "Requirement already satisfied: flask>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (1.1.4)\n",
            "Requirement already satisfied: protobuf>=3.11.0 in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (3.17.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (3.2.2)\n",
            "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddleseg==2.5.0) (0.6.1)\n",
            "Requirement already satisfied: pyflakes<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddleseg==2.5.0) (2.4.0)\n",
            "Requirement already satisfied: pycodestyle<2.9.0,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddleseg==2.5.0) (2.8.0)\n",
            "Requirement already satisfied: importlib-metadata<4.3 in /usr/local/lib/python3.7/dist-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddleseg==2.5.0) (4.2.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg==2.5.0) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg==2.5.0) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg==2.5.0) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg==2.5.0) (2.11.3)\n",
            "Requirement already satisfied: Babel>=2.3 in /usr/local/lib/python3.7/dist-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddleseg==2.5.0) (2.10.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddleseg==2.5.0) (2022.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl>=2.0.0->paddleseg==2.5.0) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl>=2.0.0->paddleseg==2.5.0) (4.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask>=1.1.1->visualdl>=2.0.0->paddleseg==2.5.0) (2.0.1)\n",
            "Requirement already satisfied: future>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from bce-python-sdk->visualdl>=2.0.0->paddleseg==2.5.0) (0.18.2)\n",
            "Requirement already satisfied: pycryptodome>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from bce-python-sdk->visualdl>=2.0.0->paddleseg==2.5.0) (3.14.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->visualdl>=2.0.0->paddleseg==2.5.0) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->visualdl>=2.0.0->paddleseg==2.5.0) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->visualdl>=2.0.0->paddleseg==2.5.0) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->visualdl>=2.0.0->paddleseg==2.5.0) (2.8.2)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pre-commit->visualdl>=2.0.0->paddleseg==2.5.0) (3.3.1)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pre-commit->visualdl>=2.0.0->paddleseg==2.5.0) (2.5.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pre-commit->visualdl>=2.0.0->paddleseg==2.5.0) (0.10.2)\n",
            "Requirement already satisfied: virtualenv>=20.0.8 in /usr/local/lib/python3.7/dist-packages (from pre-commit->visualdl>=2.0.0->paddleseg==2.5.0) (20.14.1)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from pre-commit->visualdl>=2.0.0->paddleseg==2.5.0) (1.6.0)\n",
            "Requirement already satisfied: platformdirs<3,>=2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->visualdl>=2.0.0->paddleseg==2.5.0) (2.5.2)\n",
            "Requirement already satisfied: distlib<1,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->visualdl>=2.0.0->paddleseg==2.5.0) (0.3.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->paddleseg==2.5.0) (0.2.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddleseg==2.5.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddleseg==2.5.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddleseg==2.5.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddleseg==2.5.0) (2.10)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->paddleseg==2.5.0) (0.24.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->paddleseg==2.5.0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->paddleseg==2.5.0) (1.1.0)\n",
            "Installing collected packages: paddleseg\n",
            "  Attempting uninstall: paddleseg\n",
            "    Found existing installation: paddleseg 2.5.0\n",
            "    Can't uninstall 'paddleseg'. No files were found to uninstall.\n",
            "  Running setup.py develop for paddleseg\n",
            "Successfully installed paddleseg-2.5.0\n",
            "/content/PaddleSeg/Matting\n"
          ]
        }
      ],
      "source": [
        "#@title imports for paddleseg\n",
        "!pip install -q PaddlePaddle\n",
        "root_path = '/content/PaddleSeg'\n",
        "\n",
        "# clone the repository\n",
        "if not os.path.exists(root_path):\n",
        "  !git clone https://github.com/PaddlePaddle/PaddleSeg {root_path}\n",
        "\n",
        "%cd {root_path}\n",
        "!pip -qq install -r requirements.txt'\n",
        "!pip install -e .\n",
        "\n",
        "# installing Matting\n",
        "%cd Matting\n",
        "!pip -qq install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title downloading the models\n",
        "# download model checkpoint \n",
        "model_path = root_path + '/Matting/data/model'\n",
        "model_params = 'https://paddleseg.bj.bcebos.com/matting/models/human_matting-resnet34_vd.pdparams'\n",
        "model_inf = 'https://paddleseg.bj.bcebos.com/matting/models/deploy/pp-humanmatting-resnet34_vd.zip'\n",
        "# make folders\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "if not os.path.exists(os.path.join(model_path,'human_matting.pdparams')):\n",
        "  print('\\n> Download the model params')\n",
        "  !curl {model_params} -o {os.path.join(model_path,'human_matting.pdparams')}\n",
        "else:\n",
        "  print ('\\n> File already downloaded')\n",
        "if not os.path.exists(os.path.join(model_path,'human_matting-resnet.zip')):\n",
        "  print('\\n> Download the model')\n",
        "  !curl {model_inf} -o {os.path.join(model_path,'human_matting-resnet.zip')}\n",
        "  !unzip -q {os.path.join(model_path,'human_matting-resnet.zip')} -d {os.path.join(model_path)}\n",
        "else:\n",
        "  print ('\\n> File already downloaded')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MssU8gR4HWaV",
        "outputId": "eca11c56-dd03-4d31-d05c-383347748ec0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "> Download the model params\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  243M  100  243M    0     0  4691k      0  0:00:53  0:00:53 --:--:-- 12.8M\n",
            "\n",
            "> Download the model\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  226M  100  226M    0     0  4911k      0  0:00:47  0:00:47 --:--:-- 10.0M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mode = 'bgremoval' #@param ['predict','bgremoval']\n",
        "if(mode=='predict'):\n",
        "# predict\n",
        "  !export CUDA_VISIBLE_DEVICES=0\n",
        "  !python predict.py \\\n",
        "      --config configs/human_matting/human_matting-resnet34_vd.yml \\\n",
        "      --model_path data/model/human_matting.pdparams \\\n",
        "      --image_path {input_step3} \\\n",
        "      --save_dir {output_step3} \\\n",
        "      --fg_estimate True\n",
        "else:\n",
        "  # bg replacement\n",
        "  background = 'r' #@param ['r','g','b','w'] {allow-input: true}\n",
        "  !export CUDA_VISIBLE_DEVICES=0\n",
        "  !python bg_replace.py \\\n",
        "      --config configs/human_matting/human_matting-resnet34_vd.yml \\\n",
        "      --model_path data/model/human_matting.pdparams \\\n",
        "      --image_path {input_step3} \\\n",
        "      --background r \\\n",
        "      --save_dir {output_step3} \\\n",
        "      --fg_estimate True"
      ],
      "metadata": {
        "id": "JOkHdhXjJZcV",
        "outputId": "a8e3cf8f-85e3-44d7-b625-41ed00108442",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/fft/__init__.py:97: DeprecationWarning: The module numpy.dual is deprecated.  Instead of using dual, use the functions directly from numpy or scipy.\n",
            "  from numpy.dual import register_func\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/special/orthogonal.py:81: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/data/__init__.py:107: DeprecationWarning: \n",
            "    Importing file_hash from pooch.utils is DEPRECATED. Please import from the\n",
            "    top-level namespace (`from pooch import file_hash`) instead, which is fully\n",
            "    backwards compatible with pooch >= 0.1.\n",
            "    \n",
            "  return file_hash(path) == expected_hash\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/types/__init__.py:108: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  long_ = _make_signed(np.long)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/types/__init__.py:109: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  ulong = _make_unsigned(np.long)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResNet18_vd exists already! It is now updated to <function ResNet18_vd at 0x7f73a9d8b8c0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResNet50_vd exists already! It is now updated to <function ResNet50_vd at 0x7f73a98cc320> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResNet101_vd exists already! It is now updated to <function ResNet101_vd at 0x7f73a98cc440> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: MobileNetV2 exists already! It is now updated to <function MobileNetV2 at 0x7f73a9d8bdd0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W18_Small_V1 exists already! It is now updated to <function HRNet_W18_Small_V1 at 0x7f73a98ccb00> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W18_Small_V2 exists already! It is now updated to <function HRNet_W18_Small_V2 at 0x7f73a98db560> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W18 exists already! It is now updated to <function HRNet_W18 at 0x7f73a98db5f0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W30 exists already! It is now updated to <function HRNet_W30 at 0x7f73a98db710> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W32 exists already! It is now updated to <function HRNet_W32 at 0x7f73a98db830> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W40 exists already! It is now updated to <function HRNet_W40 at 0x7f73a98db950> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W44 exists already! It is now updated to <function HRNet_W44 at 0x7f73a98dba70> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W48 exists already! It is now updated to <function HRNet_W48 at 0x7f73a98dbb90> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W60 exists already! It is now updated to <function HRNet_W60 at 0x7f73a98dbcb0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W64 exists already! It is now updated to <function HRNet_W64 at 0x7f73a98dbdd0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: Compose exists already! It is now updated to <class 'transforms.Compose'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: Resize exists already! It is now updated to <class 'transforms.Resize'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResizeByLong exists already! It is now updated to <class 'transforms.ResizeByLong'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResizeByShort exists already! It is now updated to <class 'transforms.ResizeByShort'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: Normalize exists already! It is now updated to <class 'transforms.Normalize'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: LimitLong exists already! It is now updated to <class 'transforms.LimitLong'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: RandomHorizontalFlip exists already! It is now updated to <class 'transforms.RandomHorizontalFlip'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: RandomBlur exists already! It is now updated to <class 'transforms.RandomBlur'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: RandomDistort exists already! It is now updated to <class 'transforms.RandomDistort'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: Padding exists already! It is now updated to <class 'transforms.Padding'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: RandomNoise exists already! It is now updated to <class 'transforms.RandomNoise'> !!!\n",
            "  format(component_name, component))\n",
            "2022-05-03 09:11:09 [INFO]\t\n",
            "---------------Config Information---------------\n",
            "batch_size: 4\n",
            "iters: 50000\n",
            "lr_scheduler:\n",
            "  boundaries:\n",
            "  - 30000\n",
            "  - 40000\n",
            "  type: PiecewiseDecay\n",
            "  values:\n",
            "  - 0.001\n",
            "  - 0.0001\n",
            "  - 1.0e-05\n",
            "model:\n",
            "  backbone:\n",
            "    pretrained: https://paddleseg.bj.bcebos.com/matting/models/ResNet34_vd_pretrained/model.pdparams\n",
            "    type: ResNet34_vd\n",
            "  if_refine: true\n",
            "  pretrained: null\n",
            "  type: HumanMatting\n",
            "optimizer:\n",
            "  momentum: 0.9\n",
            "  type: sgd\n",
            "  weight_decay: 4.0e-05\n",
            "train_dataset:\n",
            "  dataset_root: data/PPM-100\n",
            "  mode: train\n",
            "  train_file: train.txt\n",
            "  transforms:\n",
            "  - type: LoadImages\n",
            "  - scale:\n",
            "    - 0.3\n",
            "    - 1.5\n",
            "    size:\n",
            "    - 2048\n",
            "    - 2048\n",
            "    type: RandomResize\n",
            "  - crop_size:\n",
            "    - 2048\n",
            "    - 2048\n",
            "    type: RandomCrop\n",
            "  - type: RandomDistort\n",
            "  - prob: 0.1\n",
            "    type: RandomBlur\n",
            "  - type: RandomHorizontalFlip\n",
            "  - target_size:\n",
            "    - 2048\n",
            "    - 2048\n",
            "    type: Padding\n",
            "  - type: Normalize\n",
            "  type: MattingDataset\n",
            "val_dataset:\n",
            "  dataset_root: data/PPM-100\n",
            "  get_trimap: false\n",
            "  mode: val\n",
            "  transforms:\n",
            "  - type: LoadImages\n",
            "  - short_size: 2048\n",
            "    type: ResizeByShort\n",
            "  - mult_int: 128\n",
            "    type: ResizeToIntMult\n",
            "  - type: Normalize\n",
            "  type: MattingDataset\n",
            "  val_file: val.txt\n",
            "------------------------------------------------\n",
            "/content/PaddleSeg/paddleseg/cvlibs/config.py:332: UserWarning: `dataset_root` is not found. Is it correct?\n",
            "  warnings.warn(\"`dataset_root` is not found. Is it correct?\")\n",
            "2022-05-03 09:11:10 [INFO]\tLoading pretrained model from https://paddleseg.bj.bcebos.com/matting/models/ResNet34_vd_pretrained/model.pdparams\n",
            "2022-05-03 09:11:10 [INFO]\tThere are 195/195 variables loaded into ResNet_vd.\n",
            "2022-05-03 09:11:12 [INFO]\tLoading pretrained model from data/model/human_matting.pdparams\n",
            "2022-05-03 09:11:12 [INFO]\tThere are 486/486 variables loaded into HumanMatting.\n",
            "2022-05-03 09:11:12 [INFO]\tStart to predict...\n",
            "Traceback (most recent call last):\n",
            "  File \"bg_replace.py\", line 142, in <module>\n",
            "    main(args)\n",
            "  File \"bg_replace.py\", line 107, in main\n",
            "    fg_estimate=args.fg_estimate)\n",
            "  File \"/content/PaddleSeg/Matting/core/predict.py\", line 144, in predict\n",
            "    data = preprocess(img=im_path, transforms=transforms, trimap=trimap)\n",
            "  File \"/content/PaddleSeg/Matting/core/predict.py\", line 91, in preprocess\n",
            "    data = transforms(data)\n",
            "  File \"/content/PaddleSeg/Matting/transforms.py\", line 51, in __call__\n",
            "    data = op(data)\n",
            "  File \"/content/PaddleSeg/Matting/transforms.py\", line 81, in __call__\n",
            "    data['img'] = cv2.cvtColor(data['img'], cv2.COLOR_BGR2RGB)\n",
            "cv2.error: OpenCV(4.5.4) /tmp/pip-req-build-3129w7z7/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHvEogQSBfUh"
      },
      "source": [
        "## Step 4: Clothes recoloring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFRDNlwvICRl"
      },
      "outputs": [],
      "source": [
        "input_step4, output_step4 = create_io(database=nextcloud,topic=tname,library='step5_clothes_coloring', input_redirect=output_step3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ypRPB6yICRl"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "# as we're not implementing clothes recoloring yet, we copy the folders to surpass this step\n",
        "for file in os.listdir(input_step4):\n",
        "  shutil.copy2(os.path.join(input_step4, file), output_step4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jIiSGm6ICRl"
      },
      "source": [
        "## Step 6: Skin retouching\n",
        "\n",
        "we'll implement the retouchML library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2tQDXn-ICRm"
      },
      "outputs": [],
      "source": [
        "input_step6, output_step6 = create_io(database=nextcloud,topic=tname,library='step6_skin_retouch', input_redirect=output_step5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddpvlvl6ICRm"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ceij8_mpICRm"
      },
      "source": [
        "## Step 7: Color Corrections\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb06tfujICRm"
      },
      "outputs": [],
      "source": [
        "input_step7, output_step7 = create_io(database=nextcloud,topic=tname,library='step6_color_corrections', input_redirect=output_step6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_epn_TzNICRn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gHgBX7oICRn"
      },
      "source": [
        "## Step 8: Color Grading\n",
        "\n",
        "we're implementing the deep preset library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDoSTIKlICRn"
      },
      "outputs": [],
      "source": [
        "input_step8, output_step8 = create_io(database=nextcloud,topic=tname,library='step7_color_grading', input_redirect=output_step7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3_e2_XYICRn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCYexnqCICRn"
      },
      "source": [
        "## Step 9: image upscaling\n",
        "\n",
        "This is to be implemented **if** necessary?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmzznyJ8ICRo"
      },
      "outputs": [],
      "source": [
        "input_step9, output_step9 = create_io(database=nextcloud,topic=tname,library='step8_image_upscaling', input_redirect=output_step8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQsy0whPICRo"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled12.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}