{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luca-arts/seeingtheimperceptible/blob/main/notebooks/total_flow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auv1_Ky6GZlc"
      },
      "source": [
        "# Visualising the imperceptible: total flow\n",
        "\n",
        "this is a notebook which is used to have a set of images move through the processing steps which can individually be found in the topic related folders.\n",
        "\n",
        "A **batch** of images will be processed and all intermediate steps will be saved. This is not an optimized flow, yet a flow allowing the user to intervene where necessary and have updated images continue throughout the flow.\n",
        "\n",
        "This flow is created to test with some experts and capture their feedback, it is not intended for day-to-day usage. One testing day will be organized in which this notebook will be used with some unique images.\n",
        "\n",
        "## steps\n",
        "\n",
        "1. Sensor dust removal\n",
        "2. Image Editing (LaMa)\n",
        "3. Background Removal\n",
        "4. Background Recoloring: not yet\n",
        "5. Clothes recoloring: not yet\n",
        "6. Skin retouching\n",
        "<!-- 7. Face Detection -->\n",
        "7. optional: Color Corrections: not yet\n",
        "8. Color Grading: \n",
        "9. Image upscaling\n",
        "\n",
        "\n",
        "## IMPORTANT NOTE\n",
        "\n",
        "if you add more images, make sure to add style elements in folder colorgrading/style/pureColor !!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "kJs-y9foTOs3",
        "outputId": "3783f628-08b1-4715-f449-2dcdcf423cd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun 15 08:31:41 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    34W / 250W |   3241MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "JrpFLD9BGU3q",
        "outputId": "028c0bd1-32a3-4fa3-a7b9-37c6177a3499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what's the username for nextcloud? colab\n",
            "what's the password for user colab? ··········\n",
            "1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-336c4d020a56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatabase_mod\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlink_nextcloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnextcloud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/database/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/database_mod.py\u001b[0m in \u001b[0;36mlink_nextcloud\u001b[0;34m(Nextcloud_URL)\u001b[0m\n\u001b[1;32m     29\u001b[0m             input='{}\\n{}\\n'.format(un, pw), encoding='ascii')\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/etc/fstab\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# first we'll link a database connection:\n",
        "!curl https://raw.githubusercontent.com/luca-arts/seeingtheimperceptible/main/notebooks/database_mod.py -o /content/database_mod.py --silent\n",
        "from database_mod import *\n",
        "\n",
        "link_nextcloud()\n",
        "\n",
        "nextcloud = '/content/database/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv-3JoWpICRe"
      },
      "source": [
        "## SETUP\n",
        "\n",
        "we'll link this instance of the machine learning flow to your name:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PpvzPCmICRe"
      },
      "outputs": [],
      "source": [
        "#@title setting up the next cloud folders\n",
        "tname = 'total' #@param {type:\"string\"}\n",
        "if(tname=='total'):\n",
        "    print(\"Are you sure you don't want to change the name?\")\n",
        "tname = \"total_flow_results/{}\".format(tname)\n",
        "# make input dynamic with tname\n",
        "#input_tname = '/content/database/' + tname + '/input'\n",
        "input_step1, output_step1 = create_io(database=nextcloud,topic=tname,library='step1_sensor_dust', input_redirect='/content/database/total/input')\n",
        "input_step2, output_step2 = create_io(database=nextcloud,topic=tname,library='step2_lama', input_redirect=output_step1)\n",
        "input_step3, output_step3 = create_io(database=nextcloud,topic=tname,library='step3_bg_removal', input_redirect=output_step2)\n",
        "input_step4, output_step4 = create_io(database=nextcloud,topic=tname,library='step4_clothes_coloring', input_redirect=output_step3)\n",
        "input_step5, output_step5 = create_io(database=nextcloud,topic=tname,library='step5_skin_retouch', input_redirect=output_step4)\n",
        "input_step6, output_step6 = create_io(database=nextcloud,topic=tname,library='step6_color_corrections', input_redirect=output_step5)\n",
        "input_step7, output_step7 = create_io(database=nextcloud,topic=tname,library='step7_color_grading', input_redirect=output_step6)\n",
        "input_step8, output_step8 = create_io(database=nextcloud,topic=tname,library='step8_image_upscaling', input_redirect=output_step7)\n",
        "input_step9, output_step9 = create_io(database=nextcloud,topic=tname,library='step9_noise_addition', input_redirect=output_step8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB5-jsXmItCP"
      },
      "source": [
        "## Step 1: Sensor dust removal\n",
        "\n",
        "we'll link the main input folder and write the output images in the output folder of step 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gvKTWPdHkHN",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title imports of libraries & setting up\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import os, sys\n",
        "!curl https://raw.githubusercontent.com/Tschucker/Python-Automatic-Sensor-Dust-Removal/main/shapedetector.py -o /content/shapedetector.py\n",
        "module_path = os.path.abspath(os.path.join('.'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "from shapedetector import ShapeDetector\n",
        "import imutils\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UWZFZUVI36H",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Set inpainting options and run the model\n",
        "radius = 11 #@param {type:\"slider\",min:1, max:50}\n",
        "flags = cv2.INPAINT_TELEA #@param [\"cv2.INPAINT_TELEA\",\"cv2.INPAINT_NS\"]\n",
        "\n",
        "def inpaint_img(img_path, img_name, output_path, radius=10, flags=cv2.INPAINT_TELEA):\n",
        "  #color version\n",
        "  cimg = cv2.imread(img_path)\n",
        "  #grey scale image\n",
        "  img = cv2.imread(img_path,0)\n",
        "\n",
        "  #Apply Global Threshold\n",
        "  m = np.mean(img, dtype=int)\n",
        "  global_thresh = cv2.threshold(img,int(m/1.2),255,cv2.THRESH_BINARY_INV)[1]\n",
        "\n",
        "  #Perform Adaptive Threshold\n",
        "  adaptive_thresh_img = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY_INV,19,10)\n",
        "\n",
        "  #Image Magnification Filter Kernel\n",
        "  KERNEL = np.ones((10,10), dtype=int)*10\n",
        "\n",
        "  #Filter the thresholded images*\n",
        "  img_filt = cv2.filter2D(adaptive_thresh_img,-1,KERNEL)\n",
        "  #global_thresh = cv2.filter2D(global_thresh,-1,KERNEL)\n",
        "\n",
        "  #Apply multiple times\n",
        "  for i in range(2):\n",
        "      KERNEL_i = np.ones((int(10),int(10)), dtype=int)*10\n",
        "      img_filt = cv2.filter2D(img_filt,-1,KERNEL_i)\n",
        "\n",
        "  #Combine Thresholds\n",
        "  comb = img_filt + global_thresh\n",
        "\n",
        "  #Find and Classify Contours of Image\n",
        "  cnts = cv2.findContours(comb.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cnts = imutils.grab_contours(cnts)\n",
        "  sd = ShapeDetector()\n",
        "  cimg_copy = cimg.copy()\n",
        "  for c in cnts:\n",
        "      # compute the center of the contour, then detect the name of the\n",
        "      # shape using only the contour\n",
        "      M = cv2.moments(c)\n",
        "      if M[\"m00\"] != 0:\n",
        "          cX = int((M[\"m10\"] / M[\"m00\"]) * 1)\n",
        "          cY = int((M[\"m01\"] / M[\"m00\"]) * 1)\n",
        "          shape = sd.detect(c)\n",
        "          # multiply the contour (x, y)-coordinates by the resize ratio,\n",
        "          # then draw the contours and the name of the shape on the image\n",
        "          if len(c) < 50:\n",
        "              c = c.astype(\"float\")\n",
        "              c *= 1\n",
        "              c = c.astype(\"int\")\n",
        "              cv2.drawContours(cimg_copy, [c], -1, (0, 255, 0), 2)\n",
        "              cv2.putText(cimg_copy, shape, (cX, cY), cv2.FONT_HERSHEY_SIMPLEX,0.5, (255, 255, 255), 2)\n",
        "  \n",
        "  #Create Dust Mask\n",
        "  img_mask = np.zeros((img.shape[0], img.shape[1]), dtype='uint8')\n",
        "  for c in cnts:\n",
        "      # compute the center of the contour, then detect the name of the\n",
        "      # shape using only the contour\n",
        "      M = cv2.moments(c)\n",
        "      if M[\"m00\"] != 0:\n",
        "          cX = int((M[\"m10\"] / M[\"m00\"]) * 1)\n",
        "          cY = int((M[\"m01\"] / M[\"m00\"]) * 1)\n",
        "          shape = sd.detect(c)\n",
        "          # multiply the contour (x, y)-coordinates by the resize ratio,\n",
        "          # then draw the contours and the name of the shape on the image\n",
        "          if len(c) < 50:\n",
        "              c = c.astype(\"float\")\n",
        "              c *= 1\n",
        "              c = c.astype(\"int\")\n",
        "              cv2.fillPoly(img_mask, pts=[c], color=(255,255,255))\n",
        "\n",
        "    \n",
        "  #Inpaint the image\n",
        "  cimg_inpaint = cv2.inpaint(cimg, img_mask, radius, flags=flags)\n",
        "\n",
        "  #Show and Save Final Image\n",
        "  save_img_pth = os.path.join(output_path,img_name)\n",
        "  cv2.imwrite(save_img_pth, cimg_inpaint)\n",
        "\n",
        "  # plt_out = cv2.cvtColor(cimg_inpaint, cv2.COLOR_BGR2RGB)\n",
        "  # return plt_out\n",
        "\n",
        "for img_name in os.listdir(input_step1):\n",
        "  if('.jpg' in img_name or '.png' in img_name or '.jpeg' in img_name):\n",
        "    print(\"processing \",img_name)\n",
        "    img_path = os.path.join(input_step1,img_name)\n",
        "    inpaint_img(img_path, img_name, output_step1, radius=radius, flags=flags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfTsfHmAI6R4"
      },
      "source": [
        "### verification\n",
        "\n",
        "Now it's time to go to the database and verify the results. If needed we adapt the images locally. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0UVWDfIJmUS"
      },
      "source": [
        "## step 2: Minor retouching: image editing LaMa \n",
        "Once verified we want to continue with the next step, being image editing (LaMa model)\n",
        "\n",
        "therefore we link the output folder of previous step to the inputfolder of this step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRUbNHttJb3l",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title imports of libraries & setting up\n",
        "root_path2 = '/content/lama'\n",
        "\n",
        "# clone the repository\n",
        "if not os.path.exists(root_path2):\n",
        "  !git clone https://github.com/saic-mdal/lama {root_path2}\n",
        "# Set up the environment\n",
        "print('\\n> Install dependencies')\n",
        "!pip install -q -r lama/requirements.txt \n",
        "!pip install torchtext==0.9.0 --quiet \n",
        "!pip install torchvision==0.9.0 --quiet \n",
        "!pip install -q wget \n",
        "\n",
        "# model path\n",
        "model_path = os.path.join(nextcloud,'ImageEditing/big-lama')\n",
        "\n",
        "# fixing openCV\n",
        "print('>fixing opencv')\n",
        "!pip uninstall -q opencv-python-headless -y \n",
        "!pip install -q opencv-python-headless==4.1.2.30 \n",
        "!pip install torch==1.8.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iG3cZFNfL-NZ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title imports & helper functions\n",
        "\n",
        "import base64, os\n",
        "from IPython.display import HTML, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import wget\n",
        "from shutil import copyfile\n",
        "import shutil\n",
        "\n",
        "canvas_html = \"\"\"\n",
        "<style>\n",
        ".button {\n",
        "  background-color: #4CAF50;\n",
        "  border: none;\n",
        "  color: white;\n",
        "  position: absolute;\n",
        "  padding: 15px 25px;\n",
        "  text-align: center;\n",
        "  text-decoration: none;\n",
        "  display: inline-block;\n",
        "  font-size: 16px;\n",
        "  margin: 4px 2px;\n",
        "  cursor: pointer;\n",
        "}\n",
        "</style>\n",
        "<canvas1 width=%d height=%d>\n",
        "</canvas1>\n",
        "<canvas width=%d height=%d>\n",
        "</canvas>\n",
        "\n",
        "<button class=\"button\">Finish</button>\n",
        "<script>\n",
        "var canvas = document.querySelector('canvas')\n",
        "var ctx = canvas.getContext('2d')\n",
        "\n",
        "var canvas1 = document.querySelector('canvas1')\n",
        "var ctx1 = canvas.getContext('2d')\n",
        "\n",
        "\n",
        "ctx.strokeStyle = 'red';\n",
        "\n",
        "var img = new Image();\n",
        "img.src = \"data:image/%s;charset=utf-8;base64,%s\";\n",
        "console.log(img)\n",
        "img.onload = function() {\n",
        "  ctx1.drawImage(img, 0, 0);\n",
        "};\n",
        "img.crossOrigin = 'Anonymous';\n",
        "\n",
        "ctx.clearRect(0, 0, canvas.width, canvas.height);\n",
        "\n",
        "ctx.lineWidth = %d\n",
        "var button = document.querySelector('button')\n",
        "var mouse = {x: 0, y: 0}\n",
        "\n",
        "canvas.addEventListener('mousemove', function(e) {\n",
        "  mouse.x = e.pageX - this.offsetLeft\n",
        "  mouse.y = e.pageY - this.offsetTop\n",
        "})\n",
        "canvas.onmousedown = ()=>{\n",
        "  ctx.beginPath()\n",
        "  ctx.moveTo(mouse.x, mouse.y)\n",
        "  canvas.addEventListener('mousemove', onPaint)\n",
        "}\n",
        "canvas.onmouseup = ()=>{\n",
        "  canvas.removeEventListener('mousemove', onPaint)\n",
        "}\n",
        "var onPaint = ()=>{\n",
        "  ctx.lineTo(mouse.x, mouse.y)\n",
        "  ctx.stroke()\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "  button.onclick = ()=>{\n",
        "    resolve(canvas.toDataURL('image/png'))\n",
        "    button.remove()\n",
        "    canvas.remove()\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def draw(imgm, filename='drawing.png', w=400, h=200, line_width=1):\n",
        "  display(HTML(canvas_html % (w, h, w,h, filename.split('.')[-1], imgm, line_width)))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "\n",
        "\n",
        "step2_temp = os.path.join(nextcloud, tname, \"step2temp\")\n",
        "\n",
        "os.makedirs(step2_temp,exist_ok=True)\n",
        "\n",
        "for i in os.listdir(input_step2):\n",
        "  shutil.copy2(os.path.join(input_step2,i),step2_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minor Retouching via LaMa"
      ],
      "metadata": {
        "id": "Ki2KX6d0PNpZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdwoEd9bqytl",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title create masks\n",
        "%cd {root_path2}\n",
        "\n",
        "for i in os.listdir(step2_temp):\n",
        "  if('mask' in i):\n",
        "    # fix if we run the cell multiple times, not to take into account the masks\n",
        "    continue\n",
        "  fpath = os.path.join(step2_temp,i)\n",
        "\n",
        "  image64 = base64.b64encode(open(fpath, 'rb').read())\n",
        "  image64 = image64.decode('utf-8')\n",
        "  fname = fpath.split('/')[-1].split('.')[0]\n",
        "  img = np.array(plt.imread(f'{fpath}')[:,:,:3])\n",
        "\n",
        "  draw(image64, filename=f\"./{fname}_mask.png\", w=img.shape[1], h=img.shape[0], line_width=0.04*img.shape[1])\n",
        "  \n",
        "for i in os.listdir(step2_temp):\n",
        "  if('mask' in i):\n",
        "    # fix if we run the cell multiple times, not to take into account the masks\n",
        "    continue\n",
        "  fpath = os.path.join(step2_temp,i)\n",
        "  fname = fpath.split('/')[-1].split('.')[0]\n",
        "  with_mask = np.array(plt.imread(f\"./{fname}_mask.png\")[:,:,:3])\n",
        "  mask = (with_mask[:,:,0]==1)*(with_mask[:,:,1]==0)*(with_mask[:,:,2]==0)\n",
        "  plt.imsave(f\"{step2_temp}/{fname}_mask.png\",mask, cmap='gray')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run inpainting\n",
        "if '.jpeg' in fpath:\n",
        "  !PYTHONPATH=. TORCH_HOME=$(pwd) python3 bin/predict.py  model.path={model_path} indir={step2_temp}  outdir={output_step2}  dataset.img_suffix=.jpeg   > /dev/null\n",
        "elif '.jpg' in fpath:\n",
        "  !PYTHONPATH=. TORCH_HOME=$(pwd) python3 bin/predict.py  model.path={model_path} indir={step2_temp}  outdir={output_step2}  dataset.img_suffix=.jpg    > /dev/null\n",
        "elif '.png' in fpath:\n",
        "  !PYTHONPATH=. TORCH_HOME=$(pwd) python3 bin/predict.py  model.path={model_path} indir={step2_temp}  outdir={output_step2}  dataset.img_suffix=.png    > /dev/null\n",
        "else:\n",
        "  print(f'Error: unknown suffix .{fname.split(\".\")[-1]} use [.png, .jpeg, .jpg]')\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 200\n",
        "\n",
        "for i in (os.listdir(output_step2)):\n",
        "  i_name = i.replace('_mask','')\n",
        "  os.rename(os.path.join(output_step2,i),os.path.join(output_step2,i_name))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kuoiEGtFrSBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVknZ2QiAzSE"
      },
      "source": [
        "## Step 3: background removal\n",
        "\n",
        "Again, verify the outcome of step 2. \n",
        "\n",
        "Now we'll subtract the background using the PaddleSeg model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "H2dRnK6VBMlj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title imports for paddleseg\n",
        "!pip install -q PaddlePaddle\n",
        "root_path3 = '/content/PaddleSeg'\n",
        "\n",
        "# clone the repository\n",
        "if not os.path.exists(root_path3):\n",
        "  !git clone https://github.com/PaddlePaddle/PaddleSeg {root_path3}\n",
        "\n",
        "%cd {root_path3}\n",
        "!pip -qq install -r requirements.txt'\n",
        "!pip install -e .\n",
        "\n",
        "# installing Matting\n",
        "%cd Matting\n",
        "!pip -qq install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title linking the models\n",
        "model_path = os.path.join(nextcloud,\"bgRemoval/PaddleSeg/model/human_matting-resnet34_vd.pdparams\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HZC9kucsScoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JOkHdhXjJZcV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "mode = 'background_removal' #@param ['background_removal','background_replacement']\n",
        "\n",
        "step3_temp = os.path.join(nextcloud, tname, 'step3temp')\n",
        "os.makedirs(step3_temp, exist_ok=True)\n",
        "\n",
        "if(mode=='background_removal'):\n",
        "  # predict\n",
        "  !export CUDA_VISIBLE_DEVICES=0\n",
        "# data/model/human_matting.pdparams\n",
        "  !python predict.py \\\n",
        "      --config configs/human_matting/human_matting-resnet34_vd.yml \\\n",
        "      --model_path {model_path} \\\n",
        "      --image_path {input_step3} \\\n",
        "      --save_dir {step3_temp} \\\n",
        "      --fg_estimate True\n",
        "\n",
        "  for i in os.listdir(step3_temp):\n",
        "    if('_alpha' in i):\n",
        "      #we only want to copy the output files to the next step\n",
        "      continue\n",
        "\n",
        "    i_name = i.replace('_clip','')\n",
        "\n",
        "    shutil.copy2(os.path.join(step3_temp,i),os.path.join(output_step3,i_name))\n",
        "else:\n",
        "  # bg replacement\n",
        "  #@markdown either choose an rgbw value as background or type the path to the bgimage:\n",
        "\n",
        "  background = 'w' #@param ['r','g','b','w'] {allow-input: true}\n",
        "\n",
        "  !export CUDA_VISIBLE_DEVICES=0\n",
        "\n",
        "  for infer_img in os.listdir(input_step3):\n",
        "\n",
        "    !python bg_replace.py \\\n",
        "        --config configs/human_matting/human_matting-resnet34_vd.yml \\\n",
        "        --model_path {model_path} \\\n",
        "        --image_path {os.path.join(input_step3,infer_img)} \\\n",
        "        --save_dir {step3_temp} \\\n",
        "        --background {background} \\\n",
        "        --fg_estimate True\n",
        "\n",
        "  for i in os.listdir(step3_temp):\n",
        "    if('_' in i):\n",
        "      #we only want to copy the output files to the next step\n",
        "      continue\n",
        "\n",
        "    shutil.copy2(os.path.join(step3_temp,i),os.path.join(output_step3,i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHvEogQSBfUh"
      },
      "source": [
        "## Step 4: Clothes recoloring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ypRPB6yICRl"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "#@markdown as we're not implementing clothes recoloring yet, we copy the folders to surpass this step\n",
        "for file in os.listdir(input_step4):\n",
        "  shutil.copy2(os.path.join(input_step4, file), output_step4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jIiSGm6ICRl"
      },
      "source": [
        "## Step 5: Skin retouching\n",
        "\n",
        "we'll implement the retouchML library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ddpvlvl6ICRm",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title install models and prerequisites\n",
        "#@markdown, ignore the warning messages\n",
        "!pip install 'h5py==2.10.0' \n",
        "# numpy versions from 1.20 throw an error further down the road, might need to restart the runtime.\n",
        "!pip install numpy==1.19.5\n",
        "root_path5 = '/content/retouchML'\n",
        "# clone the repository\n",
        "if not os.path.exists(root_path5):\n",
        "  !git clone https://github.com/ju-leon/RetouchML {root_path5}\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "38XCtoLJ-Ktc",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title we first create the 'improved' images of faces\n",
        "#@markdown this might take a while\n",
        "\n",
        "%cd {root_path5}\n",
        "# make folders\n",
        "os.makedirs('aligned_images',exist_ok=True)\n",
        "os.makedirs('alignement_vector',exist_ok=True)\n",
        "\n",
        "!python align_images.py {input_step5} aligned_images/ alignement_vector/\n",
        "\n",
        "!python encode_images.py aligned_images/ generated_images/ latent_representations/ \\\n",
        "    --vgg_url=https://rolux.org/media/stylegan/vgg16_zhang_perceptual.pkl \\\n",
        "    --lr=0.4 \\\n",
        "    --iterations=200 \\\n",
        "    --use_best_loss=True \\\n",
        "    --early_stopping=True \\\n",
        "    --load_resnet=True \\\n",
        "    --composite_blur=6 # default=8\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDuF8o0rzNtx"
      },
      "outputs": [],
      "source": [
        "#@title then we stitch them back together with their original image\n",
        "face_path = \"generated_images/\" \n",
        "mask_path = \"masks/\"\n",
        "vector_path = \"alignement_vector/\"\n",
        "for img_name in os.listdir(input_step5):\n",
        "  raw_path = os.path.join(input_step5, img_name)\n",
        "  out_path = os.path.join(output_step5, img_name)\n",
        "\n",
        "  !python fit_faces.py {raw_path} {face_path} {mask_path} {vector_path} {out_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ceij8_mpICRm"
      },
      "source": [
        "## Step 6: Color Corrections\n",
        "\n",
        "Enhancement of the colors (CURL)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_epn_TzNICRn"
      },
      "outputs": [],
      "source": [
        "root_path6 = '/content/CURL'\n",
        "\n",
        "# clone the repository\n",
        "if not os.path.exists(root_path6):\n",
        "  !git clone https://github.com/sjmoran/CURL {root_path6}\n",
        "%cd {root_path6}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CYe5tpOO8qvx"
      },
      "outputs": [],
      "source": [
        "#@title imports\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import sys\n",
        "import torch\n",
        "import torchvision.transforms.functional as TF\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Imports from the code written by authors inside modules\n",
        "import model\n",
        "import util\n",
        "from util import ImageProcessing\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' # Might not work without GPU so if you want the cpu verson, clone https://github.com/deshwalmahesh/CURL---cpu-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6RSDg2D8vQl",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Helper functions\n",
        "def resize(image, new_width_height = 1920, convert_RGB = True):\n",
        "  '''\n",
        "  Resize and return Given Image\n",
        "  args:\n",
        "    path: Image Path, BytesIO or the image \n",
        "    new_width_height = Reshaped image's width and height. # If integer is given, it'll keep the aspect ratio as it is by shrinking the Bigger dimension (width or height) to the max of new_width_height  and then shring the smaller dimension accordingly \n",
        "    convert_RGB: Whether to Convert the RGBA image to RGB (by default backgroud is white)\n",
        "  '''\n",
        "  image = Image.open(image) if isinstance(image, (str, BytesIO)) else image\n",
        "  w, h = image.size\n",
        "\n",
        "  fixed_size = new_width_height if isinstance(new_width_height, int) else False\n",
        "\n",
        "  if fixed_size:\n",
        "    if h > w:\n",
        "      fixed_height = fixed_size\n",
        "      height_percent = (fixed_height / float(h))\n",
        "      width_size = int((float(w) * float(height_percent)))\n",
        "      image = image.resize((width_size, fixed_height), Image.NEAREST)\n",
        "\n",
        "    else:\n",
        "      fixed_width = fixed_size\n",
        "      width_percent = (fixed_width / float(w))\n",
        "      height_size = int((float(h) * float(width_percent)))\n",
        "      image = image.resize((fixed_width, height_size), Image.NEAREST) # Try Image.ANTIALIAS inplace of Image.NEAREST\n",
        "\n",
        "  else:\n",
        "    image = image.resize(new_width_height)\n",
        "\n",
        "  if image.mode == \"RGBA\" and convert_RGB:\n",
        "  \n",
        "    new = Image.new(\"RGBA\", image.size, \"WHITE\") # Create a white rgba background\n",
        "    new.paste(image, (0, 0), image) # Paste the image on the background.\n",
        "    image = new.convert('RGB')\n",
        "\n",
        "  return image\n",
        "\n",
        "\n",
        "\n",
        "def load_image(path, resize_image_size = 1920):\n",
        "    '''\n",
        "    Load the image as tensor according to the format authors have used in the code\n",
        "    '''\n",
        "    if (\"https\" in path) or (\"http\" in path):\n",
        "      image = Image.open(BytesIO(requests.get(path).content))\n",
        "\n",
        "    else:\n",
        "      image = Image.open(path)\n",
        "\n",
        "    if image.mode != 'RGB':\n",
        "      image = image.convert('RGB')\n",
        "    \n",
        "    if resize:\n",
        "      image = resize(image, resize_image_size)\n",
        "               \n",
        "    return TF.to_tensor(image).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngq2Ouyv81W8",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title load pre)trained model\n",
        "checkpoint_filepath = \"./pretrained_models/adobe_dpe/curl_validpsnr_23.073045286204017_validloss_0.0701291635632515_testpsnr_23.584083321292365_testloss_0.061363041400909424_epoch_510_model.pt\"\n",
        "\n",
        "# Build Model\n",
        "net = model.CURLNet()\n",
        "checkpoint = torch.load(checkpoint_filepath, map_location=DEVICE)\n",
        "net.load_state_dict(checkpoint['model_state_dict'])\n",
        "net.eval()\n",
        "if DEVICE == 'cuda':\n",
        "  net.cuda()\n",
        "\n",
        "\n",
        "def evaluate(img, convert_uint = False):\n",
        "    \"\"\"\n",
        "    Evaluate the model per image instance. Image of Batch size 1. Can be used in API production\n",
        "    \"\"\"\n",
        "    img = load_image(img)\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        img = img.unsqueeze(0)\n",
        "        img = torch.clamp(img, 0, 1)\n",
        "\n",
        "        net_output_img_example , _ = net(img)\n",
        "\n",
        "        net_output_img_example_numpy = net_output_img_example.squeeze(0).data.cpu().numpy()\n",
        "        net_output_img_example_numpy = ImageProcessing.swapimdims_3HW_HW3(net_output_img_example_numpy)\n",
        "        return (net_output_img_example_numpy* 255).astype(np.uint8) if convert_uint else net_output_img_example_numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5yazwQa864k"
      },
      "outputs": [],
      "source": [
        "imgs_to_convert = os.listdir(input_step6)\n",
        "# for _img in imgs_to_convert:\n",
        "#     # Load .png image\n",
        "#   image = cv2.imread(os.path.join(input_step6,_img))\n",
        "#   # Save .jpg image\n",
        "#   cv2.imwrite(os.path.join(output_step6,'{}.jpg').format(_img.split('.')[0]), image, [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
        "# imgs_to_convert = os.listdir(input_step6)\n",
        "\n",
        "for _img in imgs_to_convert:\n",
        "  print(_img)\n",
        "  result = evaluate(os.path.join(input_step6,_img), convert_uint = True) # gives you array between 0-1 so if you want an \"Image\", use 'convert_uint = True', then Image.fromarray(array).save(path)\n",
        "  Image.fromarray(result).save(os.path.join(output_step6,'{}.jpg'.format(_img.split('.')[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gHgBX7oICRn"
      },
      "source": [
        "## Step 7: Color Grading\n",
        "\n",
        "Model: deep preset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3_e2_XYICRn"
      },
      "outputs": [],
      "source": [
        "#@title install model and prerequisites\n",
        "import os\n",
        "root_path7 = '/content/DeepPreset'\n",
        "\n",
        "# folder with style transfer\n",
        "style_folder = os.path.join(nextcloud,'colorGrading/style/pureColor')\n",
        "\n",
        "# clone the repository\n",
        "if not os.path.exists(root_path7):\n",
        "  !git clone https://github.com/minhmanho/deep_preset {root_path7}\n",
        "\n",
        "!pip -q install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio==0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQEnwfnZLyd9"
      },
      "outputs": [],
      "source": [
        "#@title run the colorgrading\n",
        "%cd {root_path7}\n",
        "\n",
        "source = os.path.join(nextcloud,'colorGrading/DP_model/dp_wPPL.pth.tar')\n",
        "\n",
        "!CUDA_VISIBLE_DEVICES=0 python run.py \\\n",
        "     --content {input_step7} \\\n",
        "     --style {style_folder} \\\n",
        "     --out {output_step7} \\\n",
        "     --ckpt {source} \\\n",
        "     --size 400x592"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCYexnqCICRn"
      },
      "source": [
        "## Step 8: image upscaling\n",
        "\n",
        "Model: RealESRGan\n",
        "\n",
        "[ESRGan](https://github.com/luca-arts/seeingtheimperceptible/blob/main/notebooks/basicSuperRestoration/tests/Real_ESRGAN.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "JQsy0whPICRo",
        "cellView": "form",
        "outputId": "4cbe7923-5aad-4520-a791-5caa4608d6db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/  dp.py    \u001b[01;34mnetworks\u001b[0m/     README.md  utils.py\n",
            "\u001b[01;34mdocs\u001b[0m/  \u001b[01;34mmodels\u001b[0m/  \u001b[01;34m__pycache__\u001b[0m/  run.py\n"
          ]
        }
      ],
      "source": [
        "#@title setup and clone git repo\n",
        "import os\n",
        "root_path8 = '/content/BasicSR'\n",
        "\n",
        "# clone the repository\n",
        "if not os.path.exists(root_path8):\n",
        "  !git clone https://github.com/xinntao/Real-ESRGAN {root_path8}\n",
        "\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "0wftpfagMJyn",
        "outputId": "d988569a-2bec-402e-a9c5-7fd334d67dcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BasicSR\n",
            "running develop\n",
            "running egg_info\n",
            "writing realesrgan.egg-info/PKG-INFO\n",
            "writing dependency_links to realesrgan.egg-info/dependency_links.txt\n",
            "writing requirements to realesrgan.egg-info/requires.txt\n",
            "writing top-level names to realesrgan.egg-info/top_level.txt\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'realesrgan.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.7/dist-packages/realesrgan.egg-link (link to .)\n",
            "realesrgan 0.2.5.0 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /content/BasicSR\n",
            "Processing dependencies for realesrgan==0.2.5.0\n",
            "Searching for tqdm==4.64.0\n",
            "Best match: tqdm 4.64.0\n",
            "Adding tqdm 4.64.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torchvision==0.11.1+cu113\n",
            "Best match: torchvision 0.11.1+cu113\n",
            "Adding torchvision 0.11.1+cu113 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torch==1.10.0+cu113\n",
            "Best match: torch 1.10.0+cu113\n",
            "Adding torch 1.10.0+cu113 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Pillow==7.1.2\n",
            "Best match: Pillow 7.1.2\n",
            "Adding Pillow 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for opencv-python==4.5.4.60\n",
            "Best match: opencv-python 4.5.4.60\n",
            "Adding opencv-python 4.5.4.60 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.19.5\n",
            "Best match: numpy 1.19.5\n",
            "Adding numpy 1.19.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gfpgan==1.3.2\n",
            "Best match: gfpgan 1.3.2\n",
            "Adding gfpgan 1.3.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for facexlib==0.2.3\n",
            "Best match: facexlib 0.2.3\n",
            "Adding facexlib 0.2.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for basicsr==1.3.5\n",
            "Best match: basicsr 1.3.5\n",
            "Adding basicsr 1.3.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==4.2.0\n",
            "Best match: typing-extensions 4.2.0\n",
            "Adding typing-extensions 4.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tb-nightly==2.10.0a20220614\n",
            "Best match: tb-nightly 2.10.0a20220614\n",
            "Adding tb-nightly 2.10.0a20220614 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for yapf==0.32.0\n",
            "Best match: yapf 0.32.0\n",
            "Adding yapf 0.32.0 to easy-install.pth file\n",
            "Installing yapf script to /usr/local/bin\n",
            "Installing yapf-diff script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for PyYAML==6.0\n",
            "Best match: PyYAML 6.0\n",
            "Adding PyYAML 6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for lmdb==0.99\n",
            "Best match: lmdb 0.99\n",
            "Adding lmdb 0.99 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for filterpy==1.4.5\n",
            "Best match: filterpy 1.4.5\n",
            "Adding filterpy 1.4.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numba==0.51.2\n",
            "Best match: numba 0.51.2\n",
            "Adding numba 0.51.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for future==0.18.2\n",
            "Best match: future 0.18.2\n",
            "Adding future 0.18.2 to easy-install.pth file\n",
            "Installing futurize script to /usr/local/bin\n",
            "Installing pasteurize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scikit-image==0.17.2\n",
            "Best match: scikit-image 0.17.2\n",
            "Adding scikit-image 0.17.2 to easy-install.pth file\n",
            "Installing skivi script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for addict==2.4.0\n",
            "Best match: addict 2.4.0\n",
            "Adding addict 2.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for grpcio==1.46.3\n",
            "Best match: grpcio 1.46.3\n",
            "Adding grpcio 1.46.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard-plugin-wit==1.8.1\n",
            "Best match: tensorboard-plugin-wit 1.8.1\n",
            "Adding tensorboard-plugin-wit 1.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Markdown==3.3.7\n",
            "Best match: Markdown 3.3.7\n",
            "Adding Markdown 3.3.7 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for protobuf==3.17.3\n",
            "Best match: protobuf 3.17.3\n",
            "Adding protobuf 3.17.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard-data-server==0.6.1\n",
            "Best match: tensorboard-data-server 0.6.1\n",
            "Adding tensorboard-data-server 0.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for setuptools==57.4.0\n",
            "Best match: setuptools 57.4.0\n",
            "Adding setuptools 57.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for absl-py==1.1.0\n",
            "Best match: absl-py 1.1.0\n",
            "Adding absl-py 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Werkzeug==1.0.1\n",
            "Best match: Werkzeug 1.0.1\n",
            "Adding Werkzeug 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for google-auth==1.35.0\n",
            "Best match: google-auth 1.35.0\n",
            "Adding google-auth 1.35.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for google-auth-oauthlib==0.4.6\n",
            "Best match: google-auth-oauthlib 0.4.6\n",
            "Adding google-auth-oauthlib 0.4.6 to easy-install.pth file\n",
            "Installing google-oauthlib-tool script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for wheel==0.37.1\n",
            "Best match: wheel 0.37.1\n",
            "Adding wheel 0.37.1 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for matplotlib==3.2.2\n",
            "Best match: matplotlib 3.2.2\n",
            "Adding matplotlib 3.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for llvmlite==0.34.0\n",
            "Best match: llvmlite 0.34.0\n",
            "Adding llvmlite 0.34.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tifffile==2021.11.2\n",
            "Best match: tifffile 2021.11.2\n",
            "Adding tifffile 2021.11.2 to easy-install.pth file\n",
            "Installing lsm2bin script to /usr/local/bin\n",
            "Installing tiff2fsspec script to /usr/local/bin\n",
            "Installing tiffcomment script to /usr/local/bin\n",
            "Installing tifffile script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for imageio==2.4.1\n",
            "Best match: imageio 2.4.1\n",
            "Adding imageio 2.4.1 to easy-install.pth file\n",
            "Installing imageio_download_bin script to /usr/local/bin\n",
            "Installing imageio_remove_bin script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for networkx==2.6.3\n",
            "Best match: networkx 2.6.3\n",
            "Adding networkx 2.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for PyWavelets==1.3.0\n",
            "Best match: PyWavelets 1.3.0\n",
            "Adding PyWavelets 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2022.5.18.1\n",
            "Best match: certifi 2022.5.18.1\n",
            "Adding certifi 2022.5.18.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for importlib-metadata==4.11.4\n",
            "Best match: importlib-metadata 4.11.4\n",
            "Adding importlib-metadata 4.11.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyasn1-modules==0.2.8\n",
            "Best match: pyasn1-modules 0.2.8\n",
            "Adding pyasn1-modules 0.2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for rsa==4.8\n",
            "Best match: rsa 4.8\n",
            "Adding rsa 4.8 to easy-install.pth file\n",
            "Installing pyrsa-decrypt script to /usr/local/bin\n",
            "Installing pyrsa-encrypt script to /usr/local/bin\n",
            "Installing pyrsa-keygen script to /usr/local/bin\n",
            "Installing pyrsa-priv2pub script to /usr/local/bin\n",
            "Installing pyrsa-sign script to /usr/local/bin\n",
            "Installing pyrsa-verify script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cachetools==4.2.4\n",
            "Best match: cachetools 4.2.4\n",
            "Adding cachetools 4.2.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests-oauthlib==1.3.1\n",
            "Best match: requests-oauthlib 1.3.1\n",
            "Adding requests-oauthlib 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for python-dateutil==2.8.2\n",
            "Best match: python-dateutil 2.8.2\n",
            "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for kiwisolver==1.4.2\n",
            "Best match: kiwisolver 1.4.2\n",
            "Adding kiwisolver 1.4.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cycler==0.11.0\n",
            "Best match: cycler 0.11.0\n",
            "Adding cycler 0.11.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyparsing==3.0.9\n",
            "Best match: pyparsing 3.0.9\n",
            "Adding pyparsing 3.0.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for zipp==3.8.0\n",
            "Best match: zipp 3.8.0\n",
            "Adding zipp 3.8.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyasn1==0.4.8\n",
            "Best match: pyasn1 0.4.8\n",
            "Adding pyasn1 0.4.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for oauthlib==3.2.0\n",
            "Best match: oauthlib 3.2.0\n",
            "Adding oauthlib 3.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for realesrgan==0.2.5.0\n",
            "--2022-06-15 08:32:21--  https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/387326890/08f0e941-ebb7-48f0-9d6a-73e87b710e7e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220615%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220615T083222Z&X-Amz-Expires=300&X-Amz-Signature=371b56f756482f59db2f5388e7bc6af547503568d0e9dfa650db73df5f1ef86c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=387326890&response-content-disposition=attachment%3B%20filename%3DRealESRGAN_x4plus.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-06-15 08:32:22--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/387326890/08f0e941-ebb7-48f0-9d6a-73e87b710e7e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220615%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220615T083222Z&X-Amz-Expires=300&X-Amz-Signature=371b56f756482f59db2f5388e7bc6af547503568d0e9dfa650db73df5f1ef86c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=387326890&response-content-disposition=attachment%3B%20filename%3DRealESRGAN_x4plus.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67040989 (64M) [application/octet-stream]\n",
            "Saving to: ‘/content/BasicSR/experiments/pretrained_models/RealESRGAN_x4plus.pth.1’\n",
            "\n",
            "RealESRGAN_x4plus.p 100%[===================>]  63.93M   361MB/s    in 0.2s    \n",
            "\n",
            "2022-06-15 08:32:22 (361 MB/s) - ‘/content/BasicSR/experiments/pretrained_models/RealESRGAN_x4plus.pth.1’ saved [67040989/67040989]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title install model and prerequisites\n",
        "%cd {root_path8}\n",
        "\n",
        "# Set up the environment\n",
        "!pip install -q basicsr\n",
        "!pip install -q facexlib\n",
        "!pip install -q gfpgan\n",
        "!pip install -q -r requirements.txt\n",
        "!python setup.py develop\n",
        "\n",
        "# Download the pre-trained model\n",
        "!wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P /content/BasicSR/experiments/pretrained_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "collapsed": true,
        "id": "rQuNsPFKMYmK",
        "cellView": "form",
        "outputId": "518cd727-80f8-41fe-9c70-8c5a9347b484",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing 0 01\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3680: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "Testing 1 02\n",
            "Testing 2 03\n",
            "Testing 3 04\n",
            "Testing 4 05\n",
            "Testing 5 06\n",
            "Testing 6 07\n",
            "Testing 7 08\n",
            "Testing 8 09\n",
            "Testing 9 1\n",
            "Testing 10 10\n",
            "Testing 11 2\n"
          ]
        }
      ],
      "source": [
        "#@title upscale the images\n",
        "scale=2 #@param {type:\"slider\", min:1, max:5, step:0.5}\n",
        "!python inference_realesrgan.py -n RealESRGAN_x4plus -i {input_step8} -o {output_step8} --outscale 3.5 --face_enhance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arshs-swNpR6"
      },
      "source": [
        "# Step 9 add some noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "gslxfmC2NpR6",
        "cellView": "form",
        "outputId": "42442b09-8845-40d6-a3ef-7b7c1f03f435",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "> Installing OpenCV\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.5.4.60)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n",
            "\n",
            "> Installing Numpy\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "#@title imports\n",
        "# installing the needed libs\n",
        "print ('\\n> Installing OpenCV')\n",
        "!pip install opencv-python\n",
        "\n",
        "print ('\\n> Installing Numpy')\n",
        "!pip install numpy\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "F1wwEL6uNpR6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title helper functions\n",
        "# functions for different noise-types\n",
        "def normalize(mask):\n",
        "    return (mask - mask.min()) / (mask.max() - mask.min())\n",
        "\n",
        "def add_noise(noise_fun, gray: bool=False, **kwargs):\n",
        "    img = kwargs.get('img')\n",
        "    image = np.array(img, dtype=float)\n",
        "    noise = noise_fun(**kwargs)\n",
        "    if(gray):\n",
        "      gray_ch = cv2.cvtColor(noise.astype(np.float32), cv2.COLOR_BGR2GRAY)\n",
        "      #change color noise to gray noise for each channel\n",
        "      noise = cv2.merge([gray_ch,gray_ch,gray_ch])\n",
        "    image_out = image + noise\n",
        "    image_out = np.uint8(normalize(image_out) * 255)\n",
        "    return image_out\n",
        "\n",
        "def gaussian_noise(**kwargs):\n",
        "    mu=kwargs.get('mu')\n",
        "    sigma=kwargs.get('sigma')\n",
        "    image=kwargs.get('img')\n",
        "    noise = np.random.normal(mu, sigma, image.shape)\n",
        "    return noise\n",
        "\n",
        "def rayleigh_noise(**kwargs):\n",
        "    a = kwargs.get('a')\n",
        "    image = kwargs.get('img')\n",
        "    noise = np.random.rayleigh(a, size=image.shape)\n",
        "    return noise\n",
        "\n",
        "def gamma_noise(**kwargs):\n",
        "    scale = kwargs.get('scale')\n",
        "    image = kwargs.get('img')\n",
        "    noise = np.random.gamma(shape=1, scale=scale, size=image.shape)\n",
        "    return noise\n",
        "\n",
        "def exponent_noise(**kwargs):\n",
        "    scale = kwargs.get('scale')\n",
        "    image = kwargs.get('img')\n",
        "    noise = np.random.exponential(scale=scale, size=image.shape)\n",
        "    return noise\n",
        "\n",
        "def average_noise(**kwargs):\n",
        "    mean = kwargs.get('mu')\n",
        "    sigma = kwargs.get('sigma')\n",
        "    image = kwargs.get('img')\n",
        "    a = 2 * mean - np.sqrt(12 * sigma)\n",
        "    b = 2 * mean + np.sqrt(12 * sigma)\n",
        "    noise = np.random.uniform(a, b, image.shape)\n",
        "    return noise\n",
        "\n",
        "def add_gaussian_noise(img, mu=0, sigma=0.1, gray=False):\n",
        "    img_out = add_noise(gaussian_noise, gray=gray, img=img, mu=mu, sigma=sigma)\n",
        "    return img_out\n",
        "\n",
        "def add_rayleigh_noise(img, a=15, gray=False):\n",
        "    img_out = add_noise(rayleigh_noise,img=img,a=a,gray=gray) \n",
        "    return img_out\n",
        "\n",
        "def add_gamma_noise(img, scale=1, gray=False):\n",
        "    img_out = add_noise(gamma_noise, img=img, scale=scale,gray=gray)\n",
        "    return img_out\n",
        "\n",
        "def add_exponent_noise(img, scale=1.0, gray=False):\n",
        "    img_out = add_noise(exponent_noise, img=img, scale=scale,gray=gray)\n",
        "    return img_out\n",
        "\n",
        "def add_average_noise(img, mean=0, sigma=100, gray=False):\n",
        "    img_out = add_noise(average_noise, img=img, mu=mu, sigma=sigma, gray=gray)\n",
        "    return img_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "BcwrwFzvNpR6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "noise_type = \"gaussian\" #@param [\"gaussian\", \"rayleigh\", \"gamma\",\"exponent\",\"average\"]\n",
        "\n",
        "def use_noise(noise_type, img, mu=0,sigma=5,a=15,scale=1.0,gray=False):\n",
        "    if(noise_type==\"gaussian\"):\n",
        "      img = add_gaussian_noise(img=img, mu=mu, sigma=sigma, gray=gray)\n",
        "    if(noise_type==\"rayleigh\"):\n",
        "       img = add_rayleigh_noise(img=img,a=a,gray=gray)\n",
        "    if(noise_type==\"gamma\"):\n",
        "       img = add_gamma_noise(img=img,scale=scale,gray=gray)\n",
        "    if(noise_type==\"exponent\"):\n",
        "       img = add_exponent_noise(img=img,scale=scale, gray=gray)\n",
        "    if(noise_type==\"average\"):\n",
        "       img = add_average_noise(img=img, mu=mu, sigma=sigma, gray=gray)\n",
        "    return img\n",
        "\n",
        "#@markdown mu, sigma for gaussian and average noise\n",
        "mu = 0.35 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "sigma = 16.5 #@param {type:\"slider\", min:0, max:20, step:0.5}\n",
        "\n",
        "#@markdown a is for rayleigh noise\n",
        "a = 10 #@param {type:\"slider\", min:0, max:20, step:0.5}\n",
        "\n",
        "#@markdown scale is for gamma and exponent noise\n",
        "scale = 16.5 #@param {type:\"slider\", min:0, max:20, step:0.5}\n",
        "\n",
        "#@markdown an option to use **gray** noise instead of RGB noise\n",
        "gray = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown you can use the noise generation via: `gen_img = use_noise(noise_type, img=_img, mu=mu, sigma=sigma, a=a,scale=scale,gray=gray)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "2OBHs7FKNpR7"
      },
      "outputs": [],
      "source": [
        "#@title execute noise generation\n",
        "for i in os.listdir(input_step9):\n",
        "    _img_pth = os.path.join(input_step9,i)\n",
        "    _img = cv2.imread(_img_pth)\n",
        "    gen_img = use_noise(noise_type, img=_img, mu=mu, sigma=sigma, a=a,scale=scale,gray=gray)\n",
        "    cv2.imwrite(os.path.join(output_step9,i),gen_img)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_first_img_in_path(path):\n",
        "  import os\n",
        "  from PIL import Image\n",
        "  img = os.path.join(path,sorted(os.listdir(path))[0])\n",
        "  img = Image.open(img)\n",
        "  return img\n",
        "img_list = [input_step1,\n",
        "            output_step1,\n",
        "            output_step2,\n",
        "            output_step3,\n",
        "            output_step4,\n",
        "            output_step5,\n",
        "            output_step6,\n",
        "            output_step7,\n",
        "            output_step8,\n",
        "            output_step9]\n",
        "gif_list = list()\n",
        "for img in img_list:\n",
        "  _img = read_first_img_in_path(img).resize((400,592))\n",
        "  # display(_img)\n",
        "  gif_list.append(_img)\n",
        "\n",
        "gif_list[0].save(os.path.join(nextcloud,tname,\"result.gif\"),save_all=True, append_images=gif_list[1:], optimize=False, duration=500, loop=0)"
      ],
      "metadata": {
        "id": "KOFetNuxAMCQ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1YUmeA8ZcKn"
      },
      "source": [
        "# the end\n",
        "\n",
        "Now we've run through an entire flow, any feedback?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled12.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}