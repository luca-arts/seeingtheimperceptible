{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luca-arts/seeingtheimperceptible/blob/main/notebooks/total_flow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auv1_Ky6GZlc"
      },
      "source": [
        "# Seeing the imperceptible: total flow\n",
        "\n",
        "this is a notebook which is used to have a set of images move through the processing steps which can individually be found in the topic related folders.\n",
        "\n",
        "A **batch** of images will be processed and all intermediate steps will be saved. This is not an optimized flow, yet a flow allowing the user to intervene where necessary and have updated images continue throughout the flow.\n",
        "\n",
        "This flow is created to test with some experts and capture their feedback, it is not intended for day-to-day usage. One testing day will be organized in which this notebook will be used with some unique images.\n",
        "\n",
        "## steps\n",
        "\n",
        "1. Sensor dust removal\n",
        "2. Image Editing (LaMa)\n",
        "3. Background Removal\n",
        "4. Background Recoloring: not yet\n",
        "5. Clothes recoloring: not yet\n",
        "6. Skin retouching\n",
        "<!-- 7. Face Detection -->\n",
        "7. optional: Color Corrections: not yet\n",
        "8. Color Grading: \n",
        "9. Image upscaling\n",
        "\n",
        "TODO: is it necessary to create a config file and have separate notebooks for each step? (with 1 common config generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrpFLD9BGU3q",
        "outputId": "d2916507-2669-479a-c730-2577d947011f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what's the username for nextcloud? colab\n",
            "what's the password for user colab? ··········\n",
            "0\n",
            "Please enter the username to authenticate with server\n",
            "https://cloud.bxlab.net/remote.php/dav/files/colab/colabfiles/ or hit enter for none.\n",
            "  Username: Please enter the password to authenticate user colab with server\n",
            "https://cloud.bxlab.net/remote.php/dav/files/colab/colabfiles/ or hit enter for none.\n",
            "  Password:  \n"
          ]
        }
      ],
      "source": [
        "# first we'll link a database connection:\n",
        "!curl https://raw.githubusercontent.com/luca-arts/seeingtheimperceptible/main/notebooks/database_mod.py -o /content/database_mod.py --silent\n",
        "from database_mod import *\n",
        "\n",
        "link_nextcloud()\n",
        "\n",
        "nextcloud = '/content/database/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv-3JoWpICRe"
      },
      "source": [
        "## SETUP\n",
        "\n",
        "we'll link this instance of the machine learning flow to your name:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PpvzPCmICRe",
        "outputId": "0f597719-c523-4def-efe3-af00b8ff924f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Are you sure you don't want to change the name?\n"
          ]
        }
      ],
      "source": [
        "tname = 'total' #@param {type:\"string\"}\n",
        "if(tname=='total'):\n",
        "    print(\"Are you sure you don't want to change the name?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB5-jsXmItCP"
      },
      "source": [
        "## Step 1: Sensor dust removal\n",
        "\n",
        "we'll link the main input folder and write the output images in the output folder of step 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gvKTWPdHkHN",
        "outputId": "5b390b42-c5f0-40dd-ed45-5bf2535c8014"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1255  100  1255    0     0   9160      0 --:--:-- --:--:-- --:--:--  9094\r100  1255  100  1255    0     0   9160      0 --:--:-- --:--:-- --:--:--  9094\n"
          ]
        }
      ],
      "source": [
        "#@title imports of libraries & setting up\n",
        "input_step1, output_step1 = create_io(database=nextcloud,topic=tname,library='step1_sensor_dust', input_redirect='/content/database/total/input')\n",
        "\n",
        "#import libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import os, sys\n",
        "!curl https://raw.githubusercontent.com/Tschucker/Python-Automatic-Sensor-Dust-Removal/main/shapedetector.py -o /content/shapedetector.py\n",
        "module_path = os.path.abspath(os.path.join('.'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "from shapedetector import ShapeDetector\n",
        "import imutils\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UWZFZUVI36H",
        "outputId": "0976e39f-fb54-4425-83c5-97abb9bba232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing  1.jpg\n",
            "processing  2.jpg\n"
          ]
        }
      ],
      "source": [
        "#@title Set inpainting options and run the model\n",
        "radius = 11 #@param {type:\"slider\",min:1, max:50}\n",
        "flags = cv2.INPAINT_TELEA #@param [\"cv2.INPAINT_TELEA\",\"cv2.INPAINT_NS\"]\n",
        "\n",
        "def inpaint_img(img_path, img_name, output_path, radius=10, flags=cv2.INPAINT_TELEA):\n",
        "  #color version\n",
        "  cimg = cv2.imread(img_path)\n",
        "  #grey scale image\n",
        "  img = cv2.imread(img_path,0)\n",
        "\n",
        "  #Apply Global Threshold\n",
        "  m = np.mean(img, dtype=int)\n",
        "  global_thresh = cv2.threshold(img,int(m/1.2),255,cv2.THRESH_BINARY_INV)[1]\n",
        "\n",
        "  #Perform Adaptive Threshold\n",
        "  adaptive_thresh_img = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY_INV,19,10)\n",
        "\n",
        "  #Image Magnification Filter Kernel\n",
        "  KERNEL = np.ones((10,10), dtype=int)*10\n",
        "\n",
        "  #Filter the thresholded images*\n",
        "  img_filt = cv2.filter2D(adaptive_thresh_img,-1,KERNEL)\n",
        "  #global_thresh = cv2.filter2D(global_thresh,-1,KERNEL)\n",
        "\n",
        "  #Apply multiple times\n",
        "  for i in range(2):\n",
        "      KERNEL_i = np.ones((int(10),int(10)), dtype=int)*10\n",
        "      img_filt = cv2.filter2D(img_filt,-1,KERNEL_i)\n",
        "\n",
        "  #Combine Thresholds\n",
        "  comb = img_filt + global_thresh\n",
        "\n",
        "  #Find and Classify Contours of Image\n",
        "  cnts = cv2.findContours(comb.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cnts = imutils.grab_contours(cnts)\n",
        "  sd = ShapeDetector()\n",
        "  cimg_copy = cimg.copy()\n",
        "  for c in cnts:\n",
        "      # compute the center of the contour, then detect the name of the\n",
        "      # shape using only the contour\n",
        "      M = cv2.moments(c)\n",
        "      if M[\"m00\"] != 0:\n",
        "          cX = int((M[\"m10\"] / M[\"m00\"]) * 1)\n",
        "          cY = int((M[\"m01\"] / M[\"m00\"]) * 1)\n",
        "          shape = sd.detect(c)\n",
        "          # multiply the contour (x, y)-coordinates by the resize ratio,\n",
        "          # then draw the contours and the name of the shape on the image\n",
        "          if len(c) < 50:\n",
        "              c = c.astype(\"float\")\n",
        "              c *= 1\n",
        "              c = c.astype(\"int\")\n",
        "              cv2.drawContours(cimg_copy, [c], -1, (0, 255, 0), 2)\n",
        "              cv2.putText(cimg_copy, shape, (cX, cY), cv2.FONT_HERSHEY_SIMPLEX,0.5, (255, 255, 255), 2)\n",
        "  \n",
        "  #Create Dust Mask\n",
        "  img_mask = np.zeros((img.shape[0], img.shape[1]), dtype='uint8')\n",
        "  for c in cnts:\n",
        "      # compute the center of the contour, then detect the name of the\n",
        "      # shape using only the contour\n",
        "      M = cv2.moments(c)\n",
        "      if M[\"m00\"] != 0:\n",
        "          cX = int((M[\"m10\"] / M[\"m00\"]) * 1)\n",
        "          cY = int((M[\"m01\"] / M[\"m00\"]) * 1)\n",
        "          shape = sd.detect(c)\n",
        "          # multiply the contour (x, y)-coordinates by the resize ratio,\n",
        "          # then draw the contours and the name of the shape on the image\n",
        "          if len(c) < 50:\n",
        "              c = c.astype(\"float\")\n",
        "              c *= 1\n",
        "              c = c.astype(\"int\")\n",
        "              cv2.fillPoly(img_mask, pts=[c], color=(255,255,255))\n",
        "\n",
        "    \n",
        "  #Inpaint the image\n",
        "  cimg_inpaint = cv2.inpaint(cimg, img_mask, radius, flags=flags)\n",
        "\n",
        "  #Show and Save Final Image\n",
        "  save_img_pth = os.path.join(output_path,img_name)\n",
        "  cv2.imwrite(save_img_pth, cimg_inpaint)\n",
        "\n",
        "  # plt_out = cv2.cvtColor(cimg_inpaint, cv2.COLOR_BGR2RGB)\n",
        "  # return plt_out\n",
        "\n",
        "for img_name in os.listdir(input_step1):\n",
        "  print(\"processing \",img_name)\n",
        "  img_path = os.path.join(input_step1,img_name)\n",
        "  inpaint_img(img_path, img_name, output_step1, radius=radius, flags=flags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfTsfHmAI6R4"
      },
      "source": [
        "### verification\n",
        "\n",
        "Now it's time to go to the database and verify the results. If needed we adapt the images locally. \n",
        "\n",
        "TODO: how easily can we **sync** the images to allow the experts to intervene? Is it possible with nextcloud?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0UVWDfIJmUS"
      },
      "source": [
        "## step 2: Minor retouching: image editing LaMa \n",
        "Once verified we want to continue with the next step, being image editing (LaMa model)\n",
        "\n",
        "therefore we link the output folder of previous step to the inputfolder of this step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRUbNHttJb3l",
        "outputId": "e8fc644f-1eba-4d75-fcdc-7c9d1884cc22",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/lama'...\n",
            "remote: Enumerating objects: 309, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 309 (delta 47), reused 40 (delta 39), pack-reused 240\u001b[K\n",
            "Receiving objects: 100% (309/309), 6.51 MiB | 20.96 MiB/s, done.\n",
            "Resolving deltas: 100% (89/89), done.\n",
            "\n",
            "> Install dependencies\n",
            "\u001b[K     |████████████████████████████████| 12.5 MB 4.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 72 kB 573 kB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 58.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 841 kB 41.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 47.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 948 kB 41.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 48 kB/s \n",
            "\u001b[K     |████████████████████████████████| 74 kB 2.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 54.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 136 kB 50.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 45.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 176 kB 48.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 36.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 39.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 47.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 51.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 47.2 MB/s \n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\u001b[0m\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\n",
            "> Download the model\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100  363M    0  363M    0     0  9976k      0 --:--:--  0:00:37 --:--:--  9.7M\n",
            "Archive:  /content/lama/big-lama.zip\n",
            "  inflating: /content/lama/big-lama/config.yaml  \n",
            "  inflating: /content/lama/big-lama/models/best.ckpt  \n",
            ">fixing opencv\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 1.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#@title imports of libraries & setting up\n",
        "\n",
        "input_step2, output_step2 = create_io(database=nextcloud,topic=tname,library='step2_lama', input_redirect=output_step1)\n",
        "root_path2 = '/content/lama'\n",
        "\n",
        "# clone the repository\n",
        "if not os.path.exists(root_path2):\n",
        "  !git clone https://github.com/saic-mdal/lama {root_path2}\n",
        "# Set up the environment\n",
        "print('\\n> Install dependencies')\n",
        "!pip install -qr lama/requirements.txt \n",
        "# do we need the wget?\n",
        "!pip install -q wget \n",
        "\n",
        "# download the model\n",
        "print('\\n> Download the model')\n",
        "!curl -L $(yadisk-direct https://disk.yandex.ru/d/ouP6l8VJ0HpMZg) -o {root_path2}/big-lama.zip\n",
        "# todo check where the model is unzipped\n",
        "!unzip {root_path2}/big-lama.zip -d {root_path2}\n",
        "# fixing openCV\n",
        "print('>fixing opencv')\n",
        "!pip uninstall -q opencv-python-headless -y \n",
        "!pip install -q opencv-python-headless==4.1.2.30 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iG3cZFNfL-NZ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title imports & helper functions\n",
        "\n",
        "import base64, os\n",
        "from IPython.display import HTML, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import wget\n",
        "from shutil import copyfile\n",
        "import shutil\n",
        "\n",
        "canvas_html = \"\"\"\n",
        "<style>\n",
        ".button {\n",
        "  background-color: #4CAF50;\n",
        "  border: none;\n",
        "  color: white;\n",
        "  padding: 15px 32px;\n",
        "  text-align: center;\n",
        "  text-decoration: none;\n",
        "  display: inline-block;\n",
        "  font-size: 16px;\n",
        "  margin: 4px 2px;\n",
        "  cursor: pointer;\n",
        "}\n",
        "</style>\n",
        "<canvas1 width=%d height=%d>\n",
        "</canvas1>\n",
        "<canvas width=%d height=%d>\n",
        "</canvas>\n",
        "\n",
        "<button class=\"button\">Finish</button>\n",
        "<script>\n",
        "var canvas = document.querySelector('canvas')\n",
        "var ctx = canvas.getContext('2d')\n",
        "\n",
        "var canvas1 = document.querySelector('canvas1')\n",
        "var ctx1 = canvas.getContext('2d')\n",
        "\n",
        "\n",
        "ctx.strokeStyle = 'red';\n",
        "\n",
        "var img = new Image();\n",
        "img.src = \"data:image/%s;charset=utf-8;base64,%s\";\n",
        "console.log(img)\n",
        "img.onload = function() {\n",
        "  ctx1.drawImage(img, 0, 0);\n",
        "};\n",
        "img.crossOrigin = 'Anonymous';\n",
        "\n",
        "ctx.clearRect(0, 0, canvas.width, canvas.height);\n",
        "\n",
        "ctx.lineWidth = %d\n",
        "var button = document.querySelector('button')\n",
        "var mouse = {x: 0, y: 0}\n",
        "\n",
        "canvas.addEventListener('mousemove', function(e) {\n",
        "  mouse.x = e.pageX - this.offsetLeft\n",
        "  mouse.y = e.pageY - this.offsetTop\n",
        "})\n",
        "canvas.onmousedown = ()=>{\n",
        "  ctx.beginPath()\n",
        "  ctx.moveTo(mouse.x, mouse.y)\n",
        "  canvas.addEventListener('mousemove', onPaint)\n",
        "}\n",
        "canvas.onmouseup = ()=>{\n",
        "  canvas.removeEventListener('mousemove', onPaint)\n",
        "}\n",
        "var onPaint = ()=>{\n",
        "  ctx.lineTo(mouse.x, mouse.y)\n",
        "  ctx.stroke()\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "  button.onclick = ()=>{\n",
        "    resolve(canvas.toDataURL('image/png'))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def draw(imgm, filename='drawing.png', w=400, h=200, line_width=1):\n",
        "  display(HTML(canvas_html % (w, h, w,h, filename.split('.')[-1], imgm, line_width)))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZdwoEd9bqytl",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title some error happens in LaMa, so we're skipping this step for now\n",
        "import shutil\n",
        "for file in os.listdir(input_step2):\n",
        "  shutil.copy2(os.path.join(input_step2, file), output_step2)\n",
        "\n",
        "# for i in os.listdir(input_step2):\n",
        "#   fname = os.path.join(input_step2,i)\n",
        "\n",
        "#   image64 = base64.b64encode(open(fname, 'rb').read())\n",
        "#   image64 = image64.decode('utf-8')\n",
        "\n",
        "#   print(f'Will use {fname} for inpainting')\n",
        "#   img = np.array(plt.imread(f'{fname}')[:,:,:3])\n",
        "\n",
        "#   draw(image64, filename=f\"./{fname.split('.')[1]}_mask.png\", w=img.shape[1], h=img.shape[0], line_width=0.04*img.shape[1])\n",
        "#   #@title Show a masked image and save a mask\n",
        "\n",
        "#   # plt.rcParams[\"figure.figsize\"] = (15,5)\n",
        "#   # plt.rcParams['figure.dpi'] = 200\n",
        "#   # plt.subplot(131)\n",
        "#   # with_mask = np.array(plt.imread(f\"./{fname.split('.')[1]}_mask.png\")[:,:,:3])\n",
        "#   # mask = (with_mask[:,:,0]==1)*(with_mask[:,:,1]==0)*(with_mask[:,:,2]==0)\n",
        "#   # plt.imshow(mask, cmap='gray')\n",
        "#   # plt.axis('off')\n",
        "#   # plt.title('mask')\n",
        "#   # plt.imsave(f\"./{fname.split('.')[1]}_mask.png\",mask, cmap='gray')\n",
        "\n",
        "#   # plt.subplot(132)\n",
        "#   # img = np.array(plt.imread(f'{fname}')[:,:,:3])\n",
        "#   # plt.imshow(img)\n",
        "#   # plt.axis('off')\n",
        "#   # plt.title('img')\n",
        "\n",
        "#   # plt.subplot(133)\n",
        "#   # img = np.array((1-mask.reshape(mask.shape[0], mask.shape[1], -1))*plt.imread(fname)[:,:,:3])\n",
        "#   # _=plt.imshow(img)\n",
        "#   # _=plt.axis('off')\n",
        "#   # _=plt.title('img * mask')\n",
        "#   # plt.show()\n",
        "\n",
        "#   # os.makedirs('/content/output')\n",
        "\n",
        "#   print('Run inpainting')\n",
        "#   !echo $(pwd)\n",
        "#   if '.jpeg' in fname:\n",
        "#     !PYTHONPATH={root_path2} TORCH_HOME={root_path2} python3 {root_path2}/bin/predict.py model.path={root_path2}/big-lama indir={input_step2} outdir={output_step2} dataset.img_suffix=.jpeg > /dev/null\n",
        "#   elif '.jpg' in fname:\n",
        "#     !PYTHONPATH={root_path2} TORCH_HOME=$(pwd) python3 {root_path2}/bin/predict.py model.path={root_path2}/big-lama indir={input_step2}  outdir={output_step2}  dataset.img_suffix=.jpg   > /dev/null\n",
        "#   elif '.png' in fname:\n",
        "#     !PYTHONPATH={root_path2} TORCH_HOME={root_path2} python3 {root_path2}/bin/predict.py model.path={root_path2}/big-lama indir={input_step2}  outdir={output_step2}  dataset.img_suffix=.png > /dev/null\n",
        "#   else:\n",
        "#     print(f'Error: unknown suffix .{fname.split(\".\")[-1]} use [.png, .jpeg, .jpg]')\n",
        "\n",
        "#   plt.rcParams['figure.dpi'] = 200\n",
        "\n",
        "#   print(os.listdir(output_step2))\n",
        "\n",
        "# # plt.imshow(plt.imread(f\"/content/output/{fname.split('.')[1].split('/')[2]}_mask.png\"))\n",
        "# # _=plt.axis('off')\n",
        "# # _=plt.title('inpainting result')\n",
        "# # plt.show()\n",
        "\n",
        "# # fname = None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVknZ2QiAzSE"
      },
      "source": [
        "## Step 3: background removal\n",
        "\n",
        "Again, verify the outcome of step 2. \n",
        "\n",
        "Now we'll subtract the background using the PaddleSeg model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tAAAIFzIBD_Z",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "input_step3, output_step3 = create_io(database=nextcloud,topic=tname,library='step3_bg_removal', input_redirect=output_step2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "H2dRnK6VBMlj",
        "cellView": "form",
        "collapsed": true,
        "outputId": "f227f7b6-f565-46ed-b0d7-f634337090a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 108.4 MB 24 kB/s \n",
            "\u001b[?25hCloning into '/content/PaddleSeg'...\n",
            "remote: Enumerating objects: 17638, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "remote: Total 17638 (delta 53), reused 92 (delta 35), pack-reused 17518\u001b[K\n",
            "Receiving objects: 100% (17638/17638), 341.81 MiB | 34.13 MiB/s, done.\n",
            "Resolving deltas: 100% (11275/11275), done.\n",
            "/content/PaddleSeg\n",
            "/bin/bash: -c: line 0: unexpected EOF while looking for matching `''\n",
            "/bin/bash: -c: line 1: syntax error: unexpected end of file\n",
            "Obtaining file:///content/PaddleSeg\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (6.0)\n",
            "Collecting visualdl>=2.0.0\n",
            "  Downloading visualdl-2.2.3-py3-none-any.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (4.1.2.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (3.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (1.4.1)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (3.2.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (0.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (3.2.2)\n",
            "Requirement already satisfied: flask>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (1.1.4)\n",
            "Collecting bce-python-sdk\n",
            "  Downloading bce-python-sdk-0.8.64.tar.gz (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 50.7 MB/s \n",
            "\u001b[?25hCollecting Flask-Babel>=1.0.0\n",
            "  Downloading Flask_Babel-2.0.0-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: Pillow>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (2.23.0)\n",
            "Collecting flake8>=3.7.9\n",
            "  Downloading flake8-4.0.1-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.11.0 in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (3.17.3)\n",
            "Collecting pre-commit\n",
            "  Downloading pre_commit-2.18.1-py2.py3-none-any.whl (197 kB)\n",
            "\u001b[K     |████████████████████████████████| 197 kB 47.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (1.3.5)\n",
            "Collecting shellcheck-py\n",
            "  Downloading shellcheck_py-0.8.0.4-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 41.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (1.21.6)\n",
            "Collecting pyflakes<2.5.0,>=2.4.0\n",
            "  Downloading pyflakes-2.4.0-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting pycodestyle<2.9.0,>=2.8.0\n",
            "  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 903 kB/s \n",
            "\u001b[?25hCollecting importlib-metadata<4.3\n",
            "  Downloading importlib_metadata-4.2.0-py3-none-any.whl (16 kB)\n",
            "Collecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg==2.5.0) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg==2.5.0) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg==2.5.0) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg==2.5.0) (1.0.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddleseg==2.5.0) (2022.1)\n",
            "Requirement already satisfied: Babel>=2.3 in /usr/local/lib/python3.7/dist-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddleseg==2.5.0) (2.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl>=2.0.0->paddleseg==2.5.0) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl>=2.0.0->paddleseg==2.5.0) (4.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask>=1.1.1->visualdl>=2.0.0->paddleseg==2.5.0) (2.0.1)\n",
            "Collecting pycryptodome>=3.8.0\n",
            "  Downloading pycryptodome-3.14.1-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 42.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from bce-python-sdk->visualdl>=2.0.0->paddleseg==2.5.0) (0.18.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->visualdl>=2.0.0->paddleseg==2.5.0) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->visualdl>=2.0.0->paddleseg==2.5.0) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->visualdl>=2.0.0->paddleseg==2.5.0) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->visualdl>=2.0.0->paddleseg==2.5.0) (1.4.2)\n",
            "Collecting nodeenv>=0.11.1\n",
            "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
            "Collecting virtualenv>=20.0.8\n",
            "  Downloading virtualenv-20.14.1-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 38.4 MB/s \n",
            "\u001b[?25hCollecting cfgv>=2.0.0\n",
            "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting identify>=1.0.0\n",
            "  Downloading identify-2.5.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 52.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->paddleseg==2.5.0) (0.2.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddleseg==2.5.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddleseg==2.5.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddleseg==2.5.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddleseg==2.5.0) (2021.10.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->paddleseg==2.5.0) (0.24.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->paddleseg==2.5.0) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->paddleseg==2.5.0) (3.1.0)\n",
            "Building wheels for collected packages: bce-python-sdk\n",
            "  Building wheel for bce-python-sdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bce-python-sdk: filename=bce_python_sdk-0.8.64-py3-none-any.whl size=202973 sha256=e692748a7d23fa88c81818b1a8cc50139a3f021bd454eec5ea985fb4b472752c\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/ee/a5/4ad3bdc0e60b48e892e8bd6f661a3201d7e76dccfa9e968b34\n",
            "Successfully built bce-python-sdk\n",
            "Installing collected packages: platformdirs, importlib-metadata, distlib, virtualenv, toml, pyflakes, pycryptodome, pycodestyle, nodeenv, mccabe, identify, cfgv, shellcheck-py, pre-commit, Flask-Babel, flake8, bce-python-sdk, visualdl, paddleseg\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.11.3\n",
            "    Uninstalling importlib-metadata-4.11.3:\n",
            "      Successfully uninstalled importlib-metadata-4.11.3\n",
            "  Running setup.py develop for paddleseg\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 4.2.0 which is incompatible.\u001b[0m\n",
            "Successfully installed Flask-Babel-2.0.0 bce-python-sdk-0.8.64 cfgv-3.3.1 distlib-0.3.4 flake8-4.0.1 identify-2.5.0 importlib-metadata-4.2.0 mccabe-0.6.1 nodeenv-1.6.0 paddleseg-2.5.0 platformdirs-2.5.2 pre-commit-2.18.1 pycodestyle-2.8.0 pycryptodome-3.14.1 pyflakes-2.4.0 shellcheck-py-0.8.0.4 toml-0.10.2 virtualenv-20.14.1 visualdl-2.2.3\n",
            "/content/PaddleSeg/Matting\n",
            "\u001b[K     |████████████████████████████████| 60.3 MB 51 kB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#@title imports for paddleseg\n",
        "!pip install -q PaddlePaddle\n",
        "root_path = '/content/PaddleSeg'\n",
        "\n",
        "# clone the repository\n",
        "if not os.path.exists(root_path):\n",
        "  !git clone https://github.com/PaddlePaddle/PaddleSeg {root_path}\n",
        "\n",
        "%cd {root_path}\n",
        "!pip -qq install -r requirements.txt'\n",
        "!pip install -e .\n",
        "\n",
        "# installing Matting\n",
        "%cd Matting\n",
        "!pip -qq install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title downloading the models\n",
        "# download model checkpoint \n",
        "model_path = root_path + '/Matting/data/model'\n",
        "model_params = 'https://paddleseg.bj.bcebos.com/matting/models/human_matting-resnet34_vd.pdparams'\n",
        "model_inf = 'https://paddleseg.bj.bcebos.com/matting/models/deploy/pp-humanmatting-resnet34_vd.zip'\n",
        "# make folders\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "if not os.path.exists(os.path.join(model_path,'human_matting.pdparams')):\n",
        "  print('\\n> Download the model params')\n",
        "  !curl {model_params} -o {os.path.join(model_path,'human_matting.pdparams')}\n",
        "else:\n",
        "  print ('\\n> File already downloaded')\n",
        "if not os.path.exists(os.path.join(model_path,'human_matting-resnet.zip')):\n",
        "  print('\\n> Download the model')\n",
        "  !curl {model_inf} -o {os.path.join(model_path,'human_matting-resnet.zip')}\n",
        "  !unzip -q {os.path.join(model_path,'human_matting-resnet.zip')} -d {os.path.join(model_path)}\n",
        "else:\n",
        "  print ('\\n> File already downloaded')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MssU8gR4HWaV",
        "outputId": "5987cfff-9d71-44e3-c945-5224f900540f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "> Download the model params\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  243M  100  243M    0     0  5646k      0  0:00:44  0:00:44 --:--:-- 10.1M\n",
            "\n",
            "> Download the model\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  226M  100  226M    0     0  4410k      0  0:00:52  0:00:52 --:--:-- 10.9M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mode = 'bgremoval' #@param ['predict','bgremoval']\n",
        "if(mode=='predict'):\n",
        "# predict\n",
        "  !export CUDA_VISIBLE_DEVICES=0\n",
        "  !python predict.py \\\n",
        "      --config configs/human_matting/human_matting-resnet34_vd.yml \\\n",
        "      --model_path data/model/human_matting.pdparams \\\n",
        "      --image_path {input_step3} \\\n",
        "      --save_dir {output_step3} \\\n",
        "      --fg_estimate True\n",
        "else:\n",
        "  # bg replacement\n",
        "  #TODO right now all images get the same background image\n",
        "  #@markdown either choose an rgbw value as background or type the path to the bgimage:\n",
        "  background = '/content/bg.jpeg' #@param ['r','g','b','w'] {allow-input: true}\n",
        "  !export CUDA_VISIBLE_DEVICES=0\n",
        "  for infer_img in os.listdir(input_step3):\n",
        "    !python bg_replace.py \\\n",
        "        --config configs/human_matting/human_matting-resnet34_vd.yml \\\n",
        "        --model_path data/model/human_matting.pdparams \\\n",
        "        --image_path {os.path.join(input_step3,infer_img)} \\\n",
        "        --save_dir {output_step3} \\\n",
        "        --background {background} \\\n",
        "        --fg_estimate True\n"
      ],
      "metadata": {
        "id": "JOkHdhXjJZcV",
        "outputId": "39d505e5-2f63-4976-98d1-5d0e76709136",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/fft/__init__.py:97: DeprecationWarning: The module numpy.dual is deprecated.  Instead of using dual, use the functions directly from numpy or scipy.\n",
            "  from numpy.dual import register_func\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/special/orthogonal.py:81: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/data/__init__.py:107: DeprecationWarning: \n",
            "    Importing file_hash from pooch.utils is DEPRECATED. Please import from the\n",
            "    top-level namespace (`from pooch import file_hash`) instead, which is fully\n",
            "    backwards compatible with pooch >= 0.1.\n",
            "    \n",
            "  return file_hash(path) == expected_hash\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/types/__init__.py:108: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  long_ = _make_signed(np.long)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/types/__init__.py:109: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  ulong = _make_unsigned(np.long)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResNet18_vd exists already! It is now updated to <function ResNet18_vd at 0x7f9e0c7d78c0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResNet50_vd exists already! It is now updated to <function ResNet50_vd at 0x7f9e0c318320> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResNet101_vd exists already! It is now updated to <function ResNet101_vd at 0x7f9e0c318440> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: MobileNetV2 exists already! It is now updated to <function MobileNetV2 at 0x7f9e0c7d7dd0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W18_Small_V1 exists already! It is now updated to <function HRNet_W18_Small_V1 at 0x7f9e0c318b00> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W18_Small_V2 exists already! It is now updated to <function HRNet_W18_Small_V2 at 0x7f9e0c327560> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W18 exists already! It is now updated to <function HRNet_W18 at 0x7f9e0c3275f0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W30 exists already! It is now updated to <function HRNet_W30 at 0x7f9e0c327710> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W32 exists already! It is now updated to <function HRNet_W32 at 0x7f9e0c327830> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W40 exists already! It is now updated to <function HRNet_W40 at 0x7f9e0c327950> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W44 exists already! It is now updated to <function HRNet_W44 at 0x7f9e0c327a70> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W48 exists already! It is now updated to <function HRNet_W48 at 0x7f9e0c327b90> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W60 exists already! It is now updated to <function HRNet_W60 at 0x7f9e0c327cb0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W64 exists already! It is now updated to <function HRNet_W64 at 0x7f9e0c327dd0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: Compose exists already! It is now updated to <class 'transforms.Compose'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: Resize exists already! It is now updated to <class 'transforms.Resize'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResizeByLong exists already! It is now updated to <class 'transforms.ResizeByLong'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResizeByShort exists already! It is now updated to <class 'transforms.ResizeByShort'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: Normalize exists already! It is now updated to <class 'transforms.Normalize'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: LimitLong exists already! It is now updated to <class 'transforms.LimitLong'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: RandomHorizontalFlip exists already! It is now updated to <class 'transforms.RandomHorizontalFlip'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: RandomBlur exists already! It is now updated to <class 'transforms.RandomBlur'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: RandomDistort exists already! It is now updated to <class 'transforms.RandomDistort'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: Padding exists already! It is now updated to <class 'transforms.Padding'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: RandomNoise exists already! It is now updated to <class 'transforms.RandomNoise'> !!!\n",
            "  format(component_name, component))\n",
            "2022-05-03 12:27:08 [INFO]\t\n",
            "---------------Config Information---------------\n",
            "batch_size: 4\n",
            "iters: 50000\n",
            "lr_scheduler:\n",
            "  boundaries:\n",
            "  - 30000\n",
            "  - 40000\n",
            "  type: PiecewiseDecay\n",
            "  values:\n",
            "  - 0.001\n",
            "  - 0.0001\n",
            "  - 1.0e-05\n",
            "model:\n",
            "  backbone:\n",
            "    pretrained: https://paddleseg.bj.bcebos.com/matting/models/ResNet34_vd_pretrained/model.pdparams\n",
            "    type: ResNet34_vd\n",
            "  if_refine: true\n",
            "  pretrained: null\n",
            "  type: HumanMatting\n",
            "optimizer:\n",
            "  momentum: 0.9\n",
            "  type: sgd\n",
            "  weight_decay: 4.0e-05\n",
            "train_dataset:\n",
            "  dataset_root: data/PPM-100\n",
            "  mode: train\n",
            "  train_file: train.txt\n",
            "  transforms:\n",
            "  - type: LoadImages\n",
            "  - scale:\n",
            "    - 0.3\n",
            "    - 1.5\n",
            "    size:\n",
            "    - 2048\n",
            "    - 2048\n",
            "    type: RandomResize\n",
            "  - crop_size:\n",
            "    - 2048\n",
            "    - 2048\n",
            "    type: RandomCrop\n",
            "  - type: RandomDistort\n",
            "  - prob: 0.1\n",
            "    type: RandomBlur\n",
            "  - type: RandomHorizontalFlip\n",
            "  - target_size:\n",
            "    - 2048\n",
            "    - 2048\n",
            "    type: Padding\n",
            "  - type: Normalize\n",
            "  type: MattingDataset\n",
            "val_dataset:\n",
            "  dataset_root: data/PPM-100\n",
            "  get_trimap: false\n",
            "  mode: val\n",
            "  transforms:\n",
            "  - type: LoadImages\n",
            "  - short_size: 2048\n",
            "    type: ResizeByShort\n",
            "  - mult_int: 128\n",
            "    type: ResizeToIntMult\n",
            "  - type: Normalize\n",
            "  type: MattingDataset\n",
            "  val_file: val.txt\n",
            "------------------------------------------------\n",
            "/content/PaddleSeg/paddleseg/cvlibs/config.py:332: UserWarning: `dataset_root` is not found. Is it correct?\n",
            "  warnings.warn(\"`dataset_root` is not found. Is it correct?\")\n",
            "2022-05-03 12:27:09 [INFO]\tLoading pretrained model from https://paddleseg.bj.bcebos.com/matting/models/ResNet34_vd_pretrained/model.pdparams\n",
            "2022-05-03 12:27:10 [INFO]\tThere are 195/195 variables loaded into ResNet_vd.\n",
            "2022-05-03 12:27:11 [INFO]\tLoading pretrained model from data/model/human_matting.pdparams\n",
            "2022-05-03 12:27:12 [INFO]\tThere are 486/486 variables loaded into HumanMatting.\n",
            "2022-05-03 12:27:12 [INFO]\tStart to predict...\n",
            "tcmalloc: large alloc 2130329600 bytes == 0x7c25c000 @  0x7f9e48841b6b 0x7f9e48861379 0x7f9e2f8c2d8c 0x7f9e2f8c4967 0x7f9e2f8baaa3 0x7f9e2f8bb700 0x7f9e2f8adb91 0x7f9e2f8ae8f8 0x7f9e2f8a6bdb 0x7f9e2f8a64fc 0x7f9e2bf37e40 0x7f9e2d6088dc 0x7f9e2d61b4ff 0x7f9e2d61bf40 0x7f9e2f65ddeb 0x7f9e2f65e31d 0x7f9e2bee325d 0x7f9e2beed55b 0x7f9e2beee050 0x7f9e2bc46c0d 0x517553 0x549576 0x593fce 0x548ae9 0x5127f1 0x4bc98a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bcb19\n",
            "tcmalloc: large alloc 1306648576 bytes == 0x95834000 @  0x7f9e48841b6b 0x7f9e48861379 0x7f9e2f8c2d8c 0x7f9e2f8c4967 0x7f9e2f8baaa3 0x7f9e2f8bb700 0x7f9e2f8adb91 0x7f9e2f8ae8f8 0x7f9e2f8a6bdb 0x7f9e2f8a64fc 0x7f9e2bf37e40 0x7f9e2d6088dc 0x7f9e2d61b4ff 0x7f9e2d61bf40 0x7f9e2f65ddeb 0x7f9e2f65e31d 0x7f9e2bee325d 0x7f9e2beed55b 0x7f9e2beee050 0x7f9e2bc46c0d 0x517553 0x549576 0x593fce 0x548ae9 0x5127f1 0x4bc98a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bcb19\n",
            "tcmalloc: large alloc 4130881536 bytes == 0xb0ea8000 @  0x7f9e48841b6b 0x7f9e48861379 0x7f9e2f8c2d8c 0x7f9e2f8c4967 0x7f9e2f8baaa3 0x7f9e2f8bb700 0x7f9e2f8adb91 0x7f9e2f8ae8f8 0x7f9e2f8a6bdb 0x7f9e2f8a64fc 0x7f9e2bf37e40 0x7f9e2d6088dc 0x7f9e2d61b4ff 0x7f9e2d61bf40 0x7f9e2f65ddeb 0x7f9e2f65e31d 0x7f9e2bee325d 0x7f9e2beed55b 0x7f9e2beee050 0x7f9e2bc46c0d 0x517553 0x549576 0x593fce 0x548ae9 0x5127f1 0x4bc98a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bcb19\n",
            "tcmalloc: large alloc 2604670976 bytes == 0x95834000 @  0x7f9e48841b6b 0x7f9e48861379 0x7f9e2f8c2d8c 0x7f9e2f8c4967 0x7f9e2f8baaa3 0x7f9e2f8bb700 0x7f9e2f8adb91 0x7f9e2f8ae8f8 0x7f9e2f8a6bdb 0x7f9e2f8a64fc 0x7f9e2bf37e40 0x7f9e2d6088dc 0x7f9e2d61b4ff 0x7f9e2d61bf40 0x7f9e2f65ddeb 0x7f9e2f65e31d 0x7f9e2bee325d 0x7f9e2beed55b 0x7f9e2beee050 0x7f9e2bc46c0d 0x517553 0x549576 0x593fce 0x548ae9 0x5127f1 0x4bc98a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bcb19\n",
            "1/1 [==============================] - 27s 27s/step - preprocess_cost: 1.6874 - infer_cost cost: 21.6203 - postprocess_cost: 4.0247\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/fft/__init__.py:97: DeprecationWarning: The module numpy.dual is deprecated.  Instead of using dual, use the functions directly from numpy or scipy.\n",
            "  from numpy.dual import register_func\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/special/orthogonal.py:81: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/data/__init__.py:107: DeprecationWarning: \n",
            "    Importing file_hash from pooch.utils is DEPRECATED. Please import from the\n",
            "    top-level namespace (`from pooch import file_hash`) instead, which is fully\n",
            "    backwards compatible with pooch >= 0.1.\n",
            "    \n",
            "  return file_hash(path) == expected_hash\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/types/__init__.py:108: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  long_ = _make_signed(np.long)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/types/__init__.py:109: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  ulong = _make_unsigned(np.long)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResNet18_vd exists already! It is now updated to <function ResNet18_vd at 0x7f5cdd7c48c0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResNet50_vd exists already! It is now updated to <function ResNet50_vd at 0x7f5cdd305320> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResNet101_vd exists already! It is now updated to <function ResNet101_vd at 0x7f5cdd305440> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: MobileNetV2 exists already! It is now updated to <function MobileNetV2 at 0x7f5cdd7c4dd0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W18_Small_V1 exists already! It is now updated to <function HRNet_W18_Small_V1 at 0x7f5cdd305b00> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W18_Small_V2 exists already! It is now updated to <function HRNet_W18_Small_V2 at 0x7f5cdd314560> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W18 exists already! It is now updated to <function HRNet_W18 at 0x7f5cdd3145f0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W30 exists already! It is now updated to <function HRNet_W30 at 0x7f5cdd314710> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W32 exists already! It is now updated to <function HRNet_W32 at 0x7f5cdd314830> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W40 exists already! It is now updated to <function HRNet_W40 at 0x7f5cdd314950> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W44 exists already! It is now updated to <function HRNet_W44 at 0x7f5cdd314a70> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W48 exists already! It is now updated to <function HRNet_W48 at 0x7f5cdd314b90> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W60 exists already! It is now updated to <function HRNet_W60 at 0x7f5cdd314cb0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W64 exists already! It is now updated to <function HRNet_W64 at 0x7f5cdd314dd0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: Compose exists already! It is now updated to <class 'transforms.Compose'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: Resize exists already! It is now updated to <class 'transforms.Resize'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResizeByLong exists already! It is now updated to <class 'transforms.ResizeByLong'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResizeByShort exists already! It is now updated to <class 'transforms.ResizeByShort'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: Normalize exists already! It is now updated to <class 'transforms.Normalize'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: LimitLong exists already! It is now updated to <class 'transforms.LimitLong'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: RandomHorizontalFlip exists already! It is now updated to <class 'transforms.RandomHorizontalFlip'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: RandomBlur exists already! It is now updated to <class 'transforms.RandomBlur'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: RandomDistort exists already! It is now updated to <class 'transforms.RandomDistort'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: Padding exists already! It is now updated to <class 'transforms.Padding'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: RandomNoise exists already! It is now updated to <class 'transforms.RandomNoise'> !!!\n",
            "  format(component_name, component))\n",
            "2022-05-03 12:27:43 [INFO]\t\n",
            "---------------Config Information---------------\n",
            "batch_size: 4\n",
            "iters: 50000\n",
            "lr_scheduler:\n",
            "  boundaries:\n",
            "  - 30000\n",
            "  - 40000\n",
            "  type: PiecewiseDecay\n",
            "  values:\n",
            "  - 0.001\n",
            "  - 0.0001\n",
            "  - 1.0e-05\n",
            "model:\n",
            "  backbone:\n",
            "    pretrained: https://paddleseg.bj.bcebos.com/matting/models/ResNet34_vd_pretrained/model.pdparams\n",
            "    type: ResNet34_vd\n",
            "  if_refine: true\n",
            "  pretrained: null\n",
            "  type: HumanMatting\n",
            "optimizer:\n",
            "  momentum: 0.9\n",
            "  type: sgd\n",
            "  weight_decay: 4.0e-05\n",
            "train_dataset:\n",
            "  dataset_root: data/PPM-100\n",
            "  mode: train\n",
            "  train_file: train.txt\n",
            "  transforms:\n",
            "  - type: LoadImages\n",
            "  - scale:\n",
            "    - 0.3\n",
            "    - 1.5\n",
            "    size:\n",
            "    - 2048\n",
            "    - 2048\n",
            "    type: RandomResize\n",
            "  - crop_size:\n",
            "    - 2048\n",
            "    - 2048\n",
            "    type: RandomCrop\n",
            "  - type: RandomDistort\n",
            "  - prob: 0.1\n",
            "    type: RandomBlur\n",
            "  - type: RandomHorizontalFlip\n",
            "  - target_size:\n",
            "    - 2048\n",
            "    - 2048\n",
            "    type: Padding\n",
            "  - type: Normalize\n",
            "  type: MattingDataset\n",
            "val_dataset:\n",
            "  dataset_root: data/PPM-100\n",
            "  get_trimap: false\n",
            "  mode: val\n",
            "  transforms:\n",
            "  - type: LoadImages\n",
            "  - short_size: 2048\n",
            "    type: ResizeByShort\n",
            "  - mult_int: 128\n",
            "    type: ResizeToIntMult\n",
            "  - type: Normalize\n",
            "  type: MattingDataset\n",
            "  val_file: val.txt\n",
            "------------------------------------------------\n",
            "/content/PaddleSeg/paddleseg/cvlibs/config.py:332: UserWarning: `dataset_root` is not found. Is it correct?\n",
            "  warnings.warn(\"`dataset_root` is not found. Is it correct?\")\n",
            "2022-05-03 12:27:44 [INFO]\tLoading pretrained model from https://paddleseg.bj.bcebos.com/matting/models/ResNet34_vd_pretrained/model.pdparams\n",
            "2022-05-03 12:27:44 [INFO]\tThere are 195/195 variables loaded into ResNet_vd.\n",
            "2022-05-03 12:27:46 [INFO]\tLoading pretrained model from data/model/human_matting.pdparams\n",
            "2022-05-03 12:27:46 [INFO]\tThere are 486/486 variables loaded into HumanMatting.\n",
            "2022-05-03 12:27:46 [INFO]\tStart to predict...\n",
            "tcmalloc: large alloc 2130329600 bytes == 0x7ab6e000 @  0x7f5d1982eb6b 0x7f5d1984e379 0x7f5d008afd8c 0x7f5d008b1967 0x7f5d008a7aa3 0x7f5d008a8700 0x7f5d0089ab91 0x7f5d0089b8f8 0x7f5d00893bdb 0x7f5d008934fc 0x7f5cfcf24e40 0x7f5cfe5f58dc 0x7f5cfe6084ff 0x7f5cfe608f40 0x7f5d0064adeb 0x7f5d0064b31d 0x7f5cfced025d 0x7f5cfceda55b 0x7f5cfcedb050 0x7f5cfcc33c0d 0x517553 0x549576 0x593fce 0x548ae9 0x5127f1 0x4bc98a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bcb19\n",
            "tcmalloc: large alloc 1306648576 bytes == 0x94146000 @  0x7f5d1982eb6b 0x7f5d1984e379 0x7f5d008afd8c 0x7f5d008b1967 0x7f5d008a7aa3 0x7f5d008a8700 0x7f5d0089ab91 0x7f5d0089b8f8 0x7f5d00893bdb 0x7f5d008934fc 0x7f5cfcf24e40 0x7f5cfe5f58dc 0x7f5cfe6084ff 0x7f5cfe608f40 0x7f5d0064adeb 0x7f5d0064b31d 0x7f5cfced025d 0x7f5cfceda55b 0x7f5cfcedb050 0x7f5cfcc33c0d 0x517553 0x549576 0x593fce 0x548ae9 0x5127f1 0x4bc98a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bcb19\n",
            "tcmalloc: large alloc 4130881536 bytes == 0xaf7ba000 @  0x7f5d1982eb6b 0x7f5d1984e379 0x7f5d008afd8c 0x7f5d008b1967 0x7f5d008a7aa3 0x7f5d008a8700 0x7f5d0089ab91 0x7f5d0089b8f8 0x7f5d00893bdb 0x7f5d008934fc 0x7f5cfcf24e40 0x7f5cfe5f58dc 0x7f5cfe6084ff 0x7f5cfe608f40 0x7f5d0064adeb 0x7f5d0064b31d 0x7f5cfced025d 0x7f5cfceda55b 0x7f5cfcedb050 0x7f5cfcc33c0d 0x517553 0x549576 0x593fce 0x548ae9 0x5127f1 0x4bc98a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bcb19\n",
            "tcmalloc: large alloc 2604670976 bytes == 0x94146000 @  0x7f5d1982eb6b 0x7f5d1984e379 0x7f5d008afd8c 0x7f5d008b1967 0x7f5d008a7aa3 0x7f5d008a8700 0x7f5d0089ab91 0x7f5d0089b8f8 0x7f5d00893bdb 0x7f5d008934fc 0x7f5cfcf24e40 0x7f5cfe5f58dc 0x7f5cfe6084ff 0x7f5cfe608f40 0x7f5d0064adeb 0x7f5d0064b31d 0x7f5cfced025d 0x7f5cfceda55b 0x7f5cfcedb050 0x7f5cfcc33c0d 0x517553 0x549576 0x593fce 0x548ae9 0x5127f1 0x4bc98a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bcb19\n",
            "1/1 [==============================] - 27s 27s/step - preprocess_cost: 1.7279 - infer_cost cost: 22.2624 - postprocess_cost: 3.1254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHvEogQSBfUh"
      },
      "source": [
        "## Step 4: Clothes recoloring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WFRDNlwvICRl"
      },
      "outputs": [],
      "source": [
        "input_step4, output_step4 = create_io(database=nextcloud,topic=tname,library='step4_clothes_coloring', input_redirect=output_step3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-ypRPB6yICRl"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "# as we're not implementing clothes recoloring yet, we copy the folders to surpass this step\n",
        "for file in os.listdir(input_step4):\n",
        "  shutil.copy2(os.path.join(input_step4, file), output_step4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jIiSGm6ICRl"
      },
      "source": [
        "## Step 5: Skin retouching\n",
        "\n",
        "we'll implement the retouchML library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "I2tQDXn-ICRm",
        "outputId": "e34ec80d-6fa0-43a0-c046-c2e0213fe140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e74589c2d5e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_step6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_step6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnextcloud\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'step6_skin_retouch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_redirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_step5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'output_step5' is not defined"
          ]
        }
      ],
      "source": [
        "input_step5, output_step5 = create_io(database=nextcloud,topic=tname,library='step5_skin_retouch', input_redirect=output_step4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddpvlvl6ICRm"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ceij8_mpICRm"
      },
      "source": [
        "## Step 6: Color Corrections\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb06tfujICRm"
      },
      "outputs": [],
      "source": [
        "input_step6, output_step6 = create_io(database=nextcloud,topic=tname,library='step6_color_corrections', input_redirect=output_step5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_epn_TzNICRn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gHgBX7oICRn"
      },
      "source": [
        "## Step 7: Color Grading\n",
        "\n",
        "we're implementing the deep preset library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "TDoSTIKlICRn",
        "outputId": "464ef3b0-24be-461e-b9af-abd22a5a7ef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-f941a35cafba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_step7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_step7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnextcloud\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'step7_color_grading'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_redirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_step6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'output_step6' is not defined"
          ]
        }
      ],
      "source": [
        "input_step7, output_step7 = create_io(database=nextcloud,topic=tname,library='step7_color_grading', input_redirect=output_step6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3_e2_XYICRn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCYexnqCICRn"
      },
      "source": [
        "## Step 8: image upscaling\n",
        "\n",
        "This is to be implemented **if** necessary?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmzznyJ8ICRo"
      },
      "outputs": [],
      "source": [
        "input_step8, output_step8 = create_io(database=nextcloud,topic=tname,library='step8_image_upscaling', input_redirect=output_step7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQsy0whPICRo"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled12.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}