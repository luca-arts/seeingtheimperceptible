{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luca-arts/seeingtheimperceptible/blob/main/notebooks/total_flow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auv1_Ky6GZlc"
      },
      "source": [
        "# Visualising the imperceptible: total flow\n",
        "\n",
        "this is a notebook which is used to have a set of images move through the processing steps which can individually be found in the topic related folders.\n",
        "\n",
        "A **batch** of images will be processed and all intermediate steps will be saved. This is not an optimized flow, yet a flow allowing the user to intervene where necessary and have updated images continue throughout the flow.\n",
        "\n",
        "This flow is created to test with some experts and capture their feedback, it is not intended for day-to-day usage. One testing day will be organized in which this notebook will be used with some unique images.\n",
        "\n",
        "## steps\n",
        "\n",
        "1. Sensor dust removal\n",
        "2. Image Editing (LaMa)\n",
        "3. Background Removal\n",
        "4. Background Recoloring: not yet\n",
        "5. Clothes recoloring: not yet\n",
        "6. Skin retouching\n",
        "<!-- 7. Face Detection -->\n",
        "7. optional: Color Corrections: not yet\n",
        "8. Color Grading: \n",
        "9. Image upscaling\n",
        "\n",
        "TODO: is it necessary to create a config file and have separate notebooks for each step? (with 1 common config generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJs-y9foTOs3",
        "outputId": "412b642d-c734-469b-d20b-82a73ac120e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May 25 13:56:53 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrpFLD9BGU3q",
        "outputId": "758919e8-2a59-486f-d7dc-4fcdf4f2d332"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what's the username for nextcloud? colab\n",
            "what's the password for user colab? ··········\n",
            "0\n",
            "Please enter the username to authenticate with server\n",
            "https://cloud.bxlab.net/remote.php/dav/files/colab/colabfiles/ or hit enter for none.\n",
            "  Username: Please enter the password to authenticate user colab with server\n",
            "https://cloud.bxlab.net/remote.php/dav/files/colab/colabfiles/ or hit enter for none.\n",
            "  Password:  \n"
          ]
        }
      ],
      "source": [
        "# first we'll link a database connection:\n",
        "!curl https://raw.githubusercontent.com/luca-arts/seeingtheimperceptible/main/notebooks/database_mod.py -o /content/database_mod.py --silent\n",
        "from database_mod import *\n",
        "\n",
        "link_nextcloud()\n",
        "\n",
        "nextcloud = '/content/database/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv-3JoWpICRe"
      },
      "source": [
        "## SETUP\n",
        "\n",
        "we'll link this instance of the machine learning flow to your name:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "4PpvzPCmICRe",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title setting up the next cloud folders\n",
        "tname = 'lieven' #@param {type:\"string\"}\n",
        "if(tname=='total'):\n",
        "    print(\"Are you sure you don't want to change the name?\")\n",
        "\n",
        "# make input dynamic with tname\n",
        "#input_tname = '/content/database/' + tname + '/input'\n",
        "input_step1, output_step1 = create_io(database=nextcloud,topic=tname,library='step1_sensor_dust', input_redirect='/content/database/total/input')\n",
        "input_step2, output_step2 = create_io(database=nextcloud,topic=tname,library='step2_lama', input_redirect=output_step1)\n",
        "input_step3, output_step3 = create_io(database=nextcloud,topic=tname,library='step3_bg_removal', input_redirect=output_step2)\n",
        "input_step4, output_step4 = create_io(database=nextcloud,topic=tname,library='step4_clothes_coloring', input_redirect=output_step3)\n",
        "input_step5, output_step5 = create_io(database=nextcloud,topic=tname,library='step5_skin_retouch', input_redirect=output_step4)\n",
        "input_step6, output_step6 = create_io(database=nextcloud,topic=tname,library='step6_color_corrections', input_redirect=output_step5)\n",
        "input_step7, output_step7 = create_io(database=nextcloud,topic=tname,library='step7_color_grading', input_redirect=output_step6)\n",
        "input_step8, output_step8 = create_io(database=nextcloud,topic=tname,library='step8_image_upscaling', input_redirect=output_step7)\n",
        "input_step9, output_step9 = create_io(database=nextcloud,topic=tname,library='step9_noise_addition', input_redirect=output_step8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB5-jsXmItCP"
      },
      "source": [
        "## Step 1: Sensor dust removal\n",
        "\n",
        "we'll link the main input folder and write the output images in the output folder of step 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gvKTWPdHkHN",
        "outputId": "41b2d096-4c9e-44b4-91a6-3c7455938a8d",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1255  100  1255    0     0  12303      0 --:--:-- --:--:-- --:--:-- 12303\n"
          ]
        }
      ],
      "source": [
        "#@title imports of libraries & setting up\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import os, sys\n",
        "!curl https://raw.githubusercontent.com/Tschucker/Python-Automatic-Sensor-Dust-Removal/main/shapedetector.py -o /content/shapedetector.py\n",
        "module_path = os.path.abspath(os.path.join('.'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "from shapedetector import ShapeDetector\n",
        "import imutils\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UWZFZUVI36H",
        "outputId": "75d5cec3-9c96-42bc-9870-f3109a44f56d",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing  01.jpg\n",
            "processing  02.jpg\n",
            "processing  03.jpg\n",
            "processing  04.jpg\n",
            "processing  05.jpg\n",
            "processing  06.jpg\n",
            "processing  07.jpg\n",
            "processing  08.jpg\n",
            "processing  09.jpg\n",
            "processing  10.jpg\n"
          ]
        }
      ],
      "source": [
        "#@title Set inpainting options and run the model\n",
        "radius = 11 #@param {type:\"slider\",min:1, max:50}\n",
        "flags = cv2.INPAINT_TELEA #@param [\"cv2.INPAINT_TELEA\",\"cv2.INPAINT_NS\"]\n",
        "\n",
        "def inpaint_img(img_path, img_name, output_path, radius=10, flags=cv2.INPAINT_TELEA):\n",
        "  #color version\n",
        "  cimg = cv2.imread(img_path)\n",
        "  #grey scale image\n",
        "  img = cv2.imread(img_path,0)\n",
        "\n",
        "  #Apply Global Threshold\n",
        "  m = np.mean(img, dtype=int)\n",
        "  global_thresh = cv2.threshold(img,int(m/1.2),255,cv2.THRESH_BINARY_INV)[1]\n",
        "\n",
        "  #Perform Adaptive Threshold\n",
        "  adaptive_thresh_img = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY_INV,19,10)\n",
        "\n",
        "  #Image Magnification Filter Kernel\n",
        "  KERNEL = np.ones((10,10), dtype=int)*10\n",
        "\n",
        "  #Filter the thresholded images*\n",
        "  img_filt = cv2.filter2D(adaptive_thresh_img,-1,KERNEL)\n",
        "  #global_thresh = cv2.filter2D(global_thresh,-1,KERNEL)\n",
        "\n",
        "  #Apply multiple times\n",
        "  for i in range(2):\n",
        "      KERNEL_i = np.ones((int(10),int(10)), dtype=int)*10\n",
        "      img_filt = cv2.filter2D(img_filt,-1,KERNEL_i)\n",
        "\n",
        "  #Combine Thresholds\n",
        "  comb = img_filt + global_thresh\n",
        "\n",
        "  #Find and Classify Contours of Image\n",
        "  cnts = cv2.findContours(comb.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cnts = imutils.grab_contours(cnts)\n",
        "  sd = ShapeDetector()\n",
        "  cimg_copy = cimg.copy()\n",
        "  for c in cnts:\n",
        "      # compute the center of the contour, then detect the name of the\n",
        "      # shape using only the contour\n",
        "      M = cv2.moments(c)\n",
        "      if M[\"m00\"] != 0:\n",
        "          cX = int((M[\"m10\"] / M[\"m00\"]) * 1)\n",
        "          cY = int((M[\"m01\"] / M[\"m00\"]) * 1)\n",
        "          shape = sd.detect(c)\n",
        "          # multiply the contour (x, y)-coordinates by the resize ratio,\n",
        "          # then draw the contours and the name of the shape on the image\n",
        "          if len(c) < 50:\n",
        "              c = c.astype(\"float\")\n",
        "              c *= 1\n",
        "              c = c.astype(\"int\")\n",
        "              cv2.drawContours(cimg_copy, [c], -1, (0, 255, 0), 2)\n",
        "              cv2.putText(cimg_copy, shape, (cX, cY), cv2.FONT_HERSHEY_SIMPLEX,0.5, (255, 255, 255), 2)\n",
        "  \n",
        "  #Create Dust Mask\n",
        "  img_mask = np.zeros((img.shape[0], img.shape[1]), dtype='uint8')\n",
        "  for c in cnts:\n",
        "      # compute the center of the contour, then detect the name of the\n",
        "      # shape using only the contour\n",
        "      M = cv2.moments(c)\n",
        "      if M[\"m00\"] != 0:\n",
        "          cX = int((M[\"m10\"] / M[\"m00\"]) * 1)\n",
        "          cY = int((M[\"m01\"] / M[\"m00\"]) * 1)\n",
        "          shape = sd.detect(c)\n",
        "          # multiply the contour (x, y)-coordinates by the resize ratio,\n",
        "          # then draw the contours and the name of the shape on the image\n",
        "          if len(c) < 50:\n",
        "              c = c.astype(\"float\")\n",
        "              c *= 1\n",
        "              c = c.astype(\"int\")\n",
        "              cv2.fillPoly(img_mask, pts=[c], color=(255,255,255))\n",
        "\n",
        "    \n",
        "  #Inpaint the image\n",
        "  cimg_inpaint = cv2.inpaint(cimg, img_mask, radius, flags=flags)\n",
        "\n",
        "  #Show and Save Final Image\n",
        "  save_img_pth = os.path.join(output_path,img_name)\n",
        "  cv2.imwrite(save_img_pth, cimg_inpaint)\n",
        "\n",
        "  # plt_out = cv2.cvtColor(cimg_inpaint, cv2.COLOR_BGR2RGB)\n",
        "  # return plt_out\n",
        "\n",
        "for img_name in os.listdir(input_step1):\n",
        "  print(\"processing \",img_name)\n",
        "  img_path = os.path.join(input_step1,img_name)\n",
        "  inpaint_img(img_path, img_name, output_step1, radius=radius, flags=flags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfTsfHmAI6R4"
      },
      "source": [
        "### verification\n",
        "\n",
        "Now it's time to go to the database and verify the results. If needed we adapt the images locally. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0UVWDfIJmUS"
      },
      "source": [
        "## step 2: Minor retouching: image editing LaMa \n",
        "Once verified we want to continue with the next step, being image editing (LaMa model)\n",
        "\n",
        "therefore we link the output folder of previous step to the inputfolder of this step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRUbNHttJb3l",
        "outputId": "ec4f3e55-1cdc-47b9-d0ba-29a2fcc79d61",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/lama'...\n",
            "remote: Enumerating objects: 319, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)\u001b[K\rremote: Counting objects:  66% (2/3)\u001b[K\rremote: Counting objects: 100% (3/3)\u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 319 (delta 0), reused 0 (delta 0), pack-reused 316\u001b[K\n",
            "Receiving objects: 100% (319/319), 6.52 MiB | 34.40 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n",
            "\n",
            "> Install dependencies\n",
            "\u001b[K     |████████████████████████████████| 12.5 MB 29.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 72 kB 739 kB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 74.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 841 kB 56.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 73.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 948 kB 65.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 79.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 52.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 71.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 176 kB 73.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 70.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 56.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 70.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 74.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 75.6 MB/s \n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 20.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 735.5 MB 14 kB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.8.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.8.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 25.1 MB/s \n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\n",
            "> Download the model\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  363M    0  363M    0     0   9.8M      0 --:--:--  0:00:36 --:--:-- 10.3M\n",
            "Archive:  /content/lama/big-lama.zip\n",
            "  inflating: /content/lama/big-lama/config.yaml  \n",
            "  inflating: /content/lama/big-lama/models/best.ckpt  \n",
            ">fixing opencv\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 1.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#@title imports of libraries & setting up\n",
        "root_path2 = '/content/lama'\n",
        "\n",
        "# clone the repository\n",
        "if not os.path.exists(root_path2):\n",
        "  !git clone https://github.com/saic-mdal/lama {root_path2}\n",
        "# Set up the environment\n",
        "print('\\n> Install dependencies')\n",
        "!pip install -q -r lama/requirements.txt \n",
        "!pip install torch==1.8.1\n",
        "!pip install torchtext==0.9.0 --quiet \n",
        "!pip install torchvision==0.9.0 --quiet \n",
        "!pip install -q wget \n",
        "\n",
        "# download the model\n",
        "print('\\n> Download the model')\n",
        "!curl -L $(yadisk-direct https://disk.yandex.ru/d/ouP6l8VJ0HpMZg) -o {root_path2}/big-lama.zip\n",
        "# todo check where the model is unzipped\n",
        "!unzip {root_path2}/big-lama.zip -d {root_path2}\n",
        "# fixing openCV\n",
        "print('>fixing opencv')\n",
        "!pip uninstall -q opencv-python-headless -y \n",
        "!pip install -q opencv-python-headless==4.1.2.30 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "iG3cZFNfL-NZ"
      },
      "outputs": [],
      "source": [
        "#@title imports & helper functions\n",
        "\n",
        "import base64, os\n",
        "from IPython.display import HTML, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import wget\n",
        "from shutil import copyfile\n",
        "import shutil\n",
        "\n",
        "canvas_html = \"\"\"\n",
        "<style>\n",
        ".button {\n",
        "  background-color: #4CAF50;\n",
        "  border: none;\n",
        "  color: white;\n",
        "  position: absolute;\n",
        "  padding: 15px 25px;\n",
        "  text-align: center;\n",
        "  text-decoration: none;\n",
        "  display: inline-block;\n",
        "  font-size: 16px;\n",
        "  margin: 4px 2px;\n",
        "  cursor: pointer;\n",
        "}\n",
        "</style>\n",
        "<canvas1 width=%d height=%d>\n",
        "</canvas1>\n",
        "<canvas width=%d height=%d>\n",
        "</canvas>\n",
        "\n",
        "<button class=\"button\">Finish</button>\n",
        "<script>\n",
        "var canvas = document.querySelector('canvas')\n",
        "var ctx = canvas.getContext('2d')\n",
        "\n",
        "var canvas1 = document.querySelector('canvas1')\n",
        "var ctx1 = canvas.getContext('2d')\n",
        "\n",
        "\n",
        "ctx.strokeStyle = 'red';\n",
        "\n",
        "var img = new Image();\n",
        "img.src = \"data:image/%s;charset=utf-8;base64,%s\";\n",
        "console.log(img)\n",
        "img.onload = function() {\n",
        "  ctx1.drawImage(img, 0, 0);\n",
        "};\n",
        "img.crossOrigin = 'Anonymous';\n",
        "\n",
        "ctx.clearRect(0, 0, canvas.width, canvas.height);\n",
        "\n",
        "ctx.lineWidth = %d\n",
        "var button = document.querySelector('button')\n",
        "var mouse = {x: 0, y: 0}\n",
        "\n",
        "canvas.addEventListener('mousemove', function(e) {\n",
        "  mouse.x = e.pageX - this.offsetLeft\n",
        "  mouse.y = e.pageY - this.offsetTop\n",
        "})\n",
        "canvas.onmousedown = ()=>{\n",
        "  ctx.beginPath()\n",
        "  ctx.moveTo(mouse.x, mouse.y)\n",
        "  canvas.addEventListener('mousemove', onPaint)\n",
        "}\n",
        "canvas.onmouseup = ()=>{\n",
        "  canvas.removeEventListener('mousemove', onPaint)\n",
        "}\n",
        "var onPaint = ()=>{\n",
        "  ctx.lineTo(mouse.x, mouse.y)\n",
        "  ctx.stroke()\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "  button.onclick = ()=>{\n",
        "    resolve(canvas.toDataURL('image/png'))\n",
        "    button.remove()\n",
        "    canvas.remove()\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def draw(imgm, filename='drawing.png', w=400, h=200, line_width=1):\n",
        "  display(HTML(canvas_html % (w, h, w,h, filename.split('.')[-1], imgm, line_width)))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "\n",
        "\n",
        "step2_temp = '/content/database/{}/step2temp'.format(tname)\n",
        "\n",
        "os.makedirs(step2_temp,exist_ok=True)\n",
        "\n",
        "for i in os.listdir(input_step2):\n",
        "  shutil.copy2(os.path.join(input_step2,i),step2_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minor Retouching via LaMa"
      ],
      "metadata": {
        "id": "Ki2KX6d0PNpZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "ZdwoEd9bqytl",
        "outputId": "3fbd0d05-95ac-4740-951e-cbfa6dbd4592",
        "cellView": "form",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lama\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              ".button {\n",
              "  background-color: #4CAF50;\n",
              "  border: none;\n",
              "  color: white;\n",
              "  position: absolute;\n",
              "  padding: 15px 25px;\n",
              "  text-align: center;\n",
              "  text-decoration: none;\n",
              "  display: inline-block;\n",
              "  font-size: 16px;\n",
              "  margin: 4px 2px;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<canvas1 width=400 height=592>\n",
              "</canvas1>\n",
              "<canvas width=400 height=592>\n",
              "</canvas>\n",
              "\n",
              "<button class=\"button\">Finish</button>\n",
              "<script>\n",
              "var canvas = document.querySelector('canvas')\n",
              "var ctx = canvas.getContext('2d')\n",
              "\n",
              "var canvas1 = document.querySelector('canvas1')\n",
              "var ctx1 = canvas.getContext('2d')\n",
              "\n",
              "\n",
              "ctx.strokeStyle = 'red';\n",
              "\n",
              "var img = new Image();\n",
              "img.src = \"data:image/png;charset=utf-8;base64,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\";\n",
              "console.log(img)\n",
              "img.onload = function() {\n",
              "  ctx1.drawImage(img, 0, 0);\n",
              "};\n",
              "img.crossOrigin = 'Anonymous';\n",
              "\n",
              "ctx.clearRect(0, 0, canvas.width, canvas.height);\n",
              "\n",
              "ctx.lineWidth = 16\n",
              "var button = document.querySelector('button')\n",
              "var mouse = {x: 0, y: 0}\n",
              "\n",
              "canvas.addEventListener('mousemove', function(e) {\n",
              "  mouse.x = e.pageX - this.offsetLeft\n",
              "  mouse.y = e.pageY - this.offsetTop\n",
              "})\n",
              "canvas.onmousedown = ()=>{\n",
              "  ctx.beginPath()\n",
              "  ctx.moveTo(mouse.x, mouse.y)\n",
              "  canvas.addEventListener('mousemove', onPaint)\n",
              "}\n",
              "canvas.onmouseup = ()=>{\n",
              "  canvas.removeEventListener('mousemove', onPaint)\n",
              "}\n",
              "var onPaint = ()=>{\n",
              "  ctx.lineTo(mouse.x, mouse.y)\n",
              "  ctx.stroke()\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "  button.onclick = ()=>{\n",
              "    resolve(canvas.toDataURL('image/png'))\n",
              "    button.remove()\n",
              "    canvas.remove()\n",
              "  }\n",
              "})\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title create masks\n",
        "%cd {root_path2}\n",
        "#todo still need to fix the layout of the button\n",
        "\n",
        "for i in os.listdir(step2_temp):\n",
        "  if('mask' in i):\n",
        "    # fix if we run the cell multiple times, not to take into account the masks\n",
        "    continue\n",
        "  fpath = os.path.join(step2_temp,i)\n",
        "\n",
        "  image64 = base64.b64encode(open(fpath, 'rb').read())\n",
        "  image64 = image64.decode('utf-8')\n",
        "  fname = fpath.split('/')[-1].split('.')[0]\n",
        "  img = np.array(plt.imread(f'{fpath}')[:,:,:3])\n",
        "\n",
        "  draw(image64, filename=f\"./{fname}_mask.png\", w=img.shape[1], h=img.shape[0], line_width=0.04*img.shape[1])\n",
        "  \n",
        "for i in os.listdir(step2_temp):\n",
        "  if('mask' in i):\n",
        "    # fix if we run the cell multiple times, not to take into account the masks\n",
        "    continue\n",
        "  fpath = os.path.join(step2_temp,i)\n",
        "  fname = fpath.split('/')[-1].split('.')[0]\n",
        "\n",
        "  # plt.rcParams[\"figure.figsize\"] = (15,5)\n",
        "  # plt.rcParams['figure.dpi'] = 200\n",
        "  # plt.subplot(131)\n",
        "  with_mask = np.array(plt.imread(f\"./{fname}_mask.png\")[:,:,:3])\n",
        "  mask = (with_mask[:,:,0]==1)*(with_mask[:,:,1]==0)*(with_mask[:,:,2]==0)\n",
        "  # plt.imshow(mask, cmap='gray')\n",
        "  # plt.axis('off')\n",
        "  # plt.title('mask')\n",
        "  plt.imsave(f\"{step2_temp}/{fname}_mask.png\",mask, cmap='gray')\n",
        "\n",
        "  # plt.subplot(132)\n",
        "  # img = np.array(plt.imread(f'{fpath}')[:,:,:3])\n",
        "  # plt.imshow(img)\n",
        "  # plt.axis('off')\n",
        "  # plt.title('img')\n",
        "\n",
        "  # plt.subplot(133)\n",
        "  # img = np.array((1-mask.reshape(mask.shape[0], mask.shape[1], -1))*plt.imread(fpath)[:,:,:3])\n",
        "  # _=plt.imshow(img)\n",
        "  # _=plt.axis('off')\n",
        "  # _=plt.title('img * mask')\n",
        "  # plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run inpainting\n",
        "if '.jpeg' in fpath:\n",
        "  !PYTHONPATH=. TORCH_HOME=$(pwd) python3 bin/predict.py  model.path=$(pwd)/big-lama indir={step2_temp}  outdir={output_step2}  dataset.img_suffix=.jpeg   > /dev/null\n",
        "elif '.jpg' in fpath:\n",
        "  !PYTHONPATH=. TORCH_HOME=$(pwd) python3 bin/predict.py  model.path=$(pwd)/big-lama indir={step2_temp}  outdir={output_step2}  dataset.img_suffix=.jpg    > /dev/null\n",
        "elif '.png' in fpath:\n",
        "  !PYTHONPATH=. TORCH_HOME=$(pwd) python3 bin/predict.py  model.path=$(pwd)/big-lama indir={step2_temp}  outdir={output_step2}  dataset.img_suffix=.png    > /dev/null\n",
        "else:\n",
        "  print(f'Error: unknown suffix .{fname.split(\".\")[-1]} use [.png, .jpeg, .jpg]')\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 200\n",
        "\n",
        "for i in (os.listdir(output_step2)):\n",
        "  i_name = i.replace('_mask','')\n",
        "  os.rename(os.path.join(output_step2,i),os.path.join(output_step2,i_name))"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuoiEGtFrSBS",
        "outputId": "cb244400-3921-4860-afd9-4f69e8c77b41"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detectron v2 is not installed\n",
            "[2022-05-25 14:50:11,528][saicinpainting.utils][WARNING] - Setting signal 10 handler <function print_traceback_handler at 0x7f0f9dfaf9e0>\n",
            "[2022-05-25 14:50:11,555][root][INFO] - Make training model default\n",
            "[2022-05-25 14:50:11,556][saicinpainting.training.trainers.base][INFO] - BaseInpaintingTrainingModule init called\n",
            "[2022-05-25 14:50:11,556][root][INFO] - Make generator ffc_resnet\n",
            "[2022-05-25 14:50:12,009][saicinpainting.training.trainers.base][INFO] - Generator\n",
            "FFCResNetGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): FFC_BN_ACT(\n",
            "      (ffc): FFC(\n",
            "        (convl2l): Conv2d(4, 64, kernel_size=(7, 7), stride=(1, 1), bias=False, padding_mode=reflect)\n",
            "        (convl2g): Identity()\n",
            "        (convg2l): Identity()\n",
            "        (convg2g): Identity()\n",
            "        (gate): Identity()\n",
            "      )\n",
            "      (bn_l): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn_g): Identity()\n",
            "      (act_l): ReLU(inplace=True)\n",
            "      (act_g): Identity()\n",
            "    )\n",
            "    (2): FFC_BN_ACT(\n",
            "      (ffc): FFC(\n",
            "        (convl2l): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "        (convl2g): Identity()\n",
            "        (convg2l): Identity()\n",
            "        (convg2g): Identity()\n",
            "        (gate): Identity()\n",
            "      )\n",
            "      (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn_g): Identity()\n",
            "      (act_l): ReLU(inplace=True)\n",
            "      (act_g): Identity()\n",
            "    )\n",
            "    (3): FFC_BN_ACT(\n",
            "      (ffc): FFC(\n",
            "        (convl2l): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "        (convl2g): Identity()\n",
            "        (convg2l): Identity()\n",
            "        (convg2g): Identity()\n",
            "        (gate): Identity()\n",
            "      )\n",
            "      (bn_l): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn_g): Identity()\n",
            "      (act_l): ReLU(inplace=True)\n",
            "      (act_g): Identity()\n",
            "    )\n",
            "    (4): FFC_BN_ACT(\n",
            "      (ffc): FFC(\n",
            "        (convl2l): Conv2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "        (convl2g): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "        (convg2l): Identity()\n",
            "        (convg2g): Identity()\n",
            "        (gate): Identity()\n",
            "      )\n",
            "      (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act_l): ReLU(inplace=True)\n",
            "      (act_g): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): FFCResnetBlock(\n",
            "      (conv1): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (6): FFCResnetBlock(\n",
            "      (conv1): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (7): FFCResnetBlock(\n",
            "      (conv1): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (8): FFCResnetBlock(\n",
            "      (conv1): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (9): FFCResnetBlock(\n",
            "      (conv1): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (10): FFCResnetBlock(\n",
            "      (conv1): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (11): FFCResnetBlock(\n",
            "      (conv1): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (12): FFCResnetBlock(\n",
            "      (conv1): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (13): FFCResnetBlock(\n",
            "      (conv1): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (14): FFCResnetBlock(\n",
            "      (conv1): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (15): FFCResnetBlock(\n",
            "      (conv1): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (16): FFCResnetBlock(\n",
            "      (conv1): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (17): FFCResnetBlock(\n",
            "      (conv1): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (18): FFCResnetBlock(\n",
            "      (conv1): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (19): FFCResnetBlock(\n",
            "      (conv1): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (20): FFCResnetBlock(\n",
            "      (conv1): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (21): FFCResnetBlock(\n",
            "      (conv1): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (22): FFCResnetBlock(\n",
            "      (conv1): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): FFC_BN_ACT(\n",
            "        (ffc): FFC(\n",
            "          (convl2l): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convl2g): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2l): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
            "          (convg2g): SpectralTransform(\n",
            "            (downsample): Identity()\n",
            "            (conv1): Sequential(\n",
            "              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (fu): FourierUnit(\n",
            "              (conv_layer): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (conv2): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (gate): Identity()\n",
            "        )\n",
            "        (bn_l): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn_g): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act_l): ReLU(inplace=True)\n",
            "        (act_g): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (23): ConcatTupleLayer()\n",
            "    (24): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (31): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (34): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (35): Sigmoid()\n",
            "  )\n",
            ")\n",
            "[2022-05-25 14:50:12,026][saicinpainting.training.trainers.base][INFO] - BaseInpaintingTrainingModule init done\n",
            "[2022-05-25 14:50:15,943][saicinpainting.training.data.datasets][INFO] - Make val dataloader default from /content/database/lieven/step2temp/\n",
            "100% 2/2 [00:01<00:00,  1.38it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVknZ2QiAzSE"
      },
      "source": [
        "## Step 3: background removal\n",
        "\n",
        "Again, verify the outcome of step 2. \n",
        "\n",
        "Now we'll subtract the background using the PaddleSeg model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "H2dRnK6VBMlj",
        "outputId": "c9c6cd5e-5d27-4dc4-eb98-225b8bcf3d2f",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 112.3 MB 8.6 kB/s \n",
            "\u001b[K     |████████████████████████████████| 373 kB 57.6 MB/s \n",
            "\u001b[?25hCloning into '/content/PaddleSeg'...\n",
            "remote: Enumerating objects: 17862, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 17862 (delta 12), reused 17 (delta 6), pack-reused 17819\u001b[K\n",
            "Receiving objects: 100% (17862/17862), 344.82 MiB | 27.28 MiB/s, done.\n",
            "Resolving deltas: 100% (11441/11441), done.\n",
            "/content/PaddleSeg\n",
            "/bin/bash: -c: line 0: unexpected EOF while looking for matching `''\n",
            "/bin/bash: -c: line 1: syntax error: unexpected end of file\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/PaddleSeg\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (6.0)\n",
            "Collecting visualdl>=2.0.0\n",
            "  Downloading visualdl-2.2.3-py3-none-any.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 26.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (4.1.2.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (3.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (1.4.1)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (3.3.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from paddleseg==2.5.0) (0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (3.2.2)\n",
            "Requirement already satisfied: flask>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (1.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (2.23.0)\n",
            "Collecting pre-commit\n",
            "  Downloading pre_commit-2.19.0-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 67.7 MB/s \n",
            "\u001b[?25hCollecting flake8>=3.7.9\n",
            "  Downloading flake8-4.0.1-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting Flask-Babel>=1.0.0\n",
            "  Downloading Flask_Babel-2.0.0-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.11.0 in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (3.17.3)\n",
            "Requirement already satisfied: Pillow>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (7.1.2)\n",
            "Collecting shellcheck-py\n",
            "  Downloading shellcheck_py-0.8.0.4-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 59.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddleseg==2.5.0) (1.21.6)\n",
            "Collecting bce-python-sdk\n",
            "  Downloading bce-python-sdk-0.8.64.tar.gz (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 51.0 MB/s \n",
            "\u001b[?25hCollecting pycodestyle<2.9.0,>=2.8.0\n",
            "  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.1 MB/s \n",
            "\u001b[?25hCollecting importlib-metadata<4.3\n",
            "  Downloading importlib_metadata-4.2.0-py3-none-any.whl (16 kB)\n",
            "Collecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting pyflakes<2.5.0,>=2.4.0\n",
            "  Downloading pyflakes-2.4.0-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg==2.5.0) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg==2.5.0) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg==2.5.0) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg==2.5.0) (7.1.2)\n",
            "Requirement already satisfied: Babel>=2.3 in /usr/local/lib/python3.7/dist-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddleseg==2.5.0) (2.10.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddleseg==2.5.0) (2022.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl>=2.0.0->paddleseg==2.5.0) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl>=2.0.0->paddleseg==2.5.0) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask>=1.1.1->visualdl>=2.0.0->paddleseg==2.5.0) (2.0.1)\n",
            "Collecting pycryptodome>=3.8.0\n",
            "  Downloading pycryptodome-3.14.1-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 45.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from bce-python-sdk->visualdl>=2.0.0->paddleseg==2.5.0) (0.18.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->visualdl>=2.0.0->paddleseg==2.5.0) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->visualdl>=2.0.0->paddleseg==2.5.0) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->visualdl>=2.0.0->paddleseg==2.5.0) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->visualdl>=2.0.0->paddleseg==2.5.0) (3.0.9)\n",
            "Collecting identify>=1.0.0\n",
            "  Downloading identify-2.5.1-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 10.0 MB/s \n",
            "\u001b[?25hCollecting cfgv>=2.0.0\n",
            "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting virtualenv>=20.0.8\n",
            "  Downloading virtualenv-20.14.1-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 68.1 MB/s \n",
            "\u001b[?25hCollecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting nodeenv>=0.11.1\n",
            "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 66.3 MB/s \n",
            "\u001b[?25hCollecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->paddleseg==2.5.0) (0.2.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddleseg==2.5.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddleseg==2.5.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddleseg==2.5.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddleseg==2.5.0) (2022.5.18.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->paddleseg==2.5.0) (0.24.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->paddleseg==2.5.0) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->paddleseg==2.5.0) (3.1.0)\n",
            "Building wheels for collected packages: bce-python-sdk\n",
            "  Building wheel for bce-python-sdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bce-python-sdk: filename=bce_python_sdk-0.8.64-py3-none-any.whl size=202973 sha256=be7106e5e6ca05e50faec6557ff09bc2478328fecb837021834ede79c1f69df8\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/ee/a5/4ad3bdc0e60b48e892e8bd6f661a3201d7e76dccfa9e968b34\n",
            "Successfully built bce-python-sdk\n",
            "Installing collected packages: platformdirs, importlib-metadata, distlib, virtualenv, toml, pyflakes, pycryptodome, pycodestyle, nodeenv, mccabe, identify, cfgv, shellcheck-py, pre-commit, Flask-Babel, flake8, bce-python-sdk, visualdl, paddleseg\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.11.3\n",
            "    Uninstalling importlib-metadata-4.11.3:\n",
            "      Successfully uninstalled importlib-metadata-4.11.3\n",
            "  Running setup.py develop for paddleseg\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.7 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 4.2.0 which is incompatible.\u001b[0m\n",
            "Successfully installed Flask-Babel-2.0.0 bce-python-sdk-0.8.64 cfgv-3.3.1 distlib-0.3.4 flake8-4.0.1 identify-2.5.1 importlib-metadata-4.2.0 mccabe-0.6.1 nodeenv-1.6.0 paddleseg-2.5.0 platformdirs-2.5.2 pre-commit-2.19.0 pycodestyle-2.8.0 pycryptodome-3.14.1 pyflakes-2.4.0 shellcheck-py-0.8.0.4 toml-0.10.2 virtualenv-20.14.1 visualdl-2.2.3\n",
            "/content/PaddleSeg/Matting\n",
            "\u001b[K     |████████████████████████████████| 60.3 MB 1.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#@title imports for paddleseg\n",
        "!pip install -q PaddlePaddle\n",
        "root_path = '/content/PaddleSeg'\n",
        "\n",
        "# clone the repository\n",
        "if not os.path.exists(root_path):\n",
        "  !git clone https://github.com/PaddlePaddle/PaddleSeg {root_path}\n",
        "\n",
        "%cd {root_path}\n",
        "!pip -qq install -r requirements.txt'\n",
        "!pip install -e .\n",
        "\n",
        "# installing Matting\n",
        "%cd Matting\n",
        "!pip -qq install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MssU8gR4HWaV",
        "outputId": "13019492-4b6b-494b-c339-fe131f2d89b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "> Download the model params\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  243M  100  243M    0     0  5662k      0  0:00:44  0:00:44 --:--:-- 12.4M\n",
            "\n",
            "> Download the model\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  226M  100  226M    0     0  4773k      0  0:00:48  0:00:48 --:--:-- 9931k\n"
          ]
        }
      ],
      "source": [
        "#@title downloading the models\n",
        "# download model checkpoint \n",
        "model_path = root_path + '/Matting/data/model'\n",
        "model_params = 'https://paddleseg.bj.bcebos.com/matting/models/human_matting-resnet34_vd.pdparams'\n",
        "model_inf = 'https://paddleseg.bj.bcebos.com/matting/models/deploy/pp-humanmatting-resnet34_vd.zip'\n",
        "# make folders\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "if not os.path.exists(os.path.join(model_path,'human_matting.pdparams')):\n",
        "  print('\\n> Download the model params')\n",
        "  !curl {model_params} -o {os.path.join(model_path,'human_matting.pdparams')}\n",
        "else:\n",
        "  print ('\\n> File already downloaded')\n",
        "if not os.path.exists(os.path.join(model_path,'human_matting-resnet.zip')):\n",
        "  print('\\n> Download the model')\n",
        "  !curl {model_inf} -o {os.path.join(model_path,'human_matting-resnet.zip')}\n",
        "  !unzip -q {os.path.join(model_path,'human_matting-resnet.zip')} -d {os.path.join(model_path)}\n",
        "else:\n",
        "  print ('\\n> File already downloaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JOkHdhXjJZcV",
        "outputId": "aa4c2918-b24d-4276-c3ae-fa5b7f42a0ae",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/fft/__init__.py:97: DeprecationWarning: The module numpy.dual is deprecated.  Instead of using dual, use the functions directly from numpy or scipy.\n",
            "  from numpy.dual import register_func\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/special/orthogonal.py:81: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/data/__init__.py:107: DeprecationWarning: \n",
            "    Importing file_hash from pooch.utils is DEPRECATED. Please import from the\n",
            "    top-level namespace (`from pooch import file_hash`) instead, which is fully\n",
            "    backwards compatible with pooch >= 0.1.\n",
            "    \n",
            "  return file_hash(path) == expected_hash\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/types/__init__.py:108: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  long_ = _make_signed(np.long)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/types/__init__.py:109: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  ulong = _make_unsigned(np.long)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/ir_utils.py:1525: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if (hasattr(numpy, value)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/ir_utils.py:1526: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  and def_val == getattr(numpy, value)):\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/ir_utils.py:1525: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if (hasattr(numpy, value)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/ir_utils.py:1526: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  and def_val == getattr(numpy, value)):\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/ir_utils.py:1525: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if (hasattr(numpy, value)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/ir_utils.py:1526: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  and def_val == getattr(numpy, value)):\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/ir_utils.py:1525: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if (hasattr(numpy, value)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/ir_utils.py:1526: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  and def_val == getattr(numpy, value)):\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResNet18_vd exists already! It is now updated to <function ResNet18_vd at 0x7f581bfe57a0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResNet50_vd exists already! It is now updated to <function ResNet50_vd at 0x7f581bd550e0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResNet101_vd exists already! It is now updated to <function ResNet101_vd at 0x7f581bd55200> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: MobileNetV2 exists already! It is now updated to <function MobileNetV2 at 0x7f581bd48290> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W18_Small_V1 exists already! It is now updated to <function HRNet_W18_Small_V1 at 0x7f581bcbe8c0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W18_Small_V2 exists already! It is now updated to <function HRNet_W18_Small_V2 at 0x7f581bcbd560> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W18 exists already! It is now updated to <function HRNet_W18 at 0x7f581bcbd5f0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W30 exists already! It is now updated to <function HRNet_W30 at 0x7f581bcbd710> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W32 exists already! It is now updated to <function HRNet_W32 at 0x7f581bcbd830> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W40 exists already! It is now updated to <function HRNet_W40 at 0x7f581bcbd950> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W44 exists already! It is now updated to <function HRNet_W44 at 0x7f581bcbda70> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W48 exists already! It is now updated to <function HRNet_W48 at 0x7f581bcbdb90> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W60 exists already! It is now updated to <function HRNet_W60 at 0x7f581bcbdcb0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: HRNet_W64 exists already! It is now updated to <function HRNet_W64 at 0x7f581bcbddd0> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: Compose exists already! It is now updated to <class 'transforms.Compose'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: Resize exists already! It is now updated to <class 'transforms.Resize'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResizeByLong exists already! It is now updated to <class 'transforms.ResizeByLong'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: ResizeByShort exists already! It is now updated to <class 'transforms.ResizeByShort'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: Normalize exists already! It is now updated to <class 'transforms.Normalize'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: LimitLong exists already! It is now updated to <class 'transforms.LimitLong'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: RandomHorizontalFlip exists already! It is now updated to <class 'transforms.RandomHorizontalFlip'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: RandomBlur exists already! It is now updated to <class 'transforms.RandomBlur'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: RandomDistort exists already! It is now updated to <class 'transforms.RandomDistort'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: Padding exists already! It is now updated to <class 'transforms.Padding'> !!!\n",
            "  format(component_name, component))\n",
            "/content/PaddleSeg/paddleseg/cvlibs/manager.py:114: UserWarning: RandomNoise exists already! It is now updated to <class 'transforms.RandomNoise'> !!!\n",
            "  format(component_name, component))\n",
            "2022-05-24 14:27:17 [INFO]\t\n",
            "---------------Config Information---------------\n",
            "batch_size: 4\n",
            "iters: 50000\n",
            "lr_scheduler:\n",
            "  boundaries:\n",
            "  - 30000\n",
            "  - 40000\n",
            "  type: PiecewiseDecay\n",
            "  values:\n",
            "  - 0.001\n",
            "  - 0.0001\n",
            "  - 1.0e-05\n",
            "model:\n",
            "  backbone:\n",
            "    pretrained: https://paddleseg.bj.bcebos.com/matting/models/ResNet34_vd_pretrained/model.pdparams\n",
            "    type: ResNet34_vd\n",
            "  if_refine: true\n",
            "  pretrained: null\n",
            "  type: HumanMatting\n",
            "optimizer:\n",
            "  momentum: 0.9\n",
            "  type: sgd\n",
            "  weight_decay: 4.0e-05\n",
            "train_dataset:\n",
            "  dataset_root: data/PPM-100\n",
            "  mode: train\n",
            "  train_file: train.txt\n",
            "  transforms:\n",
            "  - type: LoadImages\n",
            "  - scale:\n",
            "    - 0.3\n",
            "    - 1.5\n",
            "    size:\n",
            "    - 2048\n",
            "    - 2048\n",
            "    type: RandomResize\n",
            "  - crop_size:\n",
            "    - 2048\n",
            "    - 2048\n",
            "    type: RandomCrop\n",
            "  - type: RandomDistort\n",
            "  - prob: 0.1\n",
            "    type: RandomBlur\n",
            "  - type: RandomHorizontalFlip\n",
            "  - target_size:\n",
            "    - 2048\n",
            "    - 2048\n",
            "    type: Padding\n",
            "  - type: Normalize\n",
            "  type: MattingDataset\n",
            "val_dataset:\n",
            "  dataset_root: data/PPM-100\n",
            "  get_trimap: false\n",
            "  mode: val\n",
            "  transforms:\n",
            "  - type: LoadImages\n",
            "  - short_size: 2048\n",
            "    type: ResizeByShort\n",
            "  - mult_int: 128\n",
            "    type: ResizeToIntMult\n",
            "  - type: Normalize\n",
            "  type: MattingDataset\n",
            "  val_file: val.txt\n",
            "------------------------------------------------\n",
            "/content/PaddleSeg/paddleseg/cvlibs/config.py:332: UserWarning: `dataset_root` is not found. Is it correct?\n",
            "  warnings.warn(\"`dataset_root` is not found. Is it correct?\")\n",
            "2022-05-24 14:27:17 [INFO]\tLoading pretrained model from https://paddleseg.bj.bcebos.com/matting/models/ResNet34_vd_pretrained/model.pdparams\n",
            "Connecting to https://paddleseg.bj.bcebos.com/matting/models/ResNet34_vd_pretrained/model.pdparams\n",
            "Downloading model.pdparams\n",
            "[==================================================] 100.00%\n",
            "2022-05-24 14:27:57 [INFO]\tThere are 195/195 variables loaded into ResNet_vd.\n",
            "Traceback (most recent call last):\n",
            "  File \"predict.py\", line 107, in <module>\n",
            "    main(args)\n",
            "  File \"predict.py\", line 87, in main\n",
            "    image_list, image_dir = get_image_list(args.image_path)\n",
            "  File \"/content/PaddleSeg/Matting/utils/utils.py\", line 62, in get_image_list\n",
            "    raise RuntimeError('There are not image file in `image_path`')\n",
            "RuntimeError: There are not image file in `image_path`\n"
          ]
        }
      ],
      "source": [
        "mode = 'background_removal' #@param ['background_removal','background_replacement']\n",
        "\n",
        "#step3_temp = '{}/total/step3temp'.format(nextcloud)\n",
        "step3_temp = '{}/' + tname + '/step3temp'.format(nextcloud)\n",
        "\n",
        "os.makedirs(step3_temp, exist_ok=True)\n",
        "if(mode=='background_removal'):\n",
        "# predict\n",
        "  !export CUDA_VISIBLE_DEVICES=0\n",
        "  !python predict.py \\\n",
        "      --config configs/human_matting/human_matting-resnet34_vd.yml \\\n",
        "      --model_path data/model/human_matting.pdparams \\\n",
        "      --image_path {input_step3} \\\n",
        "      --save_dir {step3_temp} \\\n",
        "      --fg_estimate True\n",
        "else:\n",
        "  # bg replacement\n",
        "  #TODO right now all images get the same background image\n",
        "  #@markdown either choose an rgbw value as background or type the path to the bgimage:\n",
        "  background = 'g' #@param ['r','g','b','w'] {allow-input: true}\n",
        "  !export CUDA_VISIBLE_DEVICES=0\n",
        "  for infer_img in os.listdir(input_step3):\n",
        "    !python bg_replace.py \\\n",
        "        --config configs/human_matting/human_matting-resnet34_vd.yml \\\n",
        "        --model_path data/model/human_matting.pdparams \\\n",
        "        --image_path {os.path.join(input_step3,infer_img)} \\\n",
        "        --save_dir {step3_temp} \\\n",
        "        --background {background} \\\n",
        "        --fg_estimate True\n",
        "for i in os.listdir(step3_temp):\n",
        "  if('_' in i):\n",
        "    #we only want to copy the output files to the next step\n",
        "    continue\n",
        "  shutil.copy2(os.path.join(step3_temp,i),os.path.join(output_step3,i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHvEogQSBfUh"
      },
      "source": [
        "## Step 4: Clothes recoloring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ypRPB6yICRl",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "#@markdown as we're not implementing clothes recoloring yet, we copy the folders to surpass this step\n",
        "for file in os.listdir(input_step4):\n",
        "  shutil.copy2(os.path.join(input_step4, file), output_step4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jIiSGm6ICRl"
      },
      "source": [
        "## Step 5: Skin retouching\n",
        "\n",
        "we'll implement the retouchML library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "collapsed": true,
        "id": "ddpvlvl6ICRm",
        "outputId": "caea3a4d-9818-4482-f4cd-153490cdea15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.21.6)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0\n",
            "Collecting numpy==1.19.5\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\n",
            "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.5\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into '/content/retouchML'...\n",
            "remote: Enumerating objects: 290, done.\u001b[K\n",
            "remote: Total 290 (delta 0), reused 0 (delta 0), pack-reused 290\u001b[K\n",
            "Receiving objects: 100% (290/290), 81.87 MiB | 13.61 MiB/s, done.\n",
            "Resolving deltas: 100% (122/122), done.\n",
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ]
        }
      ],
      "source": [
        "#@title install models and prerequisites\n",
        "#@markdown, ignore the warning messages\n",
        "!pip install 'h5py==2.10.0' \n",
        "# numpy versions from 1.20 throw an error further down the road, might need to restart the runtime.\n",
        "!pip install numpy==1.19.5\n",
        "root_path5 = '/content/retouchML'\n",
        "# clone the repository\n",
        "if not os.path.exists('retouchML'):\n",
        "  !git clone https://github.com/ju-leon/RetouchML {root_path5}\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "38XCtoLJ-Ktc",
        "outputId": "015fe531-3644-45bf-fcf9-2f8ba22b7ea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/retouchML\n",
            "Using TensorFlow backend.\n",
            "Downloading data from http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "64045056/64040097 [==============================] - 7s 0us/step\n",
            "Using TensorFlow backend.\n",
            "Downloading http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl ... done\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "Downloading https://rolux.org/media/stylegan/vgg16_zhang_perceptual.pkl ... done\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 11s 0us/step\n",
            "  0% 0/2 [00:00<?, ?it/s]Rects:\n",
            "rectangles[[(46, 64) (201, 219)]]\n",
            "Saving mask masks/1_01.png\n",
            "Loading mask masks/1_01.png\n",
            "\n",
            "  0% 0/200 [00:00<?, ?it/s]\u001b[A\n",
            "1_01: loss 303.6841; lr 0.4000:   0% 0/200 [00:15<?, ?it/s]\u001b[A\n",
            "1_01: loss 303.6841; lr 0.4000:   0% 1/200 [00:16<53:26, 16.12s/it]\u001b[A\n",
            "1_01: loss 281.1352; lr 0.4000:   0% 1/200 [00:17<53:26, 16.12s/it]\u001b[A\n",
            "1_01: loss 281.1352; lr 0.4000:   1% 2/200 [00:17<23:55,  7.25s/it]\u001b[A\n",
            "1_01: loss 259.6882; lr 0.4000:   1% 2/200 [00:18<23:55,  7.25s/it]\u001b[A\n",
            "1_01: loss 259.6882; lr 0.4000:   2% 3/200 [00:18<14:29,  4.41s/it]\u001b[A\n",
            "1_01: loss 234.1092; lr 0.4000:   2% 3/200 [00:19<14:29,  4.41s/it]\u001b[A\n",
            "1_01: loss 234.1092; lr 0.4000:   2% 4/200 [00:19<10:03,  3.08s/it]\u001b[A\n",
            "1_01: loss 221.5306; lr 0.4000:   2% 4/200 [00:20<10:03,  3.08s/it]\u001b[A\n",
            "1_01: loss 221.5306; lr 0.4000:   2% 5/200 [00:20<07:35,  2.34s/it]\u001b[A\n",
            "1_01: loss 214.2132; lr 0.4000:   2% 5/200 [00:21<07:35,  2.34s/it]\u001b[A\n",
            "1_01: loss 214.2132; lr 0.4000:   3% 6/200 [00:21<06:06,  1.89s/it]\u001b[A\n",
            "1_01: loss 206.2308; lr 0.4000:   3% 6/200 [00:22<06:06,  1.89s/it]\u001b[A\n",
            "1_01: loss 206.2308; lr 0.4000:   4% 7/200 [00:22<05:11,  1.61s/it]\u001b[A\n",
            "1_01: loss 196.2941; lr 0.3600:   4% 7/200 [00:23<05:11,  1.61s/it]\u001b[A\n",
            "1_01: loss 196.2941; lr 0.3600:   4% 8/200 [00:23<04:33,  1.43s/it]\u001b[A\n",
            "1_01: loss 189.8044; lr 0.3600:   4% 8/200 [00:24<04:33,  1.43s/it]\u001b[A\n",
            "1_01: loss 189.8044; lr 0.3600:   4% 9/200 [00:24<04:08,  1.30s/it]\u001b[A\n",
            "1_01: loss 183.4010; lr 0.3600:   4% 9/200 [00:25<04:08,  1.30s/it]\u001b[A\n",
            "1_01: loss 183.4010; lr 0.3600:   5% 10/200 [00:25<03:50,  1.21s/it]\u001b[A\n",
            "1_01: loss 179.2869; lr 0.3600:   5% 10/200 [00:26<03:50,  1.21s/it]\u001b[A\n",
            "1_01: loss 179.2869; lr 0.3600:   6% 11/200 [00:26<03:39,  1.16s/it]\u001b[A\n",
            "1_01: loss 177.9773; lr 0.3600:   6% 11/200 [00:27<03:39,  1.16s/it]\u001b[A\n",
            "1_01: loss 177.9773; lr 0.3600:   6% 12/200 [00:27<03:30,  1.12s/it]\u001b[A\n",
            "1_01: loss 171.7241; lr 0.3600:   6% 12/200 [00:28<03:30,  1.12s/it]\u001b[A\n",
            "1_01: loss 171.7241; lr 0.3600:   6% 13/200 [00:28<03:24,  1.09s/it]\u001b[A\n",
            "1_01: loss 166.5357; lr 0.3600:   6% 13/200 [00:29<03:24,  1.09s/it]\u001b[A\n",
            "1_01: loss 166.5357; lr 0.3600:   7% 14/200 [00:29<03:19,  1.07s/it]\u001b[A\n",
            "1_01: loss 161.6500; lr 0.3600:   7% 14/200 [00:30<03:19,  1.07s/it]\u001b[A\n",
            "1_01: loss 161.6500; lr 0.3600:   8% 15/200 [00:30<03:15,  1.06s/it]\u001b[A\n",
            "1_01: loss 160.7909; lr 0.3240:   8% 15/200 [00:31<03:15,  1.06s/it]\u001b[A\n",
            "1_01: loss 160.7909; lr 0.3240:   8% 16/200 [00:31<03:13,  1.05s/it]\u001b[A\n",
            "1_01: loss 155.5237; lr 0.3240:   8% 16/200 [00:32<03:13,  1.05s/it]\u001b[A\n",
            "1_01: loss 155.5237; lr 0.3240:   8% 17/200 [00:32<03:10,  1.04s/it]\u001b[A\n",
            "1_01: loss 155.2882; lr 0.3240:   8% 17/200 [00:33<03:10,  1.04s/it]\u001b[A\n",
            "1_01: loss 155.2882; lr 0.3240:   9% 18/200 [00:33<03:08,  1.04s/it]\u001b[A\n",
            "1_01: loss 151.8768; lr 0.3240:   9% 18/200 [00:34<03:08,  1.04s/it]\u001b[A\n",
            "1_01: loss 151.8768; lr 0.3240:  10% 19/200 [00:34<03:08,  1.04s/it]\u001b[A\n",
            "1_01: loss 150.7539; lr 0.3240:  10% 19/200 [00:35<03:08,  1.04s/it]\u001b[A\n",
            "1_01: loss 150.7539; lr 0.3240:  10% 20/200 [00:35<03:06,  1.04s/it]\u001b[A\n",
            "1_01: loss 148.3593; lr 0.3240:  10% 20/200 [00:36<03:06,  1.04s/it]\u001b[A\n",
            "1_01: loss 148.3593; lr 0.3240:  10% 21/200 [00:36<03:05,  1.03s/it]\u001b[A\n",
            "1_01: loss 143.6638; lr 0.3240:  10% 21/200 [00:37<03:05,  1.03s/it]\u001b[A\n",
            "1_01: loss 143.6638; lr 0.3240:  11% 22/200 [00:37<03:04,  1.04s/it]\u001b[A\n",
            "1_01: loss 145.7506; lr 0.3240:  11% 22/200 [00:38<03:04,  1.04s/it]\u001b[A\n",
            "1_01: loss 145.7506; lr 0.3240:  12% 23/200 [00:38<03:03,  1.04s/it]\u001b[A\n",
            "1_01: loss 159.3320; lr 0.2916:  12% 23/200 [00:39<03:03,  1.04s/it]\u001b[A\n",
            "1_01: loss 159.3320; lr 0.2916:  12% 24/200 [00:39<03:02,  1.03s/it]\u001b[A\n",
            "1_01: loss 142.0406; lr 0.2916:  12% 24/200 [00:40<03:02,  1.03s/it]\u001b[A\n",
            "1_01: loss 142.0406; lr 0.2916:  12% 25/200 [00:40<03:01,  1.04s/it]\u001b[A\n",
            "1_01: loss 146.8555; lr 0.2916:  12% 25/200 [00:41<03:01,  1.04s/it]\u001b[A\n",
            "1_01: loss 146.8555; lr 0.2916:  13% 26/200 [00:41<03:00,  1.04s/it]\u001b[A\n",
            "1_01: loss 142.5964; lr 0.2916:  13% 26/200 [00:42<03:00,  1.04s/it]\u001b[A\n",
            "1_01: loss 142.5964; lr 0.2916:  14% 27/200 [00:42<02:59,  1.04s/it]\u001b[A\n",
            "1_01: loss 138.2323; lr 0.2916:  14% 27/200 [00:43<02:59,  1.04s/it]\u001b[A\n",
            "1_01: loss 138.2323; lr 0.2916:  14% 28/200 [00:43<02:58,  1.04s/it]\u001b[A\n",
            "1_01: loss 139.8638; lr 0.2916:  14% 28/200 [00:45<02:58,  1.04s/it]\u001b[A\n",
            "1_01: loss 139.8638; lr 0.2916:  14% 29/200 [00:45<02:57,  1.04s/it]\u001b[A\n",
            "1_01: loss 141.1163; lr 0.2916:  14% 29/200 [00:46<02:57,  1.04s/it]\u001b[A\n",
            "1_01: loss 141.1163; lr 0.2916:  15% 30/200 [00:46<02:57,  1.04s/it]\u001b[A\n",
            "1_01: loss 135.5941; lr 0.2916:  15% 30/200 [00:47<02:57,  1.04s/it]\u001b[A\n",
            "1_01: loss 135.5941; lr 0.2916:  16% 31/200 [00:47<02:56,  1.04s/it]\u001b[A\n",
            "1_01: loss 135.3908; lr 0.2624:  16% 31/200 [00:48<02:56,  1.04s/it]\u001b[A\n",
            "1_01: loss 135.3908; lr 0.2624:  16% 32/200 [00:48<02:55,  1.04s/it]\u001b[A\n",
            "1_01: loss 132.6750; lr 0.2624:  16% 32/200 [00:49<02:55,  1.04s/it]\u001b[A\n",
            "1_01: loss 132.6750; lr 0.2624:  16% 33/200 [00:49<02:53,  1.04s/it]\u001b[A\n",
            "1_01: loss 130.2664; lr 0.2624:  16% 33/200 [00:50<02:53,  1.04s/it]\u001b[A\n",
            "1_01: loss 130.2664; lr 0.2624:  17% 34/200 [00:50<02:52,  1.04s/it]\u001b[A\n",
            "1_01: loss 129.6850; lr 0.2624:  17% 34/200 [00:51<02:52,  1.04s/it]\u001b[A\n",
            "1_01: loss 129.6850; lr 0.2624:  18% 35/200 [00:51<02:51,  1.04s/it]\u001b[A\n",
            "1_01: loss 129.2870; lr 0.2624:  18% 35/200 [00:52<02:51,  1.04s/it]\u001b[A\n",
            "1_01: loss 129.2870; lr 0.2624:  18% 36/200 [00:52<02:49,  1.03s/it]\u001b[A\n",
            "1_01: loss 129.0678; lr 0.2624:  18% 36/200 [00:53<02:49,  1.03s/it]\u001b[A\n",
            "1_01: loss 129.0678; lr 0.2624:  18% 37/200 [00:53<02:48,  1.03s/it]\u001b[A\n",
            "1_01: loss 129.5061; lr 0.2624:  18% 37/200 [00:54<02:48,  1.03s/it]\u001b[A\n",
            "1_01: loss 129.5061; lr 0.2624:  19% 38/200 [00:54<02:48,  1.04s/it]\u001b[A\n",
            "1_01: loss 128.0524; lr 0.2624:  19% 38/200 [00:55<02:48,  1.04s/it]\u001b[A\n",
            "1_01: loss 128.0524; lr 0.2624:  20% 39/200 [00:55<02:47,  1.04s/it]\u001b[A\n",
            "1_01: loss 127.3775; lr 0.2362:  20% 39/200 [00:56<02:47,  1.04s/it]\u001b[A\n",
            "1_01: loss 127.3775; lr 0.2362:  20% 40/200 [00:56<02:46,  1.04s/it]\u001b[A\n",
            "1_01: loss 123.9128; lr 0.2362:  20% 40/200 [00:57<02:46,  1.04s/it]\u001b[A\n",
            "1_01: loss 123.9128; lr 0.2362:  20% 41/200 [00:57<02:45,  1.04s/it]\u001b[A\n",
            "1_01: loss 125.2108; lr 0.2362:  20% 41/200 [00:58<02:45,  1.04s/it]\u001b[A\n",
            "1_01: loss 125.2108; lr 0.2362:  21% 42/200 [00:58<02:43,  1.04s/it]\u001b[A\n",
            "1_01: loss 126.0143; lr 0.2362:  21% 42/200 [00:59<02:43,  1.04s/it]\u001b[A\n",
            "1_01: loss 126.0143; lr 0.2362:  22% 43/200 [00:59<02:42,  1.04s/it]\u001b[A\n",
            "1_01: loss 124.7695; lr 0.2362:  22% 43/200 [01:00<02:42,  1.04s/it]\u001b[A\n",
            "1_01: loss 124.7695; lr 0.2362:  22% 44/200 [01:00<02:41,  1.04s/it]\u001b[A\n",
            "1_01: loss 130.8445; lr 0.2362:  22% 44/200 [01:01<02:41,  1.04s/it]\u001b[A\n",
            "1_01: loss 130.8445; lr 0.2362:  22% 45/200 [01:01<02:41,  1.04s/it]\u001b[A\n",
            "1_01: loss 126.5528; lr 0.2362:  22% 45/200 [01:02<02:41,  1.04s/it]\u001b[A\n",
            "1_01: loss 126.5528; lr 0.2362:  23% 46/200 [01:02<02:41,  1.05s/it]\u001b[A\n",
            "1_01: loss 124.9856; lr 0.2362:  23% 46/200 [01:03<02:41,  1.05s/it]\u001b[A\n",
            "1_01: loss 124.9856; lr 0.2362:  24% 47/200 [01:03<02:39,  1.04s/it]\u001b[A\n",
            "1_01: loss 123.1356; lr 0.2126:  24% 47/200 [01:04<02:39,  1.04s/it]\u001b[A\n",
            "1_01: loss 123.1356; lr 0.2126:  24% 48/200 [01:04<02:38,  1.04s/it]\u001b[A\n",
            "1_01: loss 121.0893; lr 0.2126:  24% 48/200 [01:05<02:38,  1.04s/it]\u001b[A\n",
            "1_01: loss 121.0893; lr 0.2126:  24% 49/200 [01:05<02:37,  1.04s/it]\u001b[A\n",
            "1_01: loss 120.0564; lr 0.2126:  24% 49/200 [01:06<02:37,  1.04s/it]\u001b[A\n",
            "1_01: loss 120.0564; lr 0.2126:  25% 50/200 [01:06<02:36,  1.04s/it]\u001b[A\n",
            "1_01: loss 121.2355; lr 0.2126:  25% 50/200 [01:07<02:36,  1.04s/it]\u001b[A\n",
            "1_01: loss 121.2355; lr 0.2126:  26% 51/200 [01:07<02:35,  1.05s/it]\u001b[A\n",
            "1_01: loss 123.7435; lr 0.2126:  26% 51/200 [01:08<02:35,  1.05s/it]\u001b[A\n",
            "1_01: loss 123.7435; lr 0.2126:  26% 52/200 [01:08<02:34,  1.04s/it]\u001b[A\n",
            "1_01: loss 121.4628; lr 0.2126:  26% 52/200 [01:10<02:34,  1.04s/it]\u001b[A\n",
            "1_01: loss 121.4628; lr 0.2126:  26% 53/200 [01:10<02:33,  1.04s/it]\u001b[A\n",
            "1_01: loss 120.7418; lr 0.2126:  26% 53/200 [01:11<02:33,  1.04s/it]\u001b[A\n",
            "1_01: loss 120.7418; lr 0.2126:  27% 54/200 [01:11<02:32,  1.04s/it]\u001b[A\n",
            "1_01: loss 118.5229; lr 0.2126:  27% 54/200 [01:12<02:32,  1.04s/it]\u001b[A\n",
            "1_01: loss 118.5229; lr 0.2126:  28% 55/200 [01:12<02:30,  1.04s/it]\u001b[A\n",
            "1_01: loss 120.4333; lr 0.1913:  28% 55/200 [01:13<02:30,  1.04s/it]\u001b[A\n",
            "1_01: loss 120.4333; lr 0.1913:  28% 56/200 [01:13<02:29,  1.04s/it]\u001b[A\n",
            "1_01: loss 120.5807; lr 0.1913:  28% 56/200 [01:14<02:29,  1.04s/it]\u001b[A\n",
            "1_01: loss 120.5807; lr 0.1913:  28% 57/200 [01:14<02:28,  1.04s/it]\u001b[A\n",
            "1_01: loss 120.8619; lr 0.1913:  28% 57/200 [01:15<02:28,  1.04s/it]\u001b[A\n",
            "1_01: loss 120.8619; lr 0.1913:  29% 58/200 [01:15<02:28,  1.04s/it]\u001b[A\n",
            "1_01: loss 119.6494; lr 0.1913:  29% 58/200 [01:16<02:28,  1.04s/it]\u001b[A\n",
            "1_01: loss 119.6494; lr 0.1913:  30% 59/200 [01:16<02:26,  1.04s/it]\u001b[A\n",
            "1_01: loss 117.4178; lr 0.1913:  30% 59/200 [01:17<02:26,  1.04s/it]\u001b[A\n",
            "1_01: loss 117.4178; lr 0.1913:  30% 60/200 [01:17<02:25,  1.04s/it]\u001b[A\n",
            "1_01: loss 116.3284; lr 0.1913:  30% 60/200 [01:18<02:25,  1.04s/it]\u001b[A\n",
            "1_01: loss 116.3284; lr 0.1913:  30% 61/200 [01:18<02:24,  1.04s/it]\u001b[A\n",
            "1_01: loss 115.9900; lr 0.1913:  30% 61/200 [01:19<02:24,  1.04s/it]\u001b[A\n",
            "1_01: loss 115.9900; lr 0.1913:  31% 62/200 [01:19<02:23,  1.04s/it]\u001b[A\n",
            "1_01: loss 116.6482; lr 0.1913:  31% 62/200 [01:20<02:23,  1.04s/it]\u001b[A\n",
            "1_01: loss 116.6482; lr 0.1913:  32% 63/200 [01:20<02:22,  1.04s/it]\u001b[A\n",
            "1_01: loss 118.7125; lr 0.1722:  32% 63/200 [01:21<02:22,  1.04s/it]\u001b[A\n",
            "1_01: loss 118.7125; lr 0.1722:  32% 64/200 [01:21<02:21,  1.04s/it]\u001b[A\n",
            "1_01: loss 117.6206; lr 0.1722:  32% 64/200 [01:22<02:21,  1.04s/it]\u001b[A\n",
            "1_01: loss 117.6206; lr 0.1722:  32% 65/200 [01:22<02:20,  1.04s/it]\u001b[A\n",
            "1_01: loss 115.7143; lr 0.1722:  32% 65/200 [01:23<02:20,  1.04s/it]\u001b[A\n",
            "1_01: loss 115.7143; lr 0.1722:  33% 66/200 [01:23<02:19,  1.04s/it]\u001b[A\n",
            "1_01: loss 115.5053; lr 0.1722:  33% 66/200 [01:24<02:19,  1.04s/it]\u001b[A\n",
            "1_01: loss 115.5053; lr 0.1722:  34% 67/200 [01:24<02:18,  1.04s/it]\u001b[A\n",
            "1_01: loss 113.8663; lr 0.1722:  34% 67/200 [01:25<02:18,  1.04s/it]\u001b[A\n",
            "1_01: loss 113.8663; lr 0.1722:  34% 68/200 [01:25<02:17,  1.04s/it]\u001b[A\n",
            "1_01: loss 115.2464; lr 0.1722:  34% 68/200 [01:26<02:17,  1.04s/it]\u001b[A\n",
            "1_01: loss 115.2464; lr 0.1722:  34% 69/200 [01:26<02:16,  1.04s/it]\u001b[A\n",
            "1_01: loss 117.5581; lr 0.1722:  34% 69/200 [01:27<02:16,  1.04s/it]\u001b[A\n",
            "1_01: loss 117.5581; lr 0.1722:  35% 70/200 [01:27<02:15,  1.04s/it]\u001b[A\n",
            "1_01: loss 112.9536; lr 0.1722:  35% 70/200 [01:28<02:15,  1.04s/it]\u001b[A\n",
            "1_01: loss 112.9536; lr 0.1722:  36% 71/200 [01:28<02:14,  1.04s/it]\u001b[A\n",
            "1_01: loss 115.3269; lr 0.1550:  36% 71/200 [01:29<02:14,  1.04s/it]\u001b[A\n",
            "1_01: loss 115.3269; lr 0.1550:  36% 72/200 [01:29<02:13,  1.04s/it]\u001b[A\n",
            "1_01: loss 115.8018; lr 0.1550:  36% 72/200 [01:30<02:13,  1.04s/it]\u001b[A\n",
            "1_01: loss 115.8018; lr 0.1550:  36% 73/200 [01:30<02:11,  1.04s/it]\u001b[A\n",
            "1_01: loss 113.9966; lr 0.1550:  36% 73/200 [01:31<02:11,  1.04s/it]\u001b[A\n",
            "1_01: loss 113.9966; lr 0.1550:  37% 74/200 [01:31<02:10,  1.04s/it]\u001b[A\n",
            "1_01: loss 113.2352; lr 0.1550:  37% 74/200 [01:32<02:10,  1.04s/it]\u001b[A\n",
            "1_01: loss 113.2352; lr 0.1550:  38% 75/200 [01:32<02:10,  1.04s/it]\u001b[A\n",
            "1_01: loss 115.5762; lr 0.1550:  38% 75/200 [01:33<02:10,  1.04s/it]\u001b[A\n",
            "1_01: loss 115.5762; lr 0.1550:  38% 76/200 [01:33<02:08,  1.04s/it]\u001b[A\n",
            "1_01: loss 114.2919; lr 0.1550:  38% 76/200 [01:34<02:08,  1.04s/it]\u001b[A\n",
            "1_01: loss 114.2919; lr 0.1550:  38% 77/200 [01:34<02:08,  1.04s/it]\u001b[A\n",
            "1_01: loss 113.3621; lr 0.1550:  38% 77/200 [01:36<02:08,  1.04s/it]\u001b[A\n",
            "1_01: loss 113.3621; lr 0.1550:  39% 78/200 [01:36<02:06,  1.04s/it]\u001b[A\n",
            "1_01: loss 111.8568; lr 0.1550:  39% 78/200 [01:37<02:06,  1.04s/it]\u001b[A\n",
            "1_01: loss 111.8568; lr 0.1550:  40% 79/200 [01:37<02:06,  1.04s/it]\u001b[A\n",
            "1_01: loss 111.5689; lr 0.1395:  40% 79/200 [01:38<02:06,  1.04s/it]\u001b[A\n",
            "1_01: loss 111.5689; lr 0.1395:  40% 80/200 [01:38<02:05,  1.05s/it]\u001b[A\n",
            "1_01: loss 111.5289; lr 0.1395:  40% 80/200 [01:39<02:05,  1.05s/it]\u001b[A\n",
            "1_01: loss 111.5289; lr 0.1395:  40% 81/200 [01:39<02:04,  1.04s/it]\u001b[A\n",
            "1_01: loss 110.8066; lr 0.1395:  40% 81/200 [01:40<02:04,  1.04s/it]\u001b[A\n",
            "1_01: loss 110.8066; lr 0.1395:  41% 82/200 [01:40<02:03,  1.04s/it]\u001b[A\n",
            "1_01: loss 110.2428; lr 0.1395:  41% 82/200 [01:41<02:03,  1.04s/it]\u001b[A\n",
            "1_01: loss 110.2428; lr 0.1395:  42% 83/200 [01:41<02:01,  1.04s/it]\u001b[A\n",
            "1_01: loss 110.9127; lr 0.1395:  42% 83/200 [01:42<02:01,  1.04s/it]\u001b[A\n",
            "1_01: loss 110.9127; lr 0.1395:  42% 84/200 [01:42<02:00,  1.04s/it]\u001b[A\n",
            "1_01: loss 113.8563; lr 0.1395:  42% 84/200 [01:43<02:00,  1.04s/it]\u001b[A\n",
            "1_01: loss 113.8563; lr 0.1395:  42% 85/200 [01:43<01:59,  1.04s/it]\u001b[A\n",
            "1_01: loss 110.8670; lr 0.1395:  42% 85/200 [01:44<01:59,  1.04s/it]\u001b[A\n",
            "1_01: loss 110.8670; lr 0.1395:  43% 86/200 [01:44<01:58,  1.04s/it]\u001b[A\n",
            "1_01: loss 112.2709; lr 0.1395:  43% 86/200 [01:45<01:58,  1.04s/it]\u001b[A\n",
            "1_01: loss 112.2709; lr 0.1395:  44% 87/200 [01:45<01:57,  1.04s/it]\u001b[A\n",
            "1_01: loss 113.4050; lr 0.1255:  44% 87/200 [01:46<01:57,  1.04s/it]\u001b[A\n",
            "1_01: loss 113.4050; lr 0.1255:  44% 88/200 [01:46<01:56,  1.04s/it]\u001b[A\n",
            "1_01: loss 110.1157; lr 0.1255:  44% 88/200 [01:47<01:56,  1.04s/it]\u001b[A\n",
            "1_01: loss 110.1157; lr 0.1255:  44% 89/200 [01:47<01:55,  1.04s/it]\u001b[A\n",
            "1_01: loss 109.9288; lr 0.1255:  44% 89/200 [01:48<01:55,  1.04s/it]\u001b[A\n",
            "1_01: loss 109.9288; lr 0.1255:  45% 90/200 [01:48<01:54,  1.04s/it]\u001b[A\n",
            "1_01: loss 109.2033; lr 0.1255:  45% 90/200 [01:49<01:54,  1.04s/it]\u001b[A\n",
            "1_01: loss 109.2033; lr 0.1255:  46% 91/200 [01:49<01:53,  1.04s/it]\u001b[A\n",
            "1_01: loss 109.0442; lr 0.1255:  46% 91/200 [01:50<01:53,  1.04s/it]\u001b[A\n",
            "1_01: loss 109.0442; lr 0.1255:  46% 92/200 [01:50<01:52,  1.04s/it]\u001b[A\n",
            "1_01: loss 109.6172; lr 0.1255:  46% 92/200 [01:51<01:52,  1.04s/it]\u001b[A\n",
            "1_01: loss 109.6172; lr 0.1255:  46% 93/200 [01:51<01:51,  1.05s/it]\u001b[A\n",
            "1_01: loss 109.2334; lr 0.1255:  46% 93/200 [01:52<01:51,  1.05s/it]\u001b[A\n",
            "1_01: loss 109.2334; lr 0.1255:  47% 94/200 [01:52<01:50,  1.05s/it]\u001b[A\n",
            "1_01: loss 109.3198; lr 0.1255:  47% 94/200 [01:53<01:50,  1.05s/it]\u001b[A\n",
            "1_01: loss 109.3198; lr 0.1255:  48% 95/200 [01:53<01:49,  1.04s/it]\u001b[A\n",
            "1_01: loss 109.6323; lr 0.1130:  48% 95/200 [01:54<01:49,  1.04s/it]\u001b[A\n",
            "1_01: loss 109.6323; lr 0.1130:  48% 96/200 [01:54<01:49,  1.05s/it]\u001b[A\n",
            "1_01: loss 110.1454; lr 0.1130:  48% 96/200 [01:55<01:49,  1.05s/it]\u001b[A\n",
            "1_01: loss 110.1454; lr 0.1130:  48% 97/200 [01:55<01:47,  1.04s/it]\u001b[A\n",
            "1_01: loss 109.2736; lr 0.1130:  48% 97/200 [01:56<01:47,  1.04s/it]\u001b[A\n",
            "1_01: loss 109.2736; lr 0.1130:  49% 98/200 [01:56<01:47,  1.05s/it]\u001b[A\n",
            "1_01: loss 109.1746; lr 0.1130:  49% 98/200 [01:57<01:47,  1.05s/it]\u001b[A\n",
            "1_01: loss 109.1746; lr 0.1130:  50% 99/200 [01:57<01:45,  1.05s/it]\u001b[A\n",
            "1_01: loss 108.6653; lr 0.1130:  50% 99/200 [01:58<01:45,  1.05s/it]\u001b[A\n",
            "1_01: loss 108.6653; lr 0.1130:  50% 100/200 [01:58<01:44,  1.04s/it]\u001b[A\n",
            "1_01: loss 108.0486; lr 0.1130:  50% 100/200 [02:00<01:44,  1.04s/it]\u001b[A\n",
            "1_01: loss 108.0486; lr 0.1130:  50% 101/200 [02:00<01:43,  1.04s/it]\u001b[A\n",
            "1_01: loss 107.7966; lr 0.1130:  50% 101/200 [02:01<01:43,  1.04s/it]\u001b[A\n",
            "1_01: loss 107.7966; lr 0.1130:  51% 102/200 [02:01<01:42,  1.05s/it]\u001b[A\n",
            "1_01: loss 107.9269; lr 0.1130:  51% 102/200 [02:02<01:42,  1.05s/it]\u001b[A\n",
            "1_01: loss 107.9269; lr 0.1130:  52% 103/200 [02:02<01:41,  1.05s/it]\u001b[A\n",
            "1_01: loss 108.8509; lr 0.1017:  52% 103/200 [02:03<01:41,  1.05s/it]\u001b[A\n",
            "1_01: loss 108.8509; lr 0.1017:  52% 104/200 [02:03<01:40,  1.04s/it]\u001b[A\n",
            "1_01: loss 108.0632; lr 0.1017:  52% 104/200 [02:04<01:40,  1.04s/it]\u001b[A\n",
            "1_01: loss 108.0632; lr 0.1017:  52% 105/200 [02:04<01:38,  1.04s/it]\u001b[A\n",
            "1_01: loss 108.2724; lr 0.1017:  52% 105/200 [02:05<01:38,  1.04s/it]\u001b[A\n",
            "1_01: loss 108.2724; lr 0.1017:  53% 106/200 [02:05<01:37,  1.04s/it]\u001b[A\n",
            "1_01: loss 108.7283; lr 0.1017:  53% 106/200 [02:06<01:37,  1.04s/it]\u001b[A\n",
            "1_01: loss 108.7283; lr 0.1017:  54% 107/200 [02:06<01:37,  1.04s/it]\u001b[A\n",
            "1_01: loss 108.7543; lr 0.1017:  54% 107/200 [02:07<01:37,  1.04s/it]\u001b[A\n",
            "1_01: loss 108.7543; lr 0.1017:  54% 108/200 [02:07<01:36,  1.04s/it]\u001b[A\n",
            "1_01: loss 107.6635; lr 0.1017:  54% 108/200 [02:08<01:36,  1.04s/it]\u001b[A\n",
            "1_01: loss 107.6635; lr 0.1017:  55% 109/200 [02:08<01:34,  1.04s/it]\u001b[A\n",
            "1_01: loss 107.2304; lr 0.1017:  55% 109/200 [02:09<01:34,  1.04s/it]\u001b[A\n",
            "1_01: loss 107.2304; lr 0.1017:  55% 110/200 [02:09<01:33,  1.04s/it]\u001b[A\n",
            "1_01: loss 106.9486; lr 0.1017:  55% 110/200 [02:10<01:33,  1.04s/it]\u001b[A\n",
            "1_01: loss 106.9486; lr 0.1017:  56% 111/200 [02:10<01:32,  1.04s/it]\u001b[A\n",
            "1_01: loss 106.5835; lr 0.0915:  56% 111/200 [02:11<01:32,  1.04s/it]\u001b[A\n",
            "1_01: loss 106.5835; lr 0.0915:  56% 112/200 [02:11<01:31,  1.04s/it]\u001b[A\n",
            "1_01: loss 106.4378; lr 0.0915:  56% 112/200 [02:12<01:31,  1.04s/it]\u001b[A\n",
            "1_01: loss 106.4378; lr 0.0915:  56% 113/200 [02:12<01:30,  1.04s/it]\u001b[A\n",
            "1_01: loss 106.0576; lr 0.0915:  56% 113/200 [02:13<01:30,  1.04s/it]\u001b[A\n",
            "1_01: loss 106.0576; lr 0.0915:  57% 114/200 [02:13<01:29,  1.04s/it]\u001b[A\n",
            "1_01: loss 106.2454; lr 0.0915:  57% 114/200 [02:14<01:29,  1.04s/it]\u001b[A\n",
            "1_01: loss 106.2454; lr 0.0915:  57% 115/200 [02:14<01:29,  1.05s/it]\u001b[A\n",
            "1_01: loss 106.8353; lr 0.0915:  57% 115/200 [02:15<01:29,  1.05s/it]\u001b[A\n",
            "1_01: loss 106.8353; lr 0.0915:  58% 116/200 [02:15<01:27,  1.05s/it]\u001b[A\n",
            "1_01: loss 107.4424; lr 0.0915:  58% 116/200 [02:16<01:27,  1.05s/it]\u001b[A\n",
            "1_01: loss 107.4424; lr 0.0915:  58% 117/200 [02:16<01:27,  1.05s/it]\u001b[A\n",
            "1_01: loss 107.1005; lr 0.0915:  58% 117/200 [02:17<01:27,  1.05s/it]\u001b[A\n",
            "1_01: loss 107.1005; lr 0.0915:  59% 118/200 [02:17<01:26,  1.05s/it]\u001b[A\n",
            "1_01: loss 108.4442; lr 0.0915:  59% 118/200 [02:18<01:26,  1.05s/it]\u001b[A\n",
            "1_01: loss 108.4442; lr 0.0915:  60% 119/200 [02:18<01:25,  1.05s/it]\u001b[A\n",
            "1_01: loss 105.8621; lr 0.0824:  60% 119/200 [02:19<01:25,  1.05s/it]\u001b[A\n",
            "1_01: loss 105.8621; lr 0.0824:  60% 120/200 [02:19<01:24,  1.05s/it]\u001b[A\n",
            "1_01: loss 106.0860; lr 0.0824:  60% 120/200 [02:20<01:24,  1.05s/it]\u001b[A\n",
            "1_01: loss 106.0860; lr 0.0824:  60% 121/200 [02:20<01:22,  1.05s/it]\u001b[A\n",
            "1_01: loss 106.1868; lr 0.0824:  60% 121/200 [02:21<01:22,  1.05s/it]\u001b[A\n",
            "1_01: loss 106.1868; lr 0.0824:  61% 122/200 [02:21<01:21,  1.05s/it]\u001b[A\n",
            "1_01: loss 105.9361; lr 0.0824:  61% 122/200 [02:23<01:21,  1.05s/it]\u001b[A\n",
            "1_01: loss 105.9361; lr 0.0824:  62% 123/200 [02:23<01:20,  1.04s/it]\u001b[A\n",
            "1_01: loss 106.4666; lr 0.0824:  62% 123/200 [02:24<01:20,  1.04s/it]\u001b[A\n",
            "1_01: loss 106.4666; lr 0.0824:  62% 124/200 [02:24<01:19,  1.05s/it]\u001b[A\n",
            "1_01: loss 106.0155; lr 0.0824:  62% 124/200 [02:25<01:19,  1.05s/it]\u001b[A\n",
            "1_01: loss 106.0155; lr 0.0824:  62% 125/200 [02:25<01:18,  1.04s/it]\u001b[A\n",
            "1_01: loss 105.7228; lr 0.0824:  62% 125/200 [02:26<01:18,  1.04s/it]\u001b[A\n",
            "1_01: loss 105.7228; lr 0.0824:  63% 126/200 [02:26<01:17,  1.04s/it]\u001b[A\n",
            "1_01: loss 105.5831; lr 0.0824:  63% 126/200 [02:27<01:17,  1.04s/it]\u001b[A\n",
            "1_01: loss 105.5831; lr 0.0824:  64% 127/200 [02:27<01:16,  1.05s/it]\u001b[A\n",
            "1_01: loss 105.3744; lr 0.0741:  64% 127/200 [02:28<01:16,  1.05s/it]\u001b[A\n",
            "1_01: loss 105.3744; lr 0.0741:  64% 128/200 [02:28<01:15,  1.04s/it]\u001b[A\n",
            "1_01: loss 105.1742; lr 0.0741:  64% 128/200 [02:29<01:15,  1.04s/it]\u001b[A\n",
            "1_01: loss 105.1742; lr 0.0741:  64% 129/200 [02:29<01:14,  1.05s/it]\u001b[A\n",
            "1_01: loss 105.1385; lr 0.0741:  64% 129/200 [02:30<01:14,  1.05s/it]\u001b[A\n",
            "1_01: loss 105.1385; lr 0.0741:  65% 130/200 [02:30<01:13,  1.05s/it]\u001b[A\n",
            "1_01: loss 104.9879; lr 0.0741:  65% 130/200 [02:31<01:13,  1.05s/it]\u001b[A\n",
            "1_01: loss 104.9879; lr 0.0741:  66% 131/200 [02:31<01:12,  1.05s/it]\u001b[A\n",
            "\n",
            "                                                                     \u001b[A1_01  Loss 104.9879\n",
            " 50% 1/2 [02:36<02:36, 156.00s/it]Rects:\n",
            "rectangles[[(46, 81) (201, 236)]]\n",
            "Saving mask masks/2_01.png\n",
            "Loading mask masks/2_01.png\n",
            "\n",
            "  0% 0/200 [00:00<?, ?it/s]\u001b[A\n",
            "2_01: loss 281.4632; lr 0.4000:   0% 0/200 [00:07<?, ?it/s]\u001b[A\n",
            "2_01: loss 281.4632; lr 0.4000:   0% 1/200 [00:07<24:02,  7.25s/it]\u001b[A\n",
            "2_01: loss 251.5516; lr 0.4000:   0% 1/200 [00:08<24:02,  7.25s/it]\u001b[A\n",
            "2_01: loss 251.5516; lr 0.4000:   1% 2/200 [00:08<11:57,  3.62s/it]\u001b[A\n",
            "2_01: loss 225.5859; lr 0.4000:   1% 2/200 [00:09<11:57,  3.62s/it]\u001b[A\n",
            "2_01: loss 225.5859; lr 0.4000:   2% 3/200 [00:09<08:01,  2.45s/it]\u001b[A\n",
            "2_01: loss 205.3415; lr 0.4000:   2% 3/200 [00:10<08:01,  2.45s/it]\u001b[A\n",
            "2_01: loss 205.3415; lr 0.4000:   2% 4/200 [00:10<06:11,  1.89s/it]\u001b[A\n",
            "2_01: loss 186.8294; lr 0.4000:   2% 4/200 [00:11<06:11,  1.89s/it]\u001b[A\n",
            "2_01: loss 186.8294; lr 0.4000:   2% 5/200 [00:11<05:10,  1.59s/it]\u001b[A\n",
            "2_01: loss 175.6290; lr 0.4000:   2% 5/200 [00:12<05:10,  1.59s/it]\u001b[A\n",
            "2_01: loss 175.6290; lr 0.4000:   3% 6/200 [00:12<04:32,  1.41s/it]\u001b[A\n",
            "2_01: loss 166.1215; lr 0.4000:   3% 6/200 [00:13<04:32,  1.41s/it]\u001b[A\n",
            "2_01: loss 166.1215; lr 0.4000:   4% 7/200 [00:13<04:09,  1.29s/it]\u001b[A\n",
            "2_01: loss 160.9734; lr 0.3600:   4% 7/200 [00:14<04:09,  1.29s/it]\u001b[A\n",
            "2_01: loss 160.9734; lr 0.3600:   4% 8/200 [00:14<03:52,  1.21s/it]\u001b[A\n",
            "2_01: loss 158.7493; lr 0.3600:   4% 8/200 [00:15<03:52,  1.21s/it]\u001b[A\n",
            "2_01: loss 158.7493; lr 0.3600:   4% 9/200 [00:15<03:41,  1.16s/it]\u001b[A\n",
            "2_01: loss 156.2493; lr 0.3600:   4% 9/200 [00:16<03:41,  1.16s/it]\u001b[A\n",
            "2_01: loss 156.2493; lr 0.3600:   5% 10/200 [00:16<03:33,  1.12s/it]\u001b[A\n",
            "2_01: loss 151.8595; lr 0.3600:   5% 10/200 [00:17<03:33,  1.12s/it]\u001b[A\n",
            "2_01: loss 151.8595; lr 0.3600:   6% 11/200 [00:17<03:27,  1.10s/it]\u001b[A\n",
            "2_01: loss 150.0016; lr 0.3600:   6% 11/200 [00:18<03:27,  1.10s/it]\u001b[A\n",
            "2_01: loss 150.0016; lr 0.3600:   6% 12/200 [00:18<03:23,  1.08s/it]\u001b[A\n",
            "2_01: loss 146.6126; lr 0.3600:   6% 12/200 [00:19<03:23,  1.08s/it]\u001b[A\n",
            "2_01: loss 146.6126; lr 0.3600:   6% 13/200 [00:19<03:20,  1.07s/it]\u001b[A\n",
            "2_01: loss 149.0714; lr 0.3600:   6% 13/200 [00:20<03:20,  1.07s/it]\u001b[A\n",
            "2_01: loss 149.0714; lr 0.3600:   7% 14/200 [00:20<03:17,  1.06s/it]\u001b[A\n",
            "2_01: loss 153.1265; lr 0.3600:   7% 14/200 [00:21<03:17,  1.06s/it]\u001b[A\n",
            "2_01: loss 153.1265; lr 0.3600:   8% 15/200 [00:21<03:15,  1.06s/it]\u001b[A\n",
            "2_01: loss 142.9007; lr 0.3240:   8% 15/200 [00:22<03:15,  1.06s/it]\u001b[A\n",
            "2_01: loss 142.9007; lr 0.3240:   8% 16/200 [00:22<03:13,  1.05s/it]\u001b[A\n",
            "2_01: loss 142.4615; lr 0.3240:   8% 16/200 [00:24<03:13,  1.05s/it]\u001b[A\n",
            "2_01: loss 142.4615; lr 0.3240:   8% 17/200 [00:24<03:12,  1.05s/it]\u001b[A\n",
            "2_01: loss 139.6891; lr 0.3240:   8% 17/200 [00:25<03:12,  1.05s/it]\u001b[A\n",
            "2_01: loss 139.6891; lr 0.3240:   9% 18/200 [00:25<03:10,  1.04s/it]\u001b[A\n",
            "2_01: loss 137.7203; lr 0.3240:   9% 18/200 [00:26<03:10,  1.04s/it]\u001b[A\n",
            "2_01: loss 137.7203; lr 0.3240:  10% 19/200 [00:26<03:08,  1.04s/it]\u001b[A\n",
            "2_01: loss 136.3547; lr 0.3240:  10% 19/200 [00:27<03:08,  1.04s/it]\u001b[A\n",
            "2_01: loss 136.3547; lr 0.3240:  10% 20/200 [00:27<03:07,  1.04s/it]\u001b[A\n",
            "2_01: loss 134.7875; lr 0.3240:  10% 20/200 [00:28<03:07,  1.04s/it]\u001b[A\n",
            "2_01: loss 134.7875; lr 0.3240:  10% 21/200 [00:28<03:05,  1.04s/it]\u001b[A\n",
            "2_01: loss 134.9989; lr 0.3240:  10% 21/200 [00:29<03:05,  1.04s/it]\u001b[A\n",
            "2_01: loss 134.9989; lr 0.3240:  11% 22/200 [00:29<03:04,  1.04s/it]\u001b[A\n",
            "2_01: loss 142.7271; lr 0.3240:  11% 22/200 [00:30<03:04,  1.04s/it]\u001b[A\n",
            "2_01: loss 142.7271; lr 0.3240:  12% 23/200 [00:30<03:03,  1.04s/it]\u001b[A\n",
            "2_01: loss 133.5179; lr 0.2916:  12% 23/200 [00:31<03:03,  1.04s/it]\u001b[A\n",
            "2_01: loss 133.5179; lr 0.2916:  12% 24/200 [00:31<03:03,  1.04s/it]\u001b[A\n",
            "2_01: loss 137.0327; lr 0.2916:  12% 24/200 [00:32<03:03,  1.04s/it]\u001b[A\n",
            "2_01: loss 137.0327; lr 0.2916:  12% 25/200 [00:32<03:02,  1.04s/it]\u001b[A\n",
            "2_01: loss 136.7838; lr 0.2916:  12% 25/200 [00:33<03:02,  1.04s/it]\u001b[A\n",
            "2_01: loss 136.7838; lr 0.2916:  13% 26/200 [00:33<03:01,  1.04s/it]\u001b[A\n",
            "2_01: loss 139.3218; lr 0.2916:  13% 26/200 [00:34<03:01,  1.04s/it]\u001b[A\n",
            "2_01: loss 139.3218; lr 0.2916:  14% 27/200 [00:34<03:00,  1.04s/it]\u001b[A\n",
            "2_01: loss 133.2474; lr 0.2916:  14% 27/200 [00:35<03:00,  1.04s/it]\u001b[A\n",
            "2_01: loss 133.2474; lr 0.2916:  14% 28/200 [00:35<02:59,  1.04s/it]\u001b[A\n",
            "2_01: loss 130.0753; lr 0.2916:  14% 28/200 [00:36<02:59,  1.04s/it]\u001b[A\n",
            "2_01: loss 130.0753; lr 0.2916:  14% 29/200 [00:36<02:57,  1.04s/it]\u001b[A\n",
            "2_01: loss 128.8929; lr 0.2916:  14% 29/200 [00:37<02:57,  1.04s/it]\u001b[A\n",
            "2_01: loss 128.8929; lr 0.2916:  15% 30/200 [00:37<02:56,  1.04s/it]\u001b[A\n",
            "2_01: loss 128.1682; lr 0.2916:  15% 30/200 [00:38<02:56,  1.04s/it]\u001b[A\n",
            "2_01: loss 128.1682; lr 0.2916:  16% 31/200 [00:38<02:54,  1.03s/it]\u001b[A\n",
            "2_01: loss 126.1757; lr 0.2624:  16% 31/200 [00:39<02:54,  1.03s/it]\u001b[A\n",
            "2_01: loss 126.1757; lr 0.2624:  16% 32/200 [00:39<02:54,  1.04s/it]\u001b[A\n",
            "2_01: loss 125.6771; lr 0.2624:  16% 32/200 [00:40<02:54,  1.04s/it]\u001b[A\n",
            "2_01: loss 125.6771; lr 0.2624:  16% 33/200 [00:40<02:52,  1.03s/it]\u001b[A\n",
            "2_01: loss 125.1594; lr 0.2624:  16% 33/200 [00:41<02:52,  1.03s/it]\u001b[A\n",
            "2_01: loss 125.1594; lr 0.2624:  17% 34/200 [00:41<02:52,  1.04s/it]\u001b[A\n",
            "2_01: loss 124.6840; lr 0.2624:  17% 34/200 [00:42<02:52,  1.04s/it]\u001b[A\n",
            "2_01: loss 124.6840; lr 0.2624:  18% 35/200 [00:42<02:51,  1.04s/it]\u001b[A\n",
            "2_01: loss 124.1667; lr 0.2624:  18% 35/200 [00:43<02:51,  1.04s/it]\u001b[A\n",
            "2_01: loss 124.1667; lr 0.2624:  18% 36/200 [00:43<02:50,  1.04s/it]\u001b[A\n",
            "2_01: loss 125.9762; lr 0.2624:  18% 36/200 [00:44<02:50,  1.04s/it]\u001b[A\n",
            "2_01: loss 125.9762; lr 0.2624:  18% 37/200 [00:44<02:49,  1.04s/it]\u001b[A\n",
            "2_01: loss 130.8603; lr 0.2624:  18% 37/200 [00:45<02:49,  1.04s/it]\u001b[A\n",
            "2_01: loss 130.8603; lr 0.2624:  19% 38/200 [00:45<02:48,  1.04s/it]\u001b[A\n",
            "2_01: loss 129.5984; lr 0.2624:  19% 38/200 [00:46<02:48,  1.04s/it]\u001b[A\n",
            "2_01: loss 129.5984; lr 0.2624:  20% 39/200 [00:46<02:47,  1.04s/it]\u001b[A\n",
            "2_01: loss 124.6657; lr 0.2362:  20% 39/200 [00:47<02:47,  1.04s/it]\u001b[A\n",
            "2_01: loss 124.6657; lr 0.2362:  20% 40/200 [00:47<02:47,  1.04s/it]\u001b[A\n",
            "2_01: loss 128.1771; lr 0.2362:  20% 40/200 [00:48<02:47,  1.04s/it]\u001b[A\n",
            "2_01: loss 128.1771; lr 0.2362:  20% 41/200 [00:48<02:45,  1.04s/it]\u001b[A\n",
            "2_01: loss 123.3822; lr 0.2362:  20% 41/200 [00:50<02:45,  1.04s/it]\u001b[A\n",
            "2_01: loss 123.3822; lr 0.2362:  21% 42/200 [00:50<02:44,  1.04s/it]\u001b[A\n",
            "2_01: loss 122.0912; lr 0.2362:  21% 42/200 [00:51<02:44,  1.04s/it]\u001b[A\n",
            "2_01: loss 122.0912; lr 0.2362:  22% 43/200 [00:51<02:44,  1.04s/it]\u001b[A\n",
            "2_01: loss 122.1789; lr 0.2362:  22% 43/200 [00:52<02:44,  1.04s/it]\u001b[A\n",
            "2_01: loss 122.1789; lr 0.2362:  22% 44/200 [00:52<02:42,  1.04s/it]\u001b[A\n",
            "2_01: loss 122.7643; lr 0.2362:  22% 44/200 [00:53<02:42,  1.04s/it]\u001b[A\n",
            "2_01: loss 122.7643; lr 0.2362:  22% 45/200 [00:53<02:41,  1.04s/it]\u001b[A\n",
            "2_01: loss 122.5364; lr 0.2362:  22% 45/200 [00:54<02:41,  1.04s/it]\u001b[A\n",
            "2_01: loss 122.5364; lr 0.2362:  23% 46/200 [00:54<02:40,  1.04s/it]\u001b[A\n",
            "2_01: loss 123.9775; lr 0.2362:  23% 46/200 [00:55<02:40,  1.04s/it]\u001b[A\n",
            "2_01: loss 123.9775; lr 0.2362:  24% 47/200 [00:55<02:39,  1.04s/it]\u001b[A\n",
            "2_01: loss 121.2818; lr 0.2126:  24% 47/200 [00:56<02:39,  1.04s/it]\u001b[A\n",
            "2_01: loss 121.2818; lr 0.2126:  24% 48/200 [00:56<02:38,  1.05s/it]\u001b[A\n",
            "2_01: loss 122.8357; lr 0.2126:  24% 48/200 [00:57<02:38,  1.05s/it]\u001b[A\n",
            "2_01: loss 122.8357; lr 0.2126:  24% 49/200 [00:57<02:37,  1.04s/it]\u001b[A\n",
            "2_01: loss 123.7041; lr 0.2126:  24% 49/200 [00:58<02:37,  1.04s/it]\u001b[A\n",
            "2_01: loss 123.7041; lr 0.2126:  25% 50/200 [00:58<02:36,  1.04s/it]\u001b[A\n",
            "2_01: loss 120.2520; lr 0.2126:  25% 50/200 [00:59<02:36,  1.04s/it]\u001b[A\n",
            "2_01: loss 120.2520; lr 0.2126:  26% 51/200 [00:59<02:35,  1.04s/it]\u001b[A\n",
            "2_01: loss 121.0264; lr 0.2126:  26% 51/200 [01:00<02:35,  1.04s/it]\u001b[A\n",
            "2_01: loss 121.0264; lr 0.2126:  26% 52/200 [01:00<02:34,  1.04s/it]\u001b[A\n",
            "2_01: loss 119.8394; lr 0.2126:  26% 52/200 [01:01<02:34,  1.04s/it]\u001b[A\n",
            "2_01: loss 119.8394; lr 0.2126:  26% 53/200 [01:01<02:33,  1.04s/it]\u001b[A\n",
            "2_01: loss 120.7287; lr 0.2126:  26% 53/200 [01:02<02:33,  1.04s/it]\u001b[A\n",
            "2_01: loss 120.7287; lr 0.2126:  27% 54/200 [01:02<02:31,  1.04s/it]\u001b[A\n",
            "2_01: loss 120.5992; lr 0.2126:  27% 54/200 [01:03<02:31,  1.04s/it]\u001b[A\n",
            "2_01: loss 120.5992; lr 0.2126:  28% 55/200 [01:03<02:30,  1.04s/it]\u001b[A\n",
            "2_01: loss 120.0688; lr 0.1913:  28% 55/200 [01:04<02:30,  1.04s/it]\u001b[A\n",
            "2_01: loss 120.0688; lr 0.1913:  28% 56/200 [01:04<02:29,  1.04s/it]\u001b[A\n",
            "2_01: loss 118.8229; lr 0.1913:  28% 56/200 [01:05<02:29,  1.04s/it]\u001b[A\n",
            "2_01: loss 118.8229; lr 0.1913:  28% 57/200 [01:05<02:28,  1.04s/it]\u001b[A\n",
            "2_01: loss 118.3776; lr 0.1913:  28% 57/200 [01:06<02:28,  1.04s/it]\u001b[A\n",
            "2_01: loss 118.3776; lr 0.1913:  29% 58/200 [01:06<02:27,  1.04s/it]\u001b[A\n",
            "2_01: loss 117.5316; lr 0.1913:  29% 58/200 [01:07<02:27,  1.04s/it]\u001b[A\n",
            "2_01: loss 117.5316; lr 0.1913:  30% 59/200 [01:07<02:26,  1.04s/it]\u001b[A\n",
            "2_01: loss 117.3546; lr 0.1913:  30% 59/200 [01:08<02:26,  1.04s/it]\u001b[A\n",
            "2_01: loss 117.3546; lr 0.1913:  30% 60/200 [01:08<02:25,  1.04s/it]\u001b[A\n",
            "2_01: loss 117.7124; lr 0.1913:  30% 60/200 [01:09<02:25,  1.04s/it]\u001b[A\n",
            "2_01: loss 117.7124; lr 0.1913:  30% 61/200 [01:09<02:25,  1.05s/it]\u001b[A\n",
            "2_01: loss 117.7329; lr 0.1913:  30% 61/200 [01:10<02:25,  1.05s/it]\u001b[A\n",
            "2_01: loss 117.7329; lr 0.1913:  31% 62/200 [01:10<02:24,  1.05s/it]\u001b[A\n",
            "2_01: loss 116.9236; lr 0.1913:  31% 62/200 [01:11<02:24,  1.05s/it]\u001b[A\n",
            "2_01: loss 116.9236; lr 0.1913:  32% 63/200 [01:11<02:23,  1.05s/it]\u001b[A\n",
            "2_01: loss 116.1264; lr 0.1722:  32% 63/200 [01:12<02:23,  1.05s/it]\u001b[A\n",
            "2_01: loss 116.1264; lr 0.1722:  32% 64/200 [01:12<02:22,  1.05s/it]\u001b[A\n",
            "2_01: loss 116.0908; lr 0.1722:  32% 64/200 [01:14<02:22,  1.05s/it]\u001b[A\n",
            "2_01: loss 116.0908; lr 0.1722:  32% 65/200 [01:14<02:21,  1.05s/it]\u001b[A\n",
            "2_01: loss 117.6749; lr 0.1722:  32% 65/200 [01:15<02:21,  1.05s/it]\u001b[A\n",
            "2_01: loss 117.6749; lr 0.1722:  33% 66/200 [01:15<02:20,  1.04s/it]\u001b[A\n",
            "2_01: loss 120.2919; lr 0.1722:  33% 66/200 [01:16<02:20,  1.04s/it]\u001b[A\n",
            "2_01: loss 120.2919; lr 0.1722:  34% 67/200 [01:16<02:18,  1.04s/it]\u001b[A\n",
            "2_01: loss 117.7496; lr 0.1722:  34% 67/200 [01:17<02:18,  1.04s/it]\u001b[A\n",
            "2_01: loss 117.7496; lr 0.1722:  34% 68/200 [01:17<02:17,  1.04s/it]\u001b[A\n",
            "2_01: loss 118.2597; lr 0.1722:  34% 68/200 [01:18<02:17,  1.04s/it]\u001b[A\n",
            "2_01: loss 118.2597; lr 0.1722:  34% 69/200 [01:18<02:16,  1.04s/it]\u001b[A\n",
            "2_01: loss 116.2099; lr 0.1722:  34% 69/200 [01:19<02:16,  1.04s/it]\u001b[A\n",
            "2_01: loss 116.2099; lr 0.1722:  35% 70/200 [01:19<02:16,  1.05s/it]\u001b[A\n",
            "2_01: loss 116.8034; lr 0.1722:  35% 70/200 [01:20<02:16,  1.05s/it]\u001b[A\n",
            "2_01: loss 116.8034; lr 0.1722:  36% 71/200 [01:20<02:14,  1.05s/it]\u001b[A\n",
            "2_01: loss 116.0874; lr 0.1550:  36% 71/200 [01:21<02:14,  1.05s/it]\u001b[A\n",
            "2_01: loss 116.0874; lr 0.1550:  36% 72/200 [01:21<02:14,  1.05s/it]\u001b[A\n",
            "2_01: loss 116.0443; lr 0.1550:  36% 72/200 [01:22<02:14,  1.05s/it]\u001b[A\n",
            "2_01: loss 116.0443; lr 0.1550:  36% 73/200 [01:22<02:13,  1.05s/it]\u001b[A\n",
            "2_01: loss 114.9986; lr 0.1550:  36% 73/200 [01:23<02:13,  1.05s/it]\u001b[A\n",
            "2_01: loss 114.9986; lr 0.1550:  37% 74/200 [01:23<02:11,  1.05s/it]\u001b[A\n",
            "2_01: loss 114.8320; lr 0.1550:  37% 74/200 [01:24<02:11,  1.05s/it]\u001b[A\n",
            "2_01: loss 114.8320; lr 0.1550:  38% 75/200 [01:24<02:11,  1.05s/it]\u001b[A\n",
            "2_01: loss 114.9086; lr 0.1550:  38% 75/200 [01:25<02:11,  1.05s/it]\u001b[A\n",
            "2_01: loss 114.9086; lr 0.1550:  38% 76/200 [01:25<02:10,  1.05s/it]\u001b[A\n",
            "2_01: loss 115.1588; lr 0.1550:  38% 76/200 [01:26<02:10,  1.05s/it]\u001b[A\n",
            "2_01: loss 115.1588; lr 0.1550:  38% 77/200 [01:26<02:08,  1.04s/it]\u001b[A\n",
            "2_01: loss 116.8366; lr 0.1550:  38% 77/200 [01:27<02:08,  1.04s/it]\u001b[A\n",
            "2_01: loss 116.8366; lr 0.1550:  39% 78/200 [01:27<02:07,  1.04s/it]\u001b[A\n",
            "2_01: loss 116.4956; lr 0.1550:  39% 78/200 [01:28<02:07,  1.04s/it]\u001b[A\n",
            "2_01: loss 116.4956; lr 0.1550:  40% 79/200 [01:28<02:06,  1.04s/it]\u001b[A\n",
            "2_01: loss 114.7977; lr 0.1395:  40% 79/200 [01:29<02:06,  1.04s/it]\u001b[A\n",
            "2_01: loss 114.7977; lr 0.1395:  40% 80/200 [01:29<02:05,  1.05s/it]\u001b[A\n",
            "2_01: loss 114.1868; lr 0.1395:  40% 80/200 [01:30<02:05,  1.05s/it]\u001b[A\n",
            "2_01: loss 114.1868; lr 0.1395:  40% 81/200 [01:30<02:04,  1.04s/it]\u001b[A\n",
            "2_01: loss 113.9087; lr 0.1395:  40% 81/200 [01:31<02:04,  1.04s/it]\u001b[A\n",
            "2_01: loss 113.9087; lr 0.1395:  41% 82/200 [01:31<02:03,  1.04s/it]\u001b[A\n",
            "2_01: loss 113.6477; lr 0.1395:  41% 82/200 [01:32<02:03,  1.04s/it]\u001b[A\n",
            "2_01: loss 113.6477; lr 0.1395:  42% 83/200 [01:32<02:02,  1.04s/it]\u001b[A\n",
            "2_01: loss 113.8119; lr 0.1395:  42% 83/200 [01:33<02:02,  1.04s/it]\u001b[A\n",
            "2_01: loss 113.8119; lr 0.1395:  42% 84/200 [01:33<02:00,  1.04s/it]\u001b[A\n",
            "2_01: loss 114.1148; lr 0.1395:  42% 84/200 [01:34<02:00,  1.04s/it]\u001b[A\n",
            "2_01: loss 114.1148; lr 0.1395:  42% 85/200 [01:34<01:58,  1.03s/it]\u001b[A\n",
            "2_01: loss 113.5175; lr 0.1395:  42% 85/200 [01:35<01:58,  1.03s/it]\u001b[A\n",
            "2_01: loss 113.5175; lr 0.1395:  43% 86/200 [01:35<01:58,  1.04s/it]\u001b[A\n",
            "2_01: loss 113.7169; lr 0.1395:  43% 86/200 [01:36<01:58,  1.04s/it]\u001b[A\n",
            "2_01: loss 113.7169; lr 0.1395:  44% 87/200 [01:36<01:57,  1.04s/it]\u001b[A\n",
            "2_01: loss 113.4711; lr 0.1255:  44% 87/200 [01:37<01:57,  1.04s/it]\u001b[A\n",
            "2_01: loss 113.4711; lr 0.1255:  44% 88/200 [01:37<01:56,  1.04s/it]\u001b[A\n",
            "2_01: loss 113.9479; lr 0.1255:  44% 88/200 [01:39<01:56,  1.04s/it]\u001b[A\n",
            "2_01: loss 113.9479; lr 0.1255:  44% 89/200 [01:39<01:55,  1.04s/it]\u001b[A\n",
            "2_01: loss 113.2264; lr 0.1255:  44% 89/200 [01:40<01:55,  1.04s/it]\u001b[A\n",
            "2_01: loss 113.2264; lr 0.1255:  45% 90/200 [01:40<01:54,  1.04s/it]\u001b[A\n",
            "2_01: loss 113.0658; lr 0.1255:  45% 90/200 [01:41<01:54,  1.04s/it]\u001b[A\n",
            "2_01: loss 113.0658; lr 0.1255:  46% 91/200 [01:41<01:53,  1.04s/it]\u001b[A\n",
            "2_01: loss 112.9235; lr 0.1255:  46% 91/200 [01:42<01:53,  1.04s/it]\u001b[A\n",
            "2_01: loss 112.9235; lr 0.1255:  46% 92/200 [01:42<01:52,  1.04s/it]\u001b[A\n",
            "2_01: loss 112.4548; lr 0.1255:  46% 92/200 [01:43<01:52,  1.04s/it]\u001b[A\n",
            "2_01: loss 112.4548; lr 0.1255:  46% 93/200 [01:43<01:52,  1.05s/it]\u001b[A\n",
            "2_01: loss 112.6262; lr 0.1255:  46% 93/200 [01:44<01:52,  1.05s/it]\u001b[A\n",
            "2_01: loss 112.6262; lr 0.1255:  47% 94/200 [01:44<01:51,  1.05s/it]\u001b[A\n",
            "2_01: loss 113.8460; lr 0.1255:  47% 94/200 [01:45<01:51,  1.05s/it]\u001b[A\n",
            "2_01: loss 113.8460; lr 0.1255:  48% 95/200 [01:45<01:50,  1.05s/it]\u001b[A\n",
            "2_01: loss 113.4340; lr 0.1130:  48% 95/200 [01:46<01:50,  1.05s/it]\u001b[A\n",
            "2_01: loss 113.4340; lr 0.1130:  48% 96/200 [01:46<01:48,  1.05s/it]\u001b[A\n",
            "2_01: loss 112.8576; lr 0.1130:  48% 96/200 [01:47<01:48,  1.05s/it]\u001b[A\n",
            "2_01: loss 112.8576; lr 0.1130:  48% 97/200 [01:47<01:47,  1.04s/it]\u001b[A\n",
            "2_01: loss 112.4136; lr 0.1130:  48% 97/200 [01:48<01:47,  1.04s/it]\u001b[A\n",
            "2_01: loss 112.4136; lr 0.1130:  49% 98/200 [01:48<01:46,  1.04s/it]\u001b[A\n",
            "2_01: loss 111.9512; lr 0.1130:  49% 98/200 [01:49<01:46,  1.04s/it]\u001b[A\n",
            "2_01: loss 111.9512; lr 0.1130:  50% 99/200 [01:49<01:45,  1.05s/it]\u001b[A\n",
            "2_01: loss 112.6447; lr 0.1130:  50% 99/200 [01:50<01:45,  1.05s/it]\u001b[A\n",
            "2_01: loss 112.6447; lr 0.1130:  50% 100/200 [01:50<01:44,  1.04s/it]\u001b[A\n",
            "2_01: loss 114.2000; lr 0.1130:  50% 100/200 [01:51<01:44,  1.04s/it]\u001b[A\n",
            "2_01: loss 114.2000; lr 0.1130:  50% 101/200 [01:51<01:43,  1.04s/it]\u001b[A\n",
            "2_01: loss 112.0332; lr 0.1130:  50% 101/200 [01:52<01:43,  1.04s/it]\u001b[A\n",
            "2_01: loss 112.0332; lr 0.1130:  51% 102/200 [01:52<01:42,  1.04s/it]\u001b[A\n",
            "2_01: loss 112.8279; lr 0.1130:  51% 102/200 [01:53<01:42,  1.04s/it]\u001b[A\n",
            "2_01: loss 112.8279; lr 0.1130:  52% 103/200 [01:53<01:40,  1.04s/it]\u001b[A\n",
            "2_01: loss 111.8790; lr 0.1017:  52% 103/200 [01:54<01:40,  1.04s/it]\u001b[A\n",
            "2_01: loss 111.8790; lr 0.1017:  52% 104/200 [01:54<01:40,  1.04s/it]\u001b[A\n",
            "2_01: loss 111.5190; lr 0.1017:  52% 104/200 [01:55<01:40,  1.04s/it]\u001b[A\n",
            "2_01: loss 111.5190; lr 0.1017:  52% 105/200 [01:55<01:39,  1.05s/it]\u001b[A\n",
            "2_01: loss 111.5189; lr 0.1017:  52% 105/200 [01:56<01:39,  1.05s/it]\u001b[A\n",
            "2_01: loss 111.5189; lr 0.1017:  53% 106/200 [01:56<01:38,  1.05s/it]\u001b[A\n",
            "2_01: loss 111.6198; lr 0.1017:  53% 106/200 [01:57<01:38,  1.05s/it]\u001b[A\n",
            "2_01: loss 111.6198; lr 0.1017:  54% 107/200 [01:57<01:37,  1.05s/it]\u001b[A\n",
            "2_01: loss 111.7489; lr 0.1017:  54% 107/200 [01:58<01:37,  1.05s/it]\u001b[A\n",
            "2_01: loss 111.7489; lr 0.1017:  54% 108/200 [01:58<01:36,  1.04s/it]\u001b[A\n",
            "2_01: loss 111.5677; lr 0.1017:  54% 108/200 [01:59<01:36,  1.04s/it]\u001b[A\n",
            "2_01: loss 111.5677; lr 0.1017:  55% 109/200 [01:59<01:35,  1.04s/it]\u001b[A\n",
            "2_01: loss 111.5989; lr 0.1017:  55% 109/200 [02:00<01:35,  1.04s/it]\u001b[A\n",
            "2_01: loss 111.5989; lr 0.1017:  55% 110/200 [02:00<01:34,  1.04s/it]\u001b[A\n",
            "2_01: loss 111.3529; lr 0.1017:  55% 110/200 [02:02<01:34,  1.04s/it]\u001b[A\n",
            "2_01: loss 111.3529; lr 0.1017:  56% 111/200 [02:02<01:32,  1.04s/it]\u001b[A\n",
            "2_01: loss 111.1396; lr 0.0915:  56% 111/200 [02:03<01:32,  1.04s/it]\u001b[A\n",
            "2_01: loss 111.1396; lr 0.0915:  56% 112/200 [02:03<01:31,  1.04s/it]\u001b[A\n",
            "2_01: loss 111.1459; lr 0.0915:  56% 112/200 [02:04<01:31,  1.04s/it]\u001b[A\n",
            "2_01: loss 111.1459; lr 0.0915:  56% 113/200 [02:04<01:31,  1.05s/it]\u001b[A\n",
            "2_01: loss 110.8682; lr 0.0915:  56% 113/200 [02:05<01:31,  1.05s/it]\u001b[A\n",
            "2_01: loss 110.8682; lr 0.0915:  57% 114/200 [02:05<01:29,  1.04s/it]\u001b[A\n",
            "2_01: loss 110.9790; lr 0.0915:  57% 114/200 [02:06<01:29,  1.04s/it]\u001b[A\n",
            "2_01: loss 110.9790; lr 0.0915:  57% 115/200 [02:06<01:28,  1.04s/it]\u001b[A\n",
            "\n",
            "                                                                     \u001b[A2_01  Loss 110.8682\n",
            "100% 2/2 [04:44<00:00, 142.30s/it]\n"
          ]
        }
      ],
      "source": [
        "#@title we first create the 'improved' images of faces\n",
        "#@markdown this might take a while\n",
        "\n",
        "%cd {root_path5}\n",
        "# make folders\n",
        "!mkdir aligned_images alignement_vector\n",
        "\n",
        "!python align_images.py {input_step5} aligned_images/ alignement_vector/\n",
        "\n",
        "!python encode_images.py aligned_images/ generated_images/ latent_representations/ \\\n",
        "    --vgg_url=https://rolux.org/media/stylegan/vgg16_zhang_perceptual.pkl \\\n",
        "    --lr=0.4 \\\n",
        "    --iterations=200 \\\n",
        "    --use_best_loss=True \\\n",
        "    --early_stopping=True \\\n",
        "    --load_resnet=True \\\n",
        "    --composite_blur=6 # default=8\n",
        "for i in os.listdir(os.path.join(root_path5,'generated_images')):\n",
        "  shutil.copy2(os.path.join(root_path5,'generated_images',i),os.path.join(output_step5,i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDuF8o0rzNtx",
        "outputId": "7136d8ef-f21b-4eb0-99fd-2fe227d7f436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "Done!\n",
            "Using TensorFlow backend.\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "#@title then we stitch them back together with their original image\n",
        "face_path = \"generated_images/\" \n",
        "mask_path = \"masks/\"\n",
        "vector_path = \"alignement_vector/\"\n",
        "for i in os.listdir(input_step5):\n",
        "  img_name = i\n",
        "  raw_path = os.path.join(input_step5,img_name)\n",
        "  out_path = os.path.join(output_step5, img_name)\n",
        "\n",
        "  !python fit_faces.py $raw_path $face_path $mask_path $vector_path $out_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ceij8_mpICRm"
      },
      "source": [
        "## Step 6: Color Corrections\n",
        "\n",
        "[Curl]()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_epn_TzNICRn",
        "outputId": "579b04f6-0f5c-435b-844f-1801427f579d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into '/content/CURL'...\n",
            "remote: Enumerating objects: 542, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 542 (delta 126), reused 127 (delta 123), pack-reused 405\u001b[K\n",
            "Receiving objects: 100% (542/542), 99.49 MiB | 14.29 MiB/s, done.\n",
            "Resolving deltas: 100% (306/306), done.\n",
            "/content/CURL\n"
          ]
        }
      ],
      "source": [
        "root_path6 = '/content/CURL'\n",
        "\n",
        "# clone the repository\n",
        "if not os.path.exists(root_path6):\n",
        "  !git clone https://github.com/sjmoran/CURL {root_path6}\n",
        "%cd {root_path6}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CYe5tpOO8qvx"
      },
      "outputs": [],
      "source": [
        "#@title imports\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import sys\n",
        "import torch\n",
        "import torchvision.transforms.functional as TF\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Imports from the code written by authors inside modules\n",
        "import model\n",
        "import util\n",
        "from util import ImageProcessing\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' # Might not work without GPU so if you want the cpu verson, clone https://github.com/deshwalmahesh/CURL---cpu-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "g6RSDg2D8vQl"
      },
      "outputs": [],
      "source": [
        "#@title Helper functions\n",
        "def resize(image, new_width_height = 1920, convert_RGB = True):\n",
        "  '''\n",
        "  Resize and return Given Image\n",
        "  args:\n",
        "    path: Image Path, BytesIO or the image \n",
        "    new_width_height = Reshaped image's width and height. # If integer is given, it'll keep the aspect ratio as it is by shrinking the Bigger dimension (width or height) to the max of new_width_height  and then shring the smaller dimension accordingly \n",
        "    convert_RGB: Whether to Convert the RGBA image to RGB (by default backgroud is white)\n",
        "  '''\n",
        "  image = Image.open(image) if isinstance(image, (str, BytesIO)) else image\n",
        "  w, h = image.size\n",
        "\n",
        "  fixed_size = new_width_height if isinstance(new_width_height, int) else False\n",
        "\n",
        "  if fixed_size:\n",
        "    if h > w:\n",
        "      fixed_height = fixed_size\n",
        "      height_percent = (fixed_height / float(h))\n",
        "      width_size = int((float(w) * float(height_percent)))\n",
        "      image = image.resize((width_size, fixed_height), Image.NEAREST)\n",
        "\n",
        "    else:\n",
        "      fixed_width = fixed_size\n",
        "      width_percent = (fixed_width / float(w))\n",
        "      height_size = int((float(h) * float(width_percent)))\n",
        "      image = image.resize((fixed_width, height_size), Image.NEAREST) # Try Image.ANTIALIAS inplace of Image.NEAREST\n",
        "\n",
        "  else:\n",
        "    image = image.resize(new_width_height)\n",
        "\n",
        "  if image.mode == \"RGBA\" and convert_RGB:\n",
        "  \n",
        "    new = Image.new(\"RGBA\", image.size, \"WHITE\") # Create a white rgba background\n",
        "    new.paste(image, (0, 0), image) # Paste the image on the background.\n",
        "    image = new.convert('RGB')\n",
        "\n",
        "  return image\n",
        "\n",
        "\n",
        "\n",
        "def load_image(path, resize_image_size = 1920):\n",
        "    '''\n",
        "    Load the image as tensor according to the format authors have used in the code\n",
        "    '''\n",
        "    if (\"https\" in path) or (\"http\" in path):\n",
        "      image = Image.open(BytesIO(requests.get(path).content))\n",
        "\n",
        "    else:\n",
        "      image = Image.open(path)\n",
        "\n",
        "    if image.mode != 'RGB':\n",
        "      image = image.convert('RGB')\n",
        "    \n",
        "    if resize:\n",
        "      image = resize(image, resize_image_size)\n",
        "               \n",
        "    return TF.to_tensor(image).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ngq2Ouyv81W8"
      },
      "outputs": [],
      "source": [
        "#@title load pre)trained model\n",
        "checkpoint_filepath = \"./pretrained_models/adobe_dpe/curl_validpsnr_23.073045286204017_validloss_0.0701291635632515_testpsnr_23.584083321292365_testloss_0.061363041400909424_epoch_510_model.pt\"\n",
        "\n",
        "# Build Model\n",
        "net = model.CURLNet()\n",
        "checkpoint = torch.load(checkpoint_filepath, map_location=DEVICE)\n",
        "net.load_state_dict(checkpoint['model_state_dict'])\n",
        "net.eval()\n",
        "if DEVICE == 'cuda':\n",
        "  net.cuda()\n",
        "\n",
        "\n",
        "def evaluate(img, convert_uint = False):\n",
        "    \"\"\"\n",
        "    Evaluate the model per image instance. Image of Batch size 1. Can be used in API production\n",
        "    \"\"\"\n",
        "    img = load_image(img)\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        img = img.unsqueeze(0)\n",
        "        img = torch.clamp(img, 0, 1)\n",
        "\n",
        "        net_output_img_example , _ = net(img)\n",
        "\n",
        "        net_output_img_example_numpy = net_output_img_example.squeeze(0).data.cpu().numpy()\n",
        "        net_output_img_example_numpy = ImageProcessing.swapimdims_3HW_HW3(net_output_img_example_numpy)\n",
        "        return (net_output_img_example_numpy* 255).astype(np.uint8) if convert_uint else net_output_img_example_numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5yazwQa864k",
        "outputId": "2fd54e68-e878-4fef-fa60-a75ee6039f56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1_01.jpg\n",
            "2_01.jpg\n",
            "1.jpg\n",
            "2.jpg\n",
            "2.png\n",
            "1.png\n",
            "2_01.png\n"
          ]
        }
      ],
      "source": [
        "imgs_to_convert = os.listdir(input_step6)\n",
        "# for _img in imgs_to_convert:\n",
        "#     # Load .png image\n",
        "#   image = cv2.imread(os.path.join(input_step6,_img))\n",
        "#   # Save .jpg image\n",
        "#   cv2.imwrite(os.path.join(input_step6,'{}.jpg').format(_img.split('.')[0]), image, [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
        "# imgs_to_convert = os.listdir(input_step6)\n",
        "\n",
        "for _img in imgs_to_convert:\n",
        "  print(_img)\n",
        "  result = evaluate(os.path.join(input_step6,_img), convert_uint = True) # gives you array between 0-1 so if you want an \"Image\", use 'convert_uint = True', then Image.fromarray(array).save(path)\n",
        "  Image.fromarray(result).save(os.path.join(output_step6,'{}.jpg'.format(_img.split('.')[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gHgBX7oICRn"
      },
      "source": [
        "## Step 7: Color Grading\n",
        "\n",
        "Model: deep preset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "M3_e2_XYICRn"
      },
      "outputs": [],
      "source": [
        "#@title install model and prerequisites\n",
        "import os\n",
        "root_path7 = '/content/DeepPreset'\n",
        "\n",
        "# folder with style transfer\n",
        "style_folder = '/content/database/colorGrading/style'\n",
        "\n",
        "# clone the repository\n",
        "if not os.path.exists('DeepPreset'):\n",
        "  !git clone https://github.com/minhmanho/deep_preset {root_path7}\n",
        "\n",
        "!pip3 -q install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio==0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vu0BUh3aLqWd"
      },
      "outputs": [],
      "source": [
        "# populate vars when runtime restart is needed\n",
        "style_folder = '/content/database/total/styles'\n",
        "root_path7 = '/content/DeepPreset'\n",
        "#@title download the deep preset model\n",
        "#@markdown **if** you want to use different styles, place them in the styles folder \n",
        "#@markdown and give them a corresponding name PER image (thus Styles/1.jpg for input/1.jpg)\n",
        "\n",
        "%cd {root_path7}\n",
        "%ls\n",
        "# Download the pre-trained model\n",
        "# one of the two models is gonna work better (cfr paper)\n",
        "# Deep Preset with PPL (Positive Pair-wise Loss)\n",
        "!sh models/fetch_model_wPPL.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pIynzpj6VN3_"
      },
      "outputs": [],
      "source": [
        "#@markdown convert the pngs from input_step7 to jpgs needed for deep preset\n",
        "from PIL import Image\n",
        "step7_temp = '/content/database/total/step7temp'\n",
        "os.makedirs(step7_temp, exist_ok=True)\n",
        "for i in os.listdir(input_step7):\n",
        "  im1 = Image.open(os.path.join(input_step7,i))\n",
        "  store_img = os.path.join(step7_temp,i.split('.')[0]+'.jpg')\n",
        "  im1.save(store_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FQEnwfnZLyd9"
      },
      "outputs": [],
      "source": [
        "#@title run the colorgrading\n",
        "\n",
        "!CUDA_VISIBLE_DEVICES=0 python run.py \\\n",
        "     --content {step7_temp} \\\n",
        "     --style {style_folder} \\\n",
        "     --out {output_step7} \\\n",
        "     --ckpt models/dp_wPPL.pth.tar \\\n",
        "     --size 400x592"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCYexnqCICRn"
      },
      "source": [
        "## Step 8: image upscaling\n",
        "\n",
        "Model: RealESRGan\n",
        "\n",
        "[ESRGan](https://github.com/luca-arts/seeingtheimperceptible/blob/main/notebooks/basicSuperRestoration/tests/Real_ESRGAN.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQsy0whPICRo",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title setup and clone git repo\n",
        "import os\n",
        "root_path8 = '/content/BasicSR'\n",
        "\n",
        "# clone the repository\n",
        "if not os.path.exists(root_path8):\n",
        "  !git clone https://github.com/xinntao/Real-ESRGAN {root_path8}\n",
        "\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "0wftpfagMJyn"
      },
      "outputs": [],
      "source": [
        "#@title install model and prerequisites\n",
        "%cd {root_path8}\n",
        "\n",
        "# Set up the environment\n",
        "!pip install -q basicsr\n",
        "!pip install -q facexlib\n",
        "!pip install -q gfpgan\n",
        "!pip install -q -r requirements.txt\n",
        "!python setup.py develop\n",
        "\n",
        "# Download the pre-trained model\n",
        "!wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P /content/BasicSR/experiments/pretrained_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rQuNsPFKMYmK"
      },
      "outputs": [],
      "source": [
        "#@title upscale the images\n",
        "!python inference_realesrgan.py -n RealESRGAN_x4plus -i {input_step8} -o {output_step8} --outscale 3.5 --face_enhance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arshs-swNpR6"
      },
      "source": [
        "# Step 9 add some noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gslxfmC2NpR6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title imports\n",
        "# installing the needed libs\n",
        "print ('\\n> Installing OpenCV')\n",
        "!pip install opencv-python\n",
        "\n",
        "print ('\\n> Installing Numpy')\n",
        "!pip install numpy\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1wwEL6uNpR6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title helper functions\n",
        "# functions for different noise-types\n",
        "def normalize(mask):\n",
        "    return (mask - mask.min()) / (mask.max() - mask.min())\n",
        "\n",
        "def add_noise(noise_fun, gray: bool=False, **kwargs):\n",
        "    img = kwargs.get('img')\n",
        "    image = np.array(img, dtype=float)\n",
        "    noise = noise_fun(**kwargs)\n",
        "    if(gray):\n",
        "      gray_ch = cv2.cvtColor(noise.astype(np.float32), cv2.COLOR_BGR2GRAY)\n",
        "      #change color noise to gray noise for each channel\n",
        "      noise = cv2.merge([gray_ch,gray_ch,gray_ch])\n",
        "    image_out = image + noise\n",
        "    image_out = np.uint8(normalize(image_out) * 255)\n",
        "    return image_out\n",
        "\n",
        "def gaussian_noise(**kwargs):\n",
        "    mu=kwargs.get('mu')\n",
        "    sigma=kwargs.get('sigma')\n",
        "    image=kwargs.get('img')\n",
        "    noise = np.random.normal(mu, sigma, image.shape)\n",
        "    return noise\n",
        "\n",
        "def rayleigh_noise(**kwargs):\n",
        "    a = kwargs.get('a')\n",
        "    image = kwargs.get('img')\n",
        "    noise = np.random.rayleigh(a, size=image.shape)\n",
        "    return noise\n",
        "\n",
        "def gamma_noise(**kwargs):\n",
        "    scale = kwargs.get('scale')\n",
        "    image = kwargs.get('img')\n",
        "    noise = np.random.gamma(shape=1, scale=scale, size=image.shape)\n",
        "    return noise\n",
        "\n",
        "def exponent_noise(**kwargs):\n",
        "    scale = kwargs.get('scale')\n",
        "    image = kwargs.get('img')\n",
        "    noise = np.random.exponential(scale=scale, size=image.shape)\n",
        "    return noise\n",
        "\n",
        "def average_noise(**kwargs):\n",
        "    mean = kwargs.get('mu')\n",
        "    sigma = kwargs.get('sigma')\n",
        "    image = kwargs.get('img')\n",
        "    a = 2 * mean - np.sqrt(12 * sigma)\n",
        "    b = 2 * mean + np.sqrt(12 * sigma)\n",
        "    noise = np.random.uniform(a, b, image.shape)\n",
        "    return noise\n",
        "\n",
        "def add_gaussian_noise(img, mu=0, sigma=0.1, gray=False):\n",
        "    img_out = add_noise(gaussian_noise, gray=gray, img=img, mu=mu, sigma=sigma)\n",
        "    return img_out\n",
        "\n",
        "def add_rayleigh_noise(img, a=15, gray=False):\n",
        "    img_out = add_noise(rayleigh_noise,img=img,a=a,gray=gray) \n",
        "    return img_out\n",
        "\n",
        "def add_gamma_noise(img, scale=1, gray=False):\n",
        "    img_out = add_noise(gamma_noise, img=img, scale=scale,gray=gray)\n",
        "    return img_out\n",
        "\n",
        "def add_exponent_noise(img, scale=1.0, gray=False):\n",
        "    img_out = add_noise(exponent_noise, img=img, scale=scale,gray=gray)\n",
        "    return img_out\n",
        "\n",
        "def add_average_noise(img, mean=0, sigma=100, gray=False):\n",
        "    img_out = add_noise(average_noise, img=img, mu=mu, sigma=sigma, gray=gray)\n",
        "    return img_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcwrwFzvNpR6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "noise_type = \"gaussian\" #@param [\"gaussian\", \"rayleigh\", \"gamma\",\"exponent\",\"average\"]\n",
        "\n",
        "def use_noise(noise_type, img, mu=0,sigma=5,a=15,scale=1.0,gray=False):\n",
        "    if(noise_type==\"gaussian\"):\n",
        "      img = add_gaussian_noise(img=img, mu=mu, sigma=sigma, gray=gray)\n",
        "    if(noise_type==\"rayleigh\"):\n",
        "       img = add_rayleigh_noise(img=img,a=a,gray=gray)\n",
        "    if(noise_type==\"gamma\"):\n",
        "       img = add_gamma_noise(img=img,scale=scale,gray=gray)\n",
        "    if(noise_type==\"exponent\"):\n",
        "       img = add_exponent_noise(img=img,scale=scale, gray=gray)\n",
        "    if(noise_type==\"average\"):\n",
        "       img = add_average_noise(img=img, mu=mu, sigma=sigma, gray=gray)\n",
        "    return img\n",
        "\n",
        "#@markdown mu, sigma for gaussian and average noise\n",
        "mu = 0.35 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "sigma = 16.5 #@param {type:\"slider\", min:0, max:20, step:0.5}\n",
        "\n",
        "#@markdown a is for rayleigh noise\n",
        "a = 10 #@param {type:\"slider\", min:0, max:20, step:0.5}\n",
        "\n",
        "#@markdown scale is for gamma and exponent noise\n",
        "scale = 16.5 #@param {type:\"slider\", min:0, max:20, step:0.5}\n",
        "\n",
        "#@markdown an option to use **gray** noise instead of RGB noise\n",
        "gray = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown you can use the noise generation via: `gen_img = use_noise(noise_type, img=_img, mu=mu, sigma=sigma, a=a,scale=scale,gray=gray)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OBHs7FKNpR7",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title execute noise generation\n",
        "for i in os.listdir(input_step9):\n",
        "    _img_pth = os.path.join(input_step9,i)\n",
        "    _img = cv2.imread(_img_pth)\n",
        "    gen_img = use_noise(noise_type, img=_img, mu=mu, sigma=sigma, a=a,scale=scale,gray=gray)\n",
        "    cv2.imwrite(os.path.join(output_step9,i),gen_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1YUmeA8ZcKn"
      },
      "source": [
        "# the end\n",
        "\n",
        "Now we've run through an entire flow, any feedback?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled12.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}