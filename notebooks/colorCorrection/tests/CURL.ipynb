{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CURL.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luca-arts/seeingtheimperceptible/blob/main/notebooks/colorCorrection/tests/CURL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CURL: Neural Curve Layers for Global Image Enhancement\n",
        "\n",
        "[GitHub](https://github.com/sjmoran/CURL)"
      ],
      "metadata": {
        "id": "AkEtQlPYUcGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Preparations\n",
        "\n",
        "Before start, make sure that you choose\n",
        "\n",
        "Runtime Type = Python 3\n",
        "Hardware Accelerator = GPU"
      ],
      "metadata": {
        "id": "A3t79ilzUmfz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BFj_nbkoUV0B",
        "outputId": "ac2d89b1-343b-4767-f58b-bcddbc41c6af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May  9 13:02:28 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. linking nextcloud\n",
        "\n",
        "Connecting to the external NextCloud drive "
      ],
      "metadata": {
        "id": "9ujeqk-7UtOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we'll link the dataset from next-cloud\n",
        "!curl https://raw.githubusercontent.com/luca-arts/seeingtheimperceptible/main/notebooks/database_mod.py -o /content/database_mod.py\n",
        "\n",
        "from database_mod import *\n",
        "\n",
        "link_nextcloud()\n",
        "\n",
        "nextcloud = '/content/database/'\n",
        "\n",
        "input_folder, output_folder = create_io(database=nextcloud,topic='colorCorrection/CURL',library='CURL')"
      ],
      "metadata": {
        "id": "YpGQwNdEUt0y",
        "outputId": "95570606-3b21-4686-b255-400a2852a878",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2480  100  2480    0     0  18102      0 --:--:-- --:--:-- --:--:-- 18102\n",
            "what's the username for nextcloud? colab\n",
            "what's the password for user colab? ··········\n",
            "0\n",
            "Please enter the username to authenticate with server\n",
            "https://cloud.bxlab.net/remote.php/dav/files/colab/colabfiles/ or hit enter for none.\n",
            "  Username: Please enter the password to authenticate user colab with server\n",
            "https://cloud.bxlab.net/remote.php/dav/files/colab/colabfiles/ or hit enter for none.\n",
            "  Password:  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CURL_direction = '/content/database/colorCorrection/CURL/output'"
      ],
      "metadata": {
        "id": "U2Jvsn5_EwdW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. clone GIT repo"
      ],
      "metadata": {
        "id": "wDG7SFJCU1co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "root_path = '/content/CURL'\n",
        "\n",
        "# clone the repository\n",
        "if not os.path.exists(root_path):\n",
        "  !git clone https://github.com/sjmoran/CURL {root_path}\n",
        "\n",
        "%ls"
      ],
      "metadata": {
        "id": "0ZM6epwTU14f",
        "outputId": "fc85d76b-46de-4c79-e75b-75f34571a43c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/CURL'...\n",
            "remote: Enumerating objects: 538, done.\u001b[K\n",
            "remote: Counting objects: 100% (133/133), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 538 (delta 125), reused 123 (delta 123), pack-reused 405\u001b[K\n",
            "Receiving objects: 100% (538/538), 97.09 MiB | 34.93 MiB/s, done.\n",
            "Resolving deltas: 100% (305/305), done.\n",
            "\u001b[0m\u001b[01;34mCURL\u001b[0m/  \u001b[01;34mdatabase\u001b[0m/  database_mod.py  \u001b[01;34m__pycache__\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {root_path}\n",
        "def replace_text_in_file(file, old_text, new_text):\n",
        "  #read input file\n",
        "  fin = open(file, \"r\")\n",
        "  #read file contents to string\n",
        "  data = fin.read()\n",
        "  if(old_text not in fin):\n",
        "    print('{} not found'.format(old_text))\n",
        "  #replace all occurrences of the required string\n",
        "  data = data.replace(old_text, new_text)\n",
        "  #close the input file\n",
        "  fin.close()\n",
        "  #open the input file in write mode\n",
        "  fin = open(file, \"w\")\n",
        "  #overrite the input file with the resulting data\n",
        "  fin.write(data)\n",
        "  #close the file\n",
        "  fin.close()\n",
        "replace_text_in_file(\"requirements.txt\",'skimage==0.0', 'scikit-image')"
      ],
      "metadata": {
        "id": "mwcnqaBGQVmR",
        "outputId": "ecd3843f-305b-4275-e1ea-ac151fd4d30e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CURL\n",
            "skimage==0.0 not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Setting up the environment"
      ],
      "metadata": {
        "id": "WLRvv9tvVH4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# installing CURL\n",
        "%cd {root_path}\n",
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {
        "id": "E58LeXUAVJLA",
        "outputId": "d667c319-fa93-4414-d076-46f45811a578",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CURL\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.7.1 which is incompatible.\n",
            "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Inference"
      ],
      "metadata": {
        "id": "UDahEQxOt-yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "replace_text_in_file('main.py','exit()','#exit()')"
      ],
      "metadata": {
        "id": "ZRIVE2-hILyv",
        "outputId": "4372bc94-9168-4e45-825c-abc3494e5ec2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exit() not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inference path\n",
        "#inf_path = root_path + ''\n",
        "\n",
        "# python3 main.py\n",
        "#    --inference_img_dirpath={./adobe5k_dpe/} \n",
        "#    --checkpoint_filepath=./pretrained_models/curl_validpsnr_23.073045286204017_validloss_0.0701291635632515_testpsnr_23.584083321292365_testloss_0.061363041400909424_epoch_510_model.pt\n",
        "# /content/database/colorCorrection/CURL/\n",
        "!python3 main.py --inference_img_dirpath=./adobe5k_dpe/    --checkpoint_filepath=./pretrained_models/adobe_dpe/curl_validpsnr_23.073045286204017_validloss_0.0701291635632515_testpsnr_23.584083321292365_testloss_0.061363041400909424_epoch_510_model.pt"
      ],
      "metadata": {
        "id": "zg7ATg43t_M3",
        "outputId": "20284067-c3a4-4992-9f81-a7b15d9ef2b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Before running this code ensure you keep the default batch size of 1. The code has not been engineered to support higher batch sizes. See README for more detail. Remove the ####exit() statement to use code. ***\n",
            "2022-05-09 14:54:06,595 INFO ######### Parameters #########\n",
            "2022-05-09 14:54:06,595 INFO Number of epochs: 100000\n",
            "2022-05-09 14:54:06,595 INFO Logging directory: ./log_2022-05-09_14-54-06\n",
            "2022-05-09 14:54:06,595 INFO Dump validation accuracy every: 10\n",
            "2022-05-09 14:54:06,595 INFO Training image directory: /home/sjm213/adobe5k/adobe5k/\n",
            "2022-05-09 14:54:06,595 INFO ##############################\n",
            "2022-05-09 14:54:06,595 INFO Loading Adobe5k dataset ...\n",
            "2022-05-09 14:54:06,597 INFO Performing inference with images in directory: ./adobe5k_dpe/\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 351, in <module>\n",
            "    main()\n",
            "  File \"main.py\", line 118, in main\n",
            "    checkpoint = torch.load(checkpoint_filepath, map_location='cuda')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 594, in load\n",
            "    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 853, in _load\n",
            "    result = unpickler.load()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 845, in persistent_load\n",
            "    load_tensor(data_type, size, key, _maybe_decode_ascii(location))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 834, in load_tensor\n",
            "    loaded_storages[key] = restore_location(storage, location)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 811, in restore_location\n",
            "    return default_restore_location(storage, map_location)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 175, in default_restore_location\n",
            "    result = fn(storage, location)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 151, in _cuda_deserialize\n",
            "    device = validate_cuda_device(location)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 132, in validate_cuda_device\n",
            "    device = torch.cuda._utils._get_device_index(location, True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/_utils.py\", line 32, in _get_device_index\n",
            "    return _torch_get_device_index(device, optional, allow_cpu)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 489, in _get_device_index\n",
            "    device_idx = _get_current_device_index()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 448, in _get_current_device_index\n",
            "    return _get_device_attr(lambda m: m.current_device())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 440, in _get_device_attr\n",
            "    if device_type.lower() == \"cuda\":\n",
            "AttributeError: 'NoneType' object has no attribute 'lower'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "*for i in os.listdir(input_folder):\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "eJnaGx7zGfB-",
        "outputId": "b114bb77-d9da-4e56-dbaa-98927a36157c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "01.jpg\n",
            "02.jpg\n",
            "03.jpg\n",
            "04.jpg\n",
            "05.jpg\n",
            "06.jpg\n",
            "07.jpg\n",
            "08.jpg\n",
            "09.jpg\n",
            "10.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5T5WCUC_G5oI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}