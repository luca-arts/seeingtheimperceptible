{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luca-arts/seeingtheimperceptible/blob/main/notebooks/ImageEditing/tests/LaMa_inpainting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pRpIwnaOnb3"
      },
      "source": [
        "#  **LaMa: Resolution-robust Large Mask Inpainting with Fourier Convolutions**\n",
        "\n",
        "[[Project page](https://saic-mdal.github.io/lama-project/)] [[GitHub](https://github.com/saic-mdal/lama)] [[arXiv](https://arxiv.org/abs/2109.07161)] [[Supplementary](https://ashukha.com/projects/lama_21/lama_supmat_2021.pdf)] [[BibTeX](https://senya-ashukha.github.io/projects/lama_21/paper.txt)]\n",
        "\n",
        "\n",
        "Our model generalizes surprisingly well to much higher resolutions (~2k) than it saw during training (256x256), and achieves the excellent performance even in challenging scenarios, e.g. completion of periodic structures."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Preparations\n",
        "\n",
        "Before start, make sure that you choose\n",
        "\n",
        "- Runtime Type = Python 3\n",
        "- Hardware Accelerator = GPU"
      ],
      "metadata": {
        "id": "nJpXEpuZXZg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "D9bGsNW3XfOd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "123d9475-ee01-4281-e503-deb6c005e2fe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr 20 13:01:42 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. linking next cloud"
      ],
      "metadata": {
        "id": "TO65fwVaX0NR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we'll link the dataset from next-cloud\n",
        "!curl https://raw.githubusercontent.com/luca-arts/seeingtheimperceptible/main/notebooks/database_mod.py -o /content/database_mod.py\n",
        "\n",
        "from database_mod import *\n",
        "\n",
        "link_nextcloud()\n",
        "\n",
        "nextcloud = '/content/database/'\n",
        "\n",
        "input_folder, output_folder = create_io(database=nextcloud,topic='ImageEditing',library='LaMa')"
      ],
      "metadata": {
        "id": "AgrPWeCBX2X2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f417827-8d08-4d21-8506-cb3adb740922"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2235  100  2235    0     0   5491      0 --:--:-- --:--:-- --:--:--  5491\n",
            "what's the username for nextcloud? colab\n",
            "what's the password for user colab? 路路路路路路路路路路\n",
            "0\n",
            "Please enter the username to authenticate with server\n",
            "https://cloud.bxlab.net/remote.php/dav/files/colab/colabfiles/ or hit enter for none.\n",
            "  Username: Please enter the password to authenticate user colab with server\n",
            "https://cloud.bxlab.net/remote.php/dav/files/colab/colabfiles/ or hit enter for none.\n",
            "  Password:  \n",
            "content of /etc/fstab: https://cloud.bxlab.net/remote.php/dav/files/colab/colabfiles/ /content/database davfs user,rw,auto 0 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Clone Git repository"
      ],
      "metadata": {
        "id": "GZKm1rPiX-so"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "root_path = '/content/LaMa'\n",
        "\n",
        "# clone the repository\n",
        "if not os.path.exists('LaMa'):\n",
        "  !git clone https://github.com/saic-mdal/lama {root_path}\n",
        "\n",
        "%ls"
      ],
      "metadata": {
        "id": "BVpg25zTYD87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a94695-e209-49b2-9b37-827b75d456d1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/LaMa'...\n",
            "remote: Enumerating objects: 306, done.\u001b[K\n",
            "remote: Counting objects: 100% (306/306), done.\u001b[K\n",
            "remote: Compressing objects: 100% (219/219), done.\u001b[K\n",
            "remote: Total 306 (delta 88), reused 279 (delta 75), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (306/306), 6.50 MiB | 12.41 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n",
            "\u001b[0m\u001b[01;34mdatabase\u001b[0m/  database_mod.py  \u001b[01;34mLaMa\u001b[0m/  \u001b[01;34m__pycache__\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Set up the environment"
      ],
      "metadata": {
        "id": "QMdbYLaSYcUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup req_path\n",
        "req_path = '/content/database/ImageEditing'\n",
        "%cd {req_path}\n",
        "\n",
        "# Set up the environment\n",
        "print('\\n> Install dependencies')\n",
        "!pip install -r requirements-LaMa.txt --quiet\n",
        "\n",
        "# do we need the wget?\n",
        "!pip install wget --quiet\n",
        "\n",
        "#print('\\n> Changing the dir to:')\n"
      ],
      "metadata": {
        "id": "Itt2haV7YhVT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec6f0fc8-6312-4719-d189-e6f2f87b3edc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/database/ImageEditing\n",
            "\n",
            "> Install dependencies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Download the pre-trained model"
      ],
      "metadata": {
        "id": "5EQKhr1CZBIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {root_path}\n",
        "\n",
        "# download the model\n",
        "print('\\n> Download the model')\n",
        "!curl -L $(yadisk-direct https://disk.yandex.ru/d/ouP6l8VJ0HpMZg) -o big-lama.zip\n",
        "!unzip big-lama.zip\n",
        "\n",
        "# fixing openCV\n",
        "print('>fixing opencv')\n",
        "!pip uninstall opencv-python-headless -y --quiet\n",
        "!pip install opencv-python-headless==4.1.2.30 --quiet"
      ],
      "metadata": {
        "id": "nZbAYKu_ZcCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf56c05c-714e-470a-fed4-8db657ee0506"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LaMa\n",
            "\n",
            "> Download the model\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100  363M    0  363M    0     0  8609k      0 --:--:--  0:00:43 --:--:--  9.8M\n",
            "Archive:  big-lama.zip\n",
            "  inflating: big-lama/config.yaml    \n",
            "  inflating: big-lama/models/best.ckpt  \n",
            ">fixing opencv\n",
            "\u001b[K     || 21.8 MB 1.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Init mask-drawing code"
      ],
      "metadata": {
        "id": "0mFwQjQgZdDy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RwXRMaNHW4r5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa04ce1a-6eb7-40c5-e648-c2bb17117734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "> Init mask-drawing code\n"
          ]
        }
      ],
      "source": [
        "print('\\n> Init mask-drawing code')\n",
        "import base64, os\n",
        "from IPython.display import HTML, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import wget\n",
        "from shutil import copyfile\n",
        "import shutil\n",
        "\n",
        "\n",
        "\n",
        "canvas_html = \"\"\"\n",
        "<style>\n",
        ".button {\n",
        "  background-color: #4CAF50;\n",
        "  border: none;\n",
        "  color: white;\n",
        "  padding: 15px 32px;\n",
        "  text-align: center;\n",
        "  text-decoration: none;\n",
        "  display: inline-block;\n",
        "  font-size: 16px;\n",
        "  margin: 4px 2px;\n",
        "  cursor: pointer;\n",
        "}\n",
        "</style>\n",
        "<canvas1 width=%d height=%d>\n",
        "</canvas1>\n",
        "<canvas width=%d height=%d>\n",
        "</canvas>\n",
        "\n",
        "<button class=\"button\">Finish</button>\n",
        "<script>\n",
        "var canvas = document.querySelector('canvas')\n",
        "var ctx = canvas.getContext('2d')\n",
        "\n",
        "var canvas1 = document.querySelector('canvas1')\n",
        "var ctx1 = canvas.getContext('2d')\n",
        "\n",
        "\n",
        "ctx.strokeStyle = 'red';\n",
        "\n",
        "var img = new Image();\n",
        "img.src = \"data:image/%s;charset=utf-8;base64,%s\";\n",
        "console.log(img)\n",
        "img.onload = function() {\n",
        "  ctx1.drawImage(img, 0, 0);\n",
        "};\n",
        "img.crossOrigin = 'Anonymous';\n",
        "\n",
        "ctx.clearRect(0, 0, canvas.width, canvas.height);\n",
        "\n",
        "ctx.lineWidth = %d\n",
        "var button = document.querySelector('button')\n",
        "var mouse = {x: 0, y: 0}\n",
        "\n",
        "canvas.addEventListener('mousemove', function(e) {\n",
        "  mouse.x = e.pageX - this.offsetLeft\n",
        "  mouse.y = e.pageY - this.offsetTop\n",
        "})\n",
        "canvas.onmousedown = ()=>{\n",
        "  ctx.beginPath()\n",
        "  ctx.moveTo(mouse.x, mouse.y)\n",
        "  canvas.addEventListener('mousemove', onPaint)\n",
        "}\n",
        "canvas.onmouseup = ()=>{\n",
        "  canvas.removeEventListener('mousemove', onPaint)\n",
        "}\n",
        "var onPaint = ()=>{\n",
        "  ctx.lineTo(mouse.x, mouse.y)\n",
        "  ctx.stroke()\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "  button.onclick = ()=>{\n",
        "    resolve(canvas.toDataURL('image/png'))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def draw(imgm, filename='drawing.png', w=400, h=200, line_width=1):\n",
        "  display(HTML(canvas_html % (w, h, w,h, filename.split('.')[-1], imgm, line_width)))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23WaUHiJeyBO"
      },
      "source": [
        "2. Inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubuqEz3OPU_v",
        "outputId": "9cd3c37e-dec6-4c49-c393-3d1053cdbb11"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mbig-lama\u001b[0m/     \u001b[01;34mcolab\u001b[0m/         \u001b[01;34mdocker\u001b[0m/      \u001b[01;34mmodels\u001b[0m/           \u001b[01;34msaicinpainting\u001b[0m/\n",
            "big-lama.zip  conda_env.yml  \u001b[01;34mfetch_data\u001b[0m/  README.md\n",
            "\u001b[01;34mbin\u001b[0m/          \u001b[01;34mconfigs\u001b[0m/       LICENSE      requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IFIDDD4IhPXd"
      },
      "outputs": [],
      "source": [
        "fname = None\n",
        "#fname = '/content/database/ImageEditing/input'\n",
        "\n",
        "# fname = 'https://ic.pics.livejournal.com/mostovoy/28566193/1224276/1224276_original.jpg' # <-in the example\n",
        "# fname = 'https://raw.githubusercontent.com/senya-ashukha/senya-ashukha.github.io/master/images/1010286.jpeg'\n",
        "# fname = 'https://raw.githubusercontent.com/senya-ashukha/senya-ashukha.github.io/master/images/1010287.jpeg'\n",
        "# fname = \"https://raw.githubusercontent.com/senya-ashukha/senya-ashukha.github.io/master/images/alex.jpg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "-VZWySTMeGDM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b42de6-6b51-467f-f498-1734dec7b9ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading Image ::: /content/database/ImageEditing/input/2.jpg\n",
            "Reading Image ::: /content/database/ImageEditing/input/3.jpg\n",
            "Reading Image ::: /content/database/ImageEditing/input/4.jpg\n",
            "Reading Image ::: /content/database/ImageEditing/input/5.jpg\n",
            "Reading Image ::: /content/database/ImageEditing/input/6.jpg\n",
            "Reading Image ::: /content/database/ImageEditing/input/7.jpg\n",
            "Reading Image ::: /content/database/ImageEditing/input/8.jpg\n",
            "img_name :::  2.jpg\n",
            "fname2 :::  data_for_prediction/2.jpg\n"
          ]
        }
      ],
      "source": [
        "#@title Draw a Mask, Press Finish, Wait for Inpainting\n",
        "\n",
        "# needs to direct to the input folder on nextcloud\n",
        "\n",
        "# if fname is None:\n",
        "#   from google.colab import files\n",
        "#   files = files.upload()\n",
        "#   fname = list(files.keys())[0]\n",
        "# else:\n",
        "#   fname = wget.download(fname)\n",
        "\n",
        "# Read input images from folder\n",
        "import glob\n",
        "\n",
        "fname = None\n",
        "\n",
        "if fname is None:\n",
        "  LM_files = glob.glob(input_folder + '/*.jpg')\n",
        "  LM_files.sort()\n",
        "  \n",
        "  fname = LM_files[0]\n",
        "\n",
        "  for file in LM_files:\n",
        "    print(\"Reading Image ::: \" + file)\n",
        "else:\n",
        "  print ('nothing to read/show')\n",
        "\n",
        "shutil.rmtree('data_for_prediction', ignore_errors=True)\n",
        "!mkdir data_for_prediction\n",
        "\n",
        "# trim the path to image name\n",
        "img_name = LM_files[0][-5:]\n",
        "\n",
        "print('img_name ::: ', img_name)\n",
        "\n",
        "copyfile(fname, f'data_for_prediction/{img_name}')\n",
        "os.remove(fname)\n",
        "fname = f'data_for_prediction/{img_name}'\n",
        "\n",
        "print('fname2 ::: ', fname)\n",
        "# image64 = base64.b64encode(open(fname, 'rb').read())\n",
        "# image64 = image64.decode('utf-8')\n",
        "\n",
        "# print(f'Will use {fname} for inpainting')\n",
        "# img = np.array(plt.imread(f'{fname}')[:,:,:3])\n",
        "\n",
        "# draw(image64, filename=f\"./{fname.split('.')[1]}_mask.png\", w=img.shape[1], h=img.shape[0], line_width=0.04*img.shape[1])\n",
        "# #@title Show a masked image and save a mask\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.rcParams[\"figure.figsize\"] = (15,5)\n",
        "# plt.rcParams['figure.dpi'] = 200\n",
        "# plt.subplot(131)\n",
        "# with_mask = np.array(plt.imread(f\"./{fname.split('.')[1]}_mask.png\")[:,:,:3])\n",
        "# mask = (with_mask[:,:,0]==1)*(with_mask[:,:,1]==0)*(with_mask[:,:,2]==0)\n",
        "# plt.imshow(mask, cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.title('mask')\n",
        "# plt.imsave(f\"./{fname.split('.')[1]}_mask.png\",mask, cmap='gray')\n",
        "\n",
        "# plt.subplot(132)\n",
        "# img = np.array(plt.imread(f'{fname}')[:,:,:3])\n",
        "# plt.imshow(img)\n",
        "# plt.axis('off')\n",
        "# plt.title('img')\n",
        "\n",
        "# plt.subplot(133)\n",
        "# img = np.array((1-mask.reshape(mask.shape[0], mask.shape[1], -1))*plt.imread(fname)[:,:,:3])\n",
        "# _=plt.imshow(img)\n",
        "# _=plt.axis('off')\n",
        "# _=plt.title('img * mask')\n",
        "# plt.show()\n",
        "\n",
        "# print('Run inpainting')\n",
        "# if '.jpeg' in fname:\n",
        "#   !PYTHONPATH=. TORCH_HOME=$(pwd) python3 bin/predict.py model.path=$(pwd)/big-lama indir=$(pwd)/data_for_prediction outdir=/content/output dataset.img_suffix=.jpeg > /dev/null\n",
        "# elif '.jpg' in fname:\n",
        "#   !PYTHONPATH=. TORCH_HOME=$(pwd) python3 bin/predict.py model.path=$(pwd)/big-lama indir=$(pwd)/data_for_prediction outdir=/content/output  dataset.img_suffix=.jpg > /dev/null\n",
        "# elif '.png' in fname:\n",
        "#   !PYTHONPATH=. TORCH_HOME=$(pwd) python3 bin/predict.py model.path=$(pwd)/big-lama indir=$(pwd)/data_for_prediction outdir=/content/output  dataset.img_suffix=.png > /dev/null\n",
        "# else:\n",
        "#   print(f'Error: unknown suffix .{fname.split(\".\")[-1]} use [.png, .jpeg, .jpg]')\n",
        "\n",
        "# plt.rcParams['figure.dpi'] = 200\n",
        "# plt.imshow(plt.imread(f\"/content/output/{fname.split('.')[1].split('/')[2]}_mask.png\"))\n",
        "# _=plt.axis('off')\n",
        "# _=plt.title('inpainting result')\n",
        "# plt.show()\n",
        "\n",
        "# fname = None"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "LaMa-inpainting.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}