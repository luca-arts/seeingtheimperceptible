{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luca-arts/seeingtheimperceptible/blob/main/notebooks/colorGrading/tests/LPTN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Color grading via LPTN\n",
        "\n",
        "[https://github.com/csjliang/LPTN](https://github.com/csjliang/LPTN)\n"
      ],
      "metadata": {
        "id": "Oka582cduBH-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1FCPYo3Wt6IL",
        "outputId": "60d7402a-3e12-4ebd-8553-d7e4300417a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1793  100  1793    0     0  38978      0 --:--:-- --:--:-- --:--:-- 38978\n",
            "what's the username for nextcloud? colab\n",
            "what's the password for user colab? ··········\n",
            "1\n",
            "Please enter the username to authenticate with server\n",
            "https://cloud.bxlab.net/remote.php/dav/files/colab/colabfiles/ or hit enter for none.\n",
            "  Username: Please enter the password to authenticate user colab with server\n",
            "https://cloud.bxlab.net/remote.php/dav/files/colab/colabfiles/ or hit enter for none.\n",
            "  Password:  \n",
            "content of /etc/fstab: https://cloud.bxlab.net/remote.php/dav/files/colab/colabfiles/ /content/database davfs user,rw,auto 0 0\n"
          ]
        }
      ],
      "source": [
        "# we'll link the dataset from next-cloud\n",
        "!curl https://raw.githubusercontent.com/luca-arts/seeingtheimperceptible/main/notebooks/database_mod.py -o /content/database_mod.py\n",
        "\n",
        "from database_mod import *\n",
        "\n",
        "link_nextcloud()\n",
        "\n",
        "nextcloud = '/content/database/'\n",
        "\n",
        "input_folder, output_folder = create_io(database=nextcloud,topic='colorGrading',library='LPTN')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Clone the Git repository"
      ],
      "metadata": {
        "id": "HiiAOBc-vTPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "root_path = '/content/LPTN'\n",
        "# clone the repository\n",
        "if not os.path.exists('LPTN'):\n",
        "  !git clone https://github.com/csjliang/LPTN {root_path}"
      ],
      "metadata": {
        "id": "bbAS06muwjiD",
        "outputId": "98b3168d-6376-4b92-a658-a71e2405a1bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/LPTN'...\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
            "remote: Total 107 (delta 26), reused 67 (delta 6), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (107/107), 263.69 KiB | 3.38 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. install dependencies"
      ],
      "metadata": {
        "id": "zJsUSddIw42B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qr {root_path}/requirement.txt"
      ],
      "metadata": {
        "id": "Qn5AaWfHw5af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe64aa7e-c49e-40a5-9f1b-9e36cce30dca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.8 MB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 190 kB 49.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Pretrained model download"
      ],
      "metadata": {
        "id": "WIu3lf_uyVXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check first if exist, otherwise create path\n",
        "pretrained_pth = root_path + '/experiments/pretrained_models/net_g_FiveK_numhigh3.pth'\n",
        "\n",
        "if not os.path.exists(pretrained_pth):\n",
        "  !gdown --id 11yuFgHqZe9e4OheJ9YHp9lS-4kQC1Fml \\\n",
        "          -O {pretrained_pth}"
      ],
      "metadata": {
        "id": "S1VOs015yVoT",
        "outputId": "883e8b41-832a-4c0c-9ee4-32d9035fece9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=11yuFgHqZe9e4OheJ9YHp9lS-4kQC1Fml\n",
            "To: /content/LPTN/experiments/pretrained_models/net_g_FiveK_numhigh3.pth\n",
            "\r  0% 0.00/2.48M [00:00<?, ?B/s]\r100% 2.48M/2.48M [00:00<00:00, 207MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. install pyYAML and update the YAML file with correct path for pretrained_models\n",
        "\n",
        "geen idee of we dit nodig hebben, maar heb zelf deze code erin gezet om te checken of het path effectief naar de goeie folder wijst.\n"
      ],
      "metadata": {
        "id": "MSFTceQ89GUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyYAML\n",
        "\n",
        "import yaml\n",
        "\n",
        "# dowload the pre-trained model for colorgrading\n",
        " \n",
        "def read_yaml(LPTN_path):\n",
        "    \"\"\" A function to read YAML file\"\"\"\n",
        "    with open('{}/options/test/LPTN/test_FiveK.yml'.format(LPTN_path)) as f:\n",
        "        config = yaml.safe_load(f)\n",
        " \n",
        "    return config\n",
        "\n",
        "read_yaml(root_path)"
      ],
      "metadata": {
        "id": "_EtdxUxI9axB",
        "outputId": "e26a60a3-f7ce-4a32-ff82-e9d61b0a289d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyYAML in /usr/local/lib/python3.7/dist-packages (3.13)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'datasets': {'test': {'dataroot_gt': 'datasets/FiveK/FiveK_test_target.lmdb',\n",
              "   'dataroot_lq': 'datasets/FiveK/FiveK_test_source.lmdb',\n",
              "   'io_backend': {'type': 'lmdb'},\n",
              "   'name': 'FiveK_val',\n",
              "   'type': 'PairedImageDataset'}},\n",
              " 'manual_seed': 10,\n",
              " 'model_type': 'LPTNTestModel',\n",
              " 'name': 'LPTN_FiveK_480p',\n",
              " 'network_g': {'nrb_high': 3, 'nrb_low': 5, 'num_high': 3, 'type': 'LPTN'},\n",
              " 'num_gpu': 1,\n",
              " 'path': {'pretrain_network_g': 'experiments/pretrained_models/net_g_FiveK_numhigh3.pth',\n",
              "  'strict_load_g': False},\n",
              " 'val': {'metrics': {'psnr': {'crop_border': 0,\n",
              "    'test_y_channel': False,\n",
              "    'type': 'calculate_psnr'}},\n",
              "  'save_img': True,\n",
              "  'suffix': None}}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. dataset downloaden"
      ],
      "metadata": {
        "id": "XayoV4kjO6Nd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "download dataset"
      ],
      "metadata": {
        "id": "dvehf5N0RVdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# define folders\n",
        "output_path_dataset = root_path +'/datasets'\n",
        "output_path_FiveK = output_path_dataset +'/FiveK'\n",
        "input_path = nextcloud + 'colorGrading/datasets/FiveK_480p.zip'\n",
        "\n",
        "# make folders\n",
        "os.makedirs(output_path_dataset, exist_ok=True)\n",
        "os.makedirs(output_path_FiveK, exist_ok=True)\n",
        "\n",
        "#!unzip \"/content/drive/path/input_file_name.zip\" -d \"/content/drive/path/output_folder/\"\n",
        "!unzip -q {input_path} -d {output_path_FiveK}\n",
        "\n",
        "%ls"
      ],
      "metadata": {
        "id": "VUSVuplwO7FN",
        "outputId": "103f37fd-bcf2-493c-aad3-1957eb27d314",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdatabase\u001b[0m/  database_mod.py  \u001b[01;34mLPTN\u001b[0m/  \u001b[01;34m__pycache__\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create lmdb"
      ],
      "metadata": {
        "id": "_aDE673VRSR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/LPTN/\n",
        "!PYTHONPATH=\"/content/LPTN/:${PYTHONPATH}\" python scripts/data_preparation/create_lmdb.py"
      ],
      "metadata": {
        "id": "3dc2IO5yRREO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd18eb57-cc5f-4cb5-8946-eb47019b9d53"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LPTN\n",
            "Reading image path list ...\n",
            "Create lmdb for datasets/FiveK/FiveK_480p/train/A, save to datasets/FiveK/FiveK_train_source.lmdb...\n",
            "Totoal images: 2250\n",
            "Data size per image is:  482882\n",
            "Write 998: 100% 2250/2250 [01:33<00:00, 24.06chunk/s]\n",
            "\n",
            "Finish writing lmdb.\n",
            "Reading image path list ...\n",
            "Create lmdb for datasets/FiveK/FiveK_480p/train/B, save to datasets/FiveK/FiveK_train_target.lmdb...\n",
            "Totoal images: 2250\n",
            "Data size per image is:  678345\n",
            "Write 999: 100% 2250/2250 [01:46<00:00, 21.15chunk/s]\n",
            "\n",
            "Finish writing lmdb.\n",
            "Reading image path list ...\n",
            "Create lmdb for datasets/FiveK/FiveK_480p/test/A, save to datasets/FiveK/FiveK_test_source.lmdb...\n",
            "Totoal images: 500\n",
            "Data size per image is:  308466\n",
            "Write 5000: 100% 500/500 [00:20<00:00, 23.85chunk/s]\n",
            "\n",
            "Finish writing lmdb.\n",
            "Reading image path list ...\n",
            "Create lmdb for datasets/FiveK/FiveK_480p/test/B, save to datasets/FiveK/FiveK_test_target.lmdb...\n",
            "Totoal images: 500\n",
            "Data size per image is:  611200\n",
            "Write 5000: 100% 500/500 [00:23<00:00, 21.08chunk/s]\n",
            "\n",
            "Finish writing lmdb.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Evaluation"
      ],
      "metadata": {
        "id": "hYOqeKOqEcep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yml file test"
      ],
      "metadata": {
        "id": "41lvseFFTiMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install basicsr\n",
        "!PYTHONPATH=\"/content/LPTN/:${PYTHONPATH}\" CUDA_VISIBLE_DEVICES=0 python codes/test.py -opt options/test/LPTN/test_FiveK.yml"
      ],
      "metadata": {
        "id": "duiptbuiEgCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d8e3f3d-b61d-4e02-a733-b0ce03433a28"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting basicsr\n",
            "  Downloading basicsr-1.3.5.tar.gz (161 kB)\n",
            "\u001b[K     |████████████████████████████████| 161 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.7/dist-packages (from basicsr) (2.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from basicsr) (0.16.0)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from basicsr) (0.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from basicsr) (1.21.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from basicsr) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from basicsr) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from basicsr) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from basicsr) (2.23.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from basicsr) (0.18.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from basicsr) (1.4.1)\n",
            "Requirement already satisfied: tb-nightly in /usr/local/lib/python3.7/dist-packages (from basicsr) (2.9.0a20220313)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from basicsr) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from basicsr) (0.11.1+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from basicsr) (4.63.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.7/dist-packages (from basicsr) (0.32.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->basicsr) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->basicsr) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->basicsr) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->basicsr) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->basicsr) (1.24.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->basicsr) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->basicsr) (2.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->basicsr) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->basicsr) (1.2.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->basicsr) (2.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->basicsr) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->basicsr) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->basicsr) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->basicsr) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->basicsr) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (1.44.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (0.37.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->basicsr) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly->basicsr) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly->basicsr) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly->basicsr) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->basicsr) (3.2.0)\n",
            "Building wheels for collected packages: basicsr\n",
            "  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for basicsr: filename=basicsr-1.3.5-py3-none-any.whl size=194484 sha256=8214406e5628981c6876bb3e0a4a51edaaf98ccaafd076b832be7a55ef4d3ad3\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/1b/d0/8659cf028233dd1e3bf282271009fbf037dfc4ab761f32a032\n",
            "Successfully built basicsr\n",
            "Installing collected packages: basicsr\n",
            "Successfully installed basicsr-1.3.5\n",
            "Disable distributed.\n",
            "2022-03-14 08:32:17,032 INFO: \n",
            "  name: LPTN_FiveK_480p\n",
            "  model_type: LPTNTestModel\n",
            "  num_gpu: 1\n",
            "  manual_seed: 10\n",
            "  datasets:[\n",
            "    test:[\n",
            "      name: FiveK_val\n",
            "      type: PairedImageDataset\n",
            "      dataroot_gt: datasets/FiveK/FiveK_test_target.lmdb\n",
            "      dataroot_lq: datasets/FiveK/FiveK_test_source.lmdb\n",
            "      io_backend:[\n",
            "        type: lmdb\n",
            "      ]\n",
            "      phase: test\n",
            "    ]\n",
            "  ]\n",
            "  network_g:[\n",
            "    type: LPTN\n",
            "    nrb_low: 5\n",
            "    nrb_high: 3\n",
            "    num_high: 3\n",
            "  ]\n",
            "  path:[\n",
            "    pretrain_network_g: experiments/pretrained_models/net_g_FiveK_numhigh3.pth\n",
            "    strict_load_g: False\n",
            "    root: /content/LPTN\n",
            "    results_root: /content/LPTN/results/LPTN_FiveK_480p\n",
            "    log: /content/LPTN/results/LPTN_FiveK_480p\n",
            "    visualization: /content/LPTN/results/LPTN_FiveK_480p/visualization\n",
            "  ]\n",
            "  val:[\n",
            "    save_img: True\n",
            "    suffix: None\n",
            "    metrics:[\n",
            "      psnr:[\n",
            "        type: calculate_psnr\n",
            "        crop_border: 0\n",
            "        test_y_channel: False\n",
            "      ]\n",
            "    ]\n",
            "  ]\n",
            "  is_train: False\n",
            "  dist: False\n",
            "  rank: 0\n",
            "  world_size: 1\n",
            "\n",
            "2022-03-14 08:32:17,034 INFO: Dataset PairedImageDataset - FiveK_val is created.\n",
            "2022-03-14 08:32:17,034 INFO: Number of test images in FiveK_val: 500\n",
            "2022-03-14 08:32:26,354 INFO: Network: LPTN, with parameters: 617,567\n",
            "2022-03-14 08:32:26,354 INFO: LPTN(\n",
            "  (lap_pyramid): Lap_Pyramid_Conv()\n",
            "  (trans_low): Trans_low(\n",
            "    (model): Sequential(\n",
            "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (2): LeakyReLU(negative_slope=0.01)\n",
            "      (3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): LeakyReLU(negative_slope=0.01)\n",
            "      (5): ResidualBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.01)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (6): ResidualBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.01)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (7): ResidualBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.01)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (8): ResidualBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.01)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (9): ResidualBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.01)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (10): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (11): LeakyReLU(negative_slope=0.01)\n",
            "      (12): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (trans_high): Trans_high(\n",
            "    (model): Sequential(\n",
            "      (0): Conv2d(9, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): LeakyReLU(negative_slope=0.01)\n",
            "      (2): ResidualBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.01)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (3): ResidualBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.01)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (4): ResidualBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.01)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (5): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "    (trans_mask_block_0): Sequential(\n",
            "      (0): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): LeakyReLU(negative_slope=0.01)\n",
            "      (2): Conv2d(16, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (trans_mask_block_1): Sequential(\n",
            "      (0): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): LeakyReLU(negative_slope=0.01)\n",
            "      (2): Conv2d(16, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (trans_mask_block_2): Sequential(\n",
            "      (0): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): LeakyReLU(negative_slope=0.01)\n",
            "      (2): Conv2d(16, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2022-03-14 08:32:26,354 INFO: Loading LPTN model from experiments/pretrained_models/net_g_FiveK_numhigh3.pth.\n",
            "2022-03-14 08:32:26,371 INFO: Model [LPTNTestModel] is created.\n",
            "2022-03-14 08:32:26,371 INFO: Testing FiveK_val...\n",
            "Test 5000: 100% 500/500 [01:20<00:00,  6.20image/s]\n",
            "2022-03-14 08:33:47,062 INFO: Validation FiveK_val\n",
            "\t # psnr: 22.9145\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "speed testing"
      ],
      "metadata": {
        "id": "s_5Ld8TRTeZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!PYTHONPATH=\"/content/LPTN/:${PYTHONPATH}\" CUDA_VISIBLE_DEVICES=0 python codes/test_speed.py -opt options/test/LPTN/test_speed_FiveK.yml"
      ],
      "metadata": {
        "id": "0zzLtvOiTdgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "918c7150-5bfe-4281-ab4c-c8bcca7f2df9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disable distributed.\n",
            "2022-03-14 08:33:50,226 INFO: \n",
            "  name: LPTN_test_speed\n",
            "  model_type: LPTNTestModel\n",
            "  num_gpu: 1\n",
            "  manual_seed: 10\n",
            "  datasets:[\n",
            "    test:[\n",
            "      name: FiveK_val\n",
            "      type: PairedImageDataset\n",
            "      dataroot_gt: datasets/FiveK/FiveK_test_target.lmdb\n",
            "      dataroot_lq: datasets/FiveK/FiveK_test_source.lmdb\n",
            "      io_backend:[\n",
            "        type: lmdb\n",
            "      ]\n",
            "      phase: test\n",
            "    ]\n",
            "  ]\n",
            "  network_g:[\n",
            "    type: LPTN\n",
            "    nrb_low: 5\n",
            "    nrb_high: 3\n",
            "    num_high: 3\n",
            "  ]\n",
            "  path:[\n",
            "    pretrain_network_g: experiments/pretrained_models/net_g_FiveK_numhigh3.pth\n",
            "    strict_load_g: False\n",
            "    root: /content/LPTN\n",
            "    results_root: /content/LPTN/results/LPTN_test_speed\n",
            "    log: /content/LPTN/results/LPTN_test_speed\n",
            "    visualization: /content/LPTN/results/LPTN_test_speed/visualization\n",
            "  ]\n",
            "  val:[\n",
            "    num_img: 10\n",
            "    times_per_img: 50\n",
            "    fix_img_size: [3840, 2160]\n",
            "  ]\n",
            "  is_train: False\n",
            "  dist: False\n",
            "  rank: 0\n",
            "  world_size: 1\n",
            "\n",
            "2022-03-14 08:33:50,227 INFO: Dataset PairedImageDataset - FiveK_val is created.\n",
            "2022-03-14 08:33:50,227 INFO: Number of test images in FiveK_val: 500\n",
            "2022-03-14 08:33:52,612 INFO: Network: LPTN, with parameters: 617,567\n",
            "2022-03-14 08:33:52,613 INFO: LPTN(\n",
            "  (lap_pyramid): Lap_Pyramid_Conv()\n",
            "  (trans_low): Trans_low(\n",
            "    (model): Sequential(\n",
            "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (2): LeakyReLU(negative_slope=0.01)\n",
            "      (3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): LeakyReLU(negative_slope=0.01)\n",
            "      (5): ResidualBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.01)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (6): ResidualBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.01)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (7): ResidualBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.01)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (8): ResidualBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.01)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (9): ResidualBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.01)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (10): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (11): LeakyReLU(negative_slope=0.01)\n",
            "      (12): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (trans_high): Trans_high(\n",
            "    (model): Sequential(\n",
            "      (0): Conv2d(9, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): LeakyReLU(negative_slope=0.01)\n",
            "      (2): ResidualBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.01)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (3): ResidualBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.01)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (4): ResidualBlock(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.01)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (5): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "    (trans_mask_block_0): Sequential(\n",
            "      (0): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): LeakyReLU(negative_slope=0.01)\n",
            "      (2): Conv2d(16, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (trans_mask_block_1): Sequential(\n",
            "      (0): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): LeakyReLU(negative_slope=0.01)\n",
            "      (2): Conv2d(16, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (trans_mask_block_2): Sequential(\n",
            "      (0): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): LeakyReLU(negative_slope=0.01)\n",
            "      (2): Conv2d(16, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2022-03-14 08:33:52,613 INFO: Loading LPTN model from experiments/pretrained_models/net_g_FiveK_numhigh3.pth.\n",
            "2022-03-14 08:33:52,619 INFO: Model [LPTNTestModel] is created.\n",
            "2022-03-14 08:33:52,619 INFO: Testing speed ...\n",
            "0 Testing 4501 (shape: 3840 * 2160) duration: 0.5769710302352905\n",
            "1 Testing 4502 (shape: 3840 * 2160) duration: 0.5277797794342041\n",
            "2 Testing 4503 (shape: 3840 * 2160) duration: 0.5293258380889893\n",
            "3 Testing 4504 (shape: 3840 * 2160) duration: 0.5293435382843018\n",
            "4 Testing 4505 (shape: 3840 * 2160) duration: 0.528304500579834\n",
            "5 Testing 4506 (shape: 3840 * 2160) duration: 0.5288965845108032\n",
            "6 Testing 4507 (shape: 3840 * 2160) duration: 0.5311731672286988\n",
            "7 Testing 4508 (shape: 3840 * 2160) duration: 0.5306681871414185\n",
            "8 Testing 4509 (shape: 3840 * 2160) duration: 0.5303222465515137\n",
            "9 Testing 4510 (shape: 3840 * 2160) duration: 0.5303715896606446\n",
            "10 Testing 4511 (shape: 3840 * 2160) duration: 0.5306756162643432\n",
            "average duration is 0.5873832077980042 seconds\n"
          ]
        }
      ]
    }
  ]
}