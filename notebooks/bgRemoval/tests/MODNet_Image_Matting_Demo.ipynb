{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luca-arts/seeingtheimperceptible/blob/main/notebooks/bgRemoval/tests/MODNet_Image_Matting_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlARSYHGHgev"
      },
      "source": [
        "# Background Removal - MODNet\n",
        "\n",
        "[![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/pdf/2011.11961.pdf)          [![GitHub stars](https://img.shields.io/github/stars/ZHKKKe/MODNet?style=social)](https://github.com/ZHKKKe/MODNet)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3t-jsyrtl7w"
      },
      "source": [
        "## 1. linking nextcloud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkk60QsJw8D0"
      },
      "source": [
        "Connecting to the external NextCloud drive \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we'll link the dataset from next-cloud\n",
        "!curl https://raw.githubusercontent.com/luca-arts/seeingtheimperceptible/main/notebooks/database_mod.py -o /content/database_mod.py\n",
        "\n",
        "from database_mod import *\n",
        "\n",
        "link_nextcloud()\n",
        "\n",
        "nextcloud = '/content/database/'\n",
        "\n",
        "input_folder, output_folder = create_io(database=nextcloud,topic='bgRemoval',library='MODNet')"
      ],
      "metadata": {
        "id": "uvBmcsAB0I9L",
        "outputId": "baea3abf-8e7a-4ea8-be0c-4a4da81664df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2235  100  2235    0     0  33358      0 --:--:-- --:--:-- --:--:-- 33358\n",
            "what's the username for nextcloud? colab\n",
            "what's the password for user colab? ··········\n",
            "0\n",
            "Please enter the username to authenticate with server\n",
            "https://cloud.bxlab.net/remote.php/dav/files/colab/colabfiles/ or hit enter for none.\n",
            "  Username: Please enter the password to authenticate user colab with server\n",
            "https://cloud.bxlab.net/remote.php/dav/files/colab/colabfiles/ or hit enter for none.\n",
            "  Password:  \n",
            "content of /etc/fstab: https://cloud.bxlab.net/remote.php/dav/files/colab/colabfiles/ /content/database davfs user,rw,auto 0 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Clone the GIT repo and download the model"
      ],
      "metadata": {
        "id": "SMznlzBt5K5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "mask_folder = '/content/mask_folder'\n",
        "os.makedirs(mask_folder, exist_ok=True)"
      ],
      "metadata": {
        "id": "NiPrBbe405Od"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "remove hidden file .ipynb_checkpoints"
      ],
      "metadata": {
        "id": "Dg3EdyRrMcLe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gEwiokUgkSDO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f862c491-b291-44d8-9617-4c520cd0c9c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/MODNet'...\n",
            "remote: Enumerating objects: 270, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 270 (delta 31), reused 30 (delta 11), pack-reused 206\u001b[K\n",
            "Receiving objects: 100% (270/270), 60.77 MiB | 13.83 MiB/s, done.\n",
            "Resolving deltas: 100% (92/92), done.\n",
            "/content/MODNet\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1mcr7ALciuAsHCpLnrtG_eop5-EYhbCmz\n",
            "To: /content/MODNet/pretrained/modnet_photographic_portrait_matting.ckpt\n",
            "100% 26.3M/26.3M [00:00<00:00, 192MB/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# clone the repository\n",
        "if not os.path.exists('/content/MODNet'):\n",
        "  !git clone https://github.com/ZHKKKe/MODNet /content/MODNet\n",
        "%cd /content/MODNet/\n",
        "\n",
        "# dowload the pre-trained ckpt for image matting\n",
        "pretrained_ckpt = 'pretrained/modnet_photographic_portrait_matting.ckpt'\n",
        "if not os.path.exists(pretrained_ckpt):\n",
        "  !gdown --id 1mcr7ALciuAsHCpLnrtG_eop5-EYhbCmz \\\n",
        "          -O pretrained/modnet_photographic_portrait_matting.ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwMfEIiwu5VB"
      },
      "source": [
        "## 3. Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJaRhVYdfxNt"
      },
      "source": [
        "<p align=\"justify\">Run the following command for alpha matte prediction:</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fi1jtFug-Nvh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba040854-689f-4933-8c07-a396832ebeda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process image: LB_0001.jpg\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3680: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "Process image: LB_0002.jpg\n",
            "Process image: LB_0003.jpg\n",
            "Process image: LB_0004.jpg\n",
            "Process image: LB_0005.jpg\n",
            "Process image: LB_0006.jpg\n",
            "Process image: LB_0007.jpg\n",
            "Process image: LB_0008.jpg\n",
            "Process image: LB_0009.jpg\n",
            "Process image: LB_0010.jpg\n",
            "Process image: LB_0011.jpg\n",
            "Process image: LB_0012.jpg\n",
            "Process image: LB_0013.jpg\n",
            "Process image: LB_0014.jpg\n",
            "Process image: LB_0015.jpg\n",
            "Process image: LB_0016.jpg\n",
            "Process image: LB_0017.jpg\n",
            "Process image: LB_0018.jpg\n",
            "Process image: LB_0019.jpg\n",
            "Process image: LB_0020.jpg\n",
            "Process image: LB_0021.jpg\n",
            "Process image: LB_0022.jpg\n",
            "Process image: LB_0023.jpg\n",
            "Process image: LB_0024.jpg\n",
            "Process image: LB_0025.jpg\n",
            "Process image: LB_0026.jpg\n",
            "Process image: LB_0027.jpg\n",
            "Process image: LB_0028.jpg\n",
            "Process image: LB_0029.jpg\n",
            "Process image: LB_0030.jpg\n",
            "Process image: LB_0031.jpg\n",
            "Process image: LB_0032.jpg\n",
            "Process image: LB_0033.jpg\n",
            "Process image: LB_0034.jpg\n",
            "Process image: LB_0035.jpg\n",
            "Process image: LB_0036.jpg\n",
            "Process image: LB_0037.jpg\n",
            "Process image: LB_0038.jpg\n",
            "Process image: LB_0039.jpg\n",
            "Process image: LB_0040.jpg\n",
            "Process image: LB_0041.jpg\n",
            "Process image: LB_0042.jpg\n",
            "Process image: LB_0043.jpg\n",
            "Process image: LB_0044.jpg\n",
            "Process image: LB_0045.jpg\n",
            "Process image: LB_0046.jpg\n",
            "Process image: LB_0047.jpg\n",
            "Process image: LB_0048.jpg\n",
            "Process image: LB_0049.jpg\n",
            "Process image: LB_0050.jpg\n"
          ]
        }
      ],
      "source": [
        "!python -m demo.image_matting.colab.inference \\\n",
        "        --input-path {input_folder} \\\n",
        "        --output-path {mask_folder} \\\n",
        "        --ckpt-path pretrained/modnet_photographic_portrait_matting.ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwGwwojKu_en"
      },
      "source": [
        "## 4. Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6FP75C8gHbz"
      },
      "source": [
        "<p align=\"justify\">Display the results (from left to right: image, foreground, and alpha matte):</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JOmYOHKfgQ5Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from os.path import isfile, join\n",
        "\n",
        "def combined_display(image, matte):\n",
        "  # calculate display resolution\n",
        "  w, h = image.width, image.height\n",
        "  rw, rh = 800, int(h * 800 / (3 * w))\n",
        "  \n",
        "  # obtain predicted foreground\n",
        "  image = np.asarray(image)\n",
        "  if len(image.shape) == 2:\n",
        "    image = image[:, :, None]\n",
        "  if image.shape[2] == 1:\n",
        "    image = np.repeat(image, 3, axis=2)\n",
        "  elif image.shape[2] == 4:\n",
        "    image = image[:, :, 0:3]\n",
        "  matte = np.repeat(np.asarray(matte)[:, :, None], 3, axis=2) / 255\n",
        "  foreground = image * matte + np.full(image.shape, 255) * (1 - matte)\n",
        "  foreground_img = Image.fromarray(np.uint8(foreground))\n",
        "  # combine image, foreground, and alpha into one line\n",
        "  combined = np.concatenate((image, foreground, matte * 255), axis=1)\n",
        "  combined = Image.fromarray(np.uint8(combined)).resize((rw, rh))\n",
        "  return combined, foreground_img\n",
        "\n",
        "# visualize all images\n",
        "def visualize_images(input_folder):\n",
        "  image_names = os.listdir(input_folder)\n",
        "  for image_name in image_names:\n",
        "    matte_name = image_name.split('.')[0] + '.png'\n",
        "    image = Image.open(os.path.join(input_folder, image_name))\n",
        "    matte = Image.open(os.path.join(mask_folder, matte_name))\n",
        "    display(combined_display(image, matte)[1])\n",
        "    print(image_name, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_options = \"combined\" #@param [\"combined\",\"mask\"]\n",
        "import shutil\n",
        "\n",
        "def save_results(save_options:str):\n",
        "  if(save_options=='mask'):\n",
        "    shutil.copy2(mask_folder, output_folder)\n",
        "  elif(save_options=='combined'):\n",
        "    image_names = os.listdir(input_folder)\n",
        "    for image_name in image_names:\n",
        "      matte_name = image_name.split('.')[0] + '.png'\n",
        "      image = Image.open(os.path.join(input_folder, image_name))\n",
        "      matte = Image.open(os.path.join(mask_folder, matte_name))\n",
        "      combined_display(image, matte).save(os.path.join(output_folder,matte_name))\n",
        "  else:\n",
        "    print(\"wrong option\")\n",
        "save_results(save_options)\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "iH6nL_JAahxb",
        "outputId": "fd0aae74-00e5-4a19-eeea-4188545baec5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1bd49448f09c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wrong option\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0msave_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-1bd49448f09c>\u001b[0m in \u001b[0;36msave_results\u001b[0;34m(save_options)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_options\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'combined'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mimage_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mmatte_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_folder' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfDKNQNeeLhx"
      },
      "source": [
        "## 5. Download Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqNdGeIf1cc8"
      },
      "source": [
        "<p align=\"justify\">Download the Zip package of predicted alpha mattes:</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6aqVu631k01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4d785b7-5514-4133-9c89-e2d8c754c999"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fabba21f-988c-4e96-a262-c382b0f6115c\", \"matte.zip\", 45567)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "zip_filename = 'matte.zip'\n",
        "create_zip(zip_filename, output_folder)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO right now we're downloading the mask. Perhaps it is the easiest to download the mask, upscale it and then use it on the original image?"
      ],
      "metadata": {
        "id": "o-GnsZnr4X3U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MODNet - Image Matting Demo.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}